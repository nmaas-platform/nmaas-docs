{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NMaaS home Overview The cost and complexity of developing and integrating in-house network management may be too high for many NRENs (National Research and Education Networks), institutions, projects or teams. Off-the-shelf solutions might not be suitable and might be costly. Network Management as a Service (NMaaS) aims to support these users in providing an effective, efficient network and service management platform. NMaaS enables management and monitoring of user networks through on-demand deployment of network management tools in a Kubernetes-based cloud infrastructure. Using a multi-tenant approach and software based VPNs, each NREN or institution has private access to their network management systems and services from a highly available cloud based platform. NMaaS is meant for smaller and emerging NRENs, campuses, small organisations or distributed research projects that may have limited resources to develop and/or maintain their own NMS infrastructure or planned to outsource these activities. By using a shared and supported platform, institutions can focus solely on the monitoring and management of their service components. It is also suitable for use in those NRENs which provide campus network management service (CNaaS) to their institutions. Using NMaaS, NRENs can easily provide per-campus network management software instances. Managed NMaaS NMaaS ( https://nmaas.eu ) is offered within the G\u00c9ANT project as a managed service since December 2018. Currently, the portfolio of tools offered by NMaaS consists of over 30 applications including Oxidized, LibreNMS, Prometheus, Grafana, Zabbix, NetBox and others. Self-hosted NMaaS NMaaS self-hosting options are also available for users having access to an existing Kubernetes infrastructure.","title":"Home"},{"location":"#nmaas-home","text":"","title":"NMaaS home"},{"location":"#overview","text":"The cost and complexity of developing and integrating in-house network management may be too high for many NRENs (National Research and Education Networks), institutions, projects or teams. Off-the-shelf solutions might not be suitable and might be costly. Network Management as a Service (NMaaS) aims to support these users in providing an effective, efficient network and service management platform. NMaaS enables management and monitoring of user networks through on-demand deployment of network management tools in a Kubernetes-based cloud infrastructure. Using a multi-tenant approach and software based VPNs, each NREN or institution has private access to their network management systems and services from a highly available cloud based platform. NMaaS is meant for smaller and emerging NRENs, campuses, small organisations or distributed research projects that may have limited resources to develop and/or maintain their own NMS infrastructure or planned to outsource these activities. By using a shared and supported platform, institutions can focus solely on the monitoring and management of their service components. It is also suitable for use in those NRENs which provide campus network management service (CNaaS) to their institutions. Using NMaaS, NRENs can easily provide per-campus network management software instances.","title":"Overview"},{"location":"#managed-nmaas","text":"NMaaS ( https://nmaas.eu ) is offered within the G\u00c9ANT project as a managed service since December 2018. Currently, the portfolio of tools offered by NMaaS consists of over 30 applications including Oxidized, LibreNMS, Prometheus, Grafana, Zabbix, NetBox and others.","title":"Managed NMaaS"},{"location":"#self-hosted-nmaas","text":"NMaaS self-hosting options are also available for users having access to an existing Kubernetes infrastructure.","title":"Self-hosted NMaaS"},{"location":"about/","text":"NMaaS Platform is actively developed and maintained as part of the G\u00c9ANT GN5-1 project co-funded by the European Union. NMaaS components are open-source licensed under the Apache 2.0 Licence. Useful links GitHub G\u00c9ANT project Project members Frederic Loui (RENATER, France) Lukasz Lopatowski (Poznan Supercomputing and Network Center, Poland) Vojdan Kjorveziroski (Ss. Cyril and Methodius University in Skopje, North Macedonia) Follow the information on the contact page to reach us!","title":"About"},{"location":"about/#useful-links","text":"GitHub G\u00c9ANT project","title":"Useful links"},{"location":"about/#project-members","text":"Frederic Loui (RENATER, France) Lukasz Lopatowski (Poznan Supercomputing and Network Center, Poland) Vojdan Kjorveziroski (Ss. Cyril and Methodius University in Skopje, North Macedonia) Follow the information on the contact page to reach us!","title":"Project members"},{"location":"contact/","text":"Contact NMaaS Mailing Lists nmaas@lists.geant.org : If you want to reach NMaaS core team members nmaas-users@lists.geant.org : Discussions related to NMaaS usage and development ( subscribe here ) nmaas-announce@lists.geant.org : Announcements shared by the NMaaS team with the community ( subscribe here )","title":"Contact"},{"location":"contact/#contact","text":"","title":"Contact"},{"location":"contact/#nmaas-mailing-lists","text":"nmaas@lists.geant.org : If you want to reach NMaaS core team members nmaas-users@lists.geant.org : Discussions related to NMaaS usage and development ( subscribe here ) nmaas-announce@lists.geant.org : Announcements shared by the NMaaS team with the community ( subscribe here )","title":"NMaaS Mailing Lists"},{"location":"faq/","text":"NMAAS FAQ The following NMaaS-related questions are answered on this page: How can I contact the NMaaS Team members? How can I test NMaaS? How can I start monitoring my infrastructure with NMaaS? How can I request creation of new NMaaS domain for my NREN / Institution / Project? How can I deploy NMaaS on my own intrastructure? Where can I find NMaaS User Guide? Where can I find NMaaS Administrator Guide? What applications are currently supported by NMaaS? What type of VPNs are established by NMaaS? What VPN solutions are supported by NMaaS? What are NMaaS VPN requirements? How can I contact the NMaaS Team members? The NMaaS Team can be contacted either by: contact form available at http://nmaas.eu/about?type=CONTACT email sent to nmaas@lists.geant.org How can I test NMaaS? In order to test NMaaS visit the NMaaS sandbox instance at https://nmaas.geant.org . Once You log in to the Portal, the NMaaS administrator will receive an automatic notification and will add You as a member of the pre-configured Test domain. In this domain, You will be able to freely browse, deploy and access applications. More information about the NMaaS sandbox is available at NMaaS Playground page . How can I start monitoring my infrastructure with NMaaS? The G\u00c9ANT NMaaS production service is available at https://nmaas.eu where users have the possibility to log in with their eduGAIN accounts. However, in order to be able to deploy network management applications user needs to be assigned to a domain. In order to request new dedicated domain creation refer to question \"How can I request creation of new NMaaS domain for my NREN/Institution/Project?\" How can I request creation of new NMaaS domain for my NREN/Institution/Project? In order to request a new NMaaS domain on the G\u00c9ANT production service fill in and submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST . You will be requested to provide some basic information about the domain to be created and a brief justification of the request. Your request will be reviewed by the NMaaS Team and You will receive a reply as soon as possible. In case of any issues, You can also email your request directly to nmaas@lists.geant.org . How can I deploy NMaaS on my own infrastructure? The complete information about the deployment of NMaaS instance is available at NMaaS Installation Guide . What are the technical requirement for the underlying NMaaS infrastructure? The complete information about the requirements for the NMaaS Kubernetes cluster are available at NMaaS Cluster Requirements . Where can I find NMaaS User Guide? The NMaaS User Guide is available at NMaaS User Guide . Where can I find NMaaS Administrator Guide? The NMaaS Administrator guide is under preparation ... What applications are currently supported by NMaaS? For the up to date information about the supported applications refer to page NMaaS Tools. It is also possible to browse all the applications in on NMaaS Portal directly at https://nmaas.eu . What type of VPNs are established by NMaaS? Two types of VPN connections are configured before a user is able to deploy and effectively used NMaaS applications: site-to-site VPN connection as a secure tunnel from the customer's management VLAN to NMaaS infrastructure, used for monitoring of the network equipment client-access VPN used by the network operators, from their own workstations, to access and configure the deployed network management applications within NMaaS. What VPN solutions are supported by NMaaS? Currently, two site-to-site VPN technologies are actively supported: OpenVPN and WireGuard. For client-access VPN we are using OpenVPN. What are NMaaS VPN requirements? To use NMaaS, prospective customers require two VPN connections: site-to-site VPN connection, establishing a secure tunnel from the customer's management VLAN to NMaaS, used for monitoring of the network equipment client-access VPN used by the network operators, from their own workstations, to access and configure the deployed network management applications within NMaaS. Currently, two site-to-site VPN technologies are actively supported: OpenVPN and WireGuard. More details are available in the subsections below. Site-to-site VPN setup... Site-to-site VPN In order to be able to use NMaaS, a secure site-to-site tunnel connection is required that will be used for all the monitoring traffic between the network management applications deployed on the NMaaS infrastructure and the customer's network devices. As mentioned above, two VPN technologies are currently actively supported for establishing a site-to-site VPN tunnel: OpenVPN and WireGuard. Any one of these can be chosen, depending on the customer's preference or existing networking stack. Required Information No matter the chosen VPN technology, the NMaaS team requires the following information before VPN connectivity can be established: a list of subnets in your local network that you would like to be reachable from NMaaS. This is required so that we can configure the necessary routing rules and policies on our side. Most likely this will be your management VLAN(s) the public IP of the device that you will use to establish the VPN connection If WireGuard is the chosen connection method, then information about the public keys will have to be exchanged between the customer and the NMaaS team as well. Establishing the VPN connection Once the necessary information has been exchanged, the NMaaS team will provision the necessary VPN and the customer will be sent additional information on how to connect to it. This information will include: the VPN tunnel subnet used for interconnecting the customer's site to NMaaS the private subnet that has been assigned to the customer and that will be used as an IP pool for every deployed application through NMaaS a list of additional auxiliary subnets for which the necessary routing information will have to be added by the customer at their end If the customer does not have an existing network device that can be used for terminating the VPN connection, then a simple GNU/Linux virtual machine can be deployed, no matter the chosen VPN technology. This virtual machine will act as a VPN client in terms of the site-to-site tunnel , and as a gateway towards the NMaaS infrastructure for all the network devices in the customer's network. The customer must make sure that appropriate routing rules are configured so that traffic destined for the NMaaS subnets goes through the VPN client, and not through the default gateway in this scenario. The customer should make sure that the appropriate routing rules are configured in their network so that their VPN client acts as a gateway towards the NMaaS' subnets. Testing the VPN connection After establishing the VPN connection, the client can perform a simple test to verify that everything is working as expected. The test involves accessing a special IP address on port 80. This special address is customer dependent and will be provided by the NMaaS team during the registration process. Any command line utility that can open TCP sessions on an arbitrary port can be used for this test, depending on the platform that you are testing from. Note that ICMP and echo requests are not supported on this IP, and ping is not expected to work. Client-access VPN setup... Client-access VPN A client-access VPN connection is used for accessing and interacting with the deployed applications within NMaaS. In order to provide greater security and isolation between the customers, by default, all applications deployed by NMaaS are accessible only through the respective client-access profiles, and not publicly. However, the option for publicly exposing a given application is also possible. Currently, the preferred way for establishing the client-access connections is by using an OpenVPN tunnel, since it offers stable packages for all major operating systems. The only information required before the client-access profiles can be generated is a list of individuals, along with their full names and email addresses that should have access to the new NMaaS domain being created. Testing the VPN connection The client-access connection can be tested in a similar fashion to the site-to-site connection. The operator, after connecting to the NMaaS VPN server can simply open a browser and type in the IP address provided by the NMaaS team during the registration process. Required information for the VPN profiles... Required information for the VPN profiles In conclusion, accessing NMaaS requires two types of VPN connections: a site-to-site, and a client-access. Before the site-to-site profiles can be created, NMaaS requires the following information: the public IP of the device that will act as the VPN client a list of additional auxiliary subnets for which the necessary routing information will have to be added by the customer at their end Before the client-access profile can be created, the following information is needed: a list of individuals that need access to the applications deployed in the new NMaaS domain, including their full names and email addresses.","title":"FAQ"},{"location":"faq/#nmaas-faq","text":"The following NMaaS-related questions are answered on this page: How can I contact the NMaaS Team members? How can I test NMaaS? How can I start monitoring my infrastructure with NMaaS? How can I request creation of new NMaaS domain for my NREN / Institution / Project? How can I deploy NMaaS on my own intrastructure? Where can I find NMaaS User Guide? Where can I find NMaaS Administrator Guide? What applications are currently supported by NMaaS? What type of VPNs are established by NMaaS? What VPN solutions are supported by NMaaS? What are NMaaS VPN requirements?","title":"NMAAS FAQ"},{"location":"faq/#how-can-i-contact-the-nmaas-team-members","text":"The NMaaS Team can be contacted either by: contact form available at http://nmaas.eu/about?type=CONTACT email sent to nmaas@lists.geant.org","title":"How can I contact the NMaaS Team members?"},{"location":"faq/#how-can-i-test-nmaas","text":"In order to test NMaaS visit the NMaaS sandbox instance at https://nmaas.geant.org . Once You log in to the Portal, the NMaaS administrator will receive an automatic notification and will add You as a member of the pre-configured Test domain. In this domain, You will be able to freely browse, deploy and access applications. More information about the NMaaS sandbox is available at NMaaS Playground page .","title":"How can I test NMaaS?"},{"location":"faq/#how-can-i-start-monitoring-my-infrastructure-with-nmaas","text":"The G\u00c9ANT NMaaS production service is available at https://nmaas.eu where users have the possibility to log in with their eduGAIN accounts. However, in order to be able to deploy network management applications user needs to be assigned to a domain. In order to request new dedicated domain creation refer to question \"How can I request creation of new NMaaS domain for my NREN/Institution/Project?\"","title":"How can I start monitoring my infrastructure with NMaaS?"},{"location":"faq/#how-can-i-request-creation-of-new-nmaas-domain-for-my-nreninstitutionproject","text":"In order to request a new NMaaS domain on the G\u00c9ANT production service fill in and submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST . You will be requested to provide some basic information about the domain to be created and a brief justification of the request. Your request will be reviewed by the NMaaS Team and You will receive a reply as soon as possible. In case of any issues, You can also email your request directly to nmaas@lists.geant.org .","title":"How can I request creation of new NMaaS domain for my NREN/Institution/Project?"},{"location":"faq/#how-can-i-deploy-nmaas-on-my-own-infrastructure","text":"The complete information about the deployment of NMaaS instance is available at NMaaS Installation Guide . What are the technical requirement for the underlying NMaaS infrastructure? The complete information about the requirements for the NMaaS Kubernetes cluster are available at NMaaS Cluster Requirements .","title":"How can I deploy NMaaS on my own infrastructure?"},{"location":"faq/#where-can-i-find-nmaas-user-guide","text":"The NMaaS User Guide is available at NMaaS User Guide .","title":"Where can I find NMaaS User Guide?"},{"location":"faq/#where-can-i-find-nmaas-administrator-guide","text":"The NMaaS Administrator guide is under preparation ...","title":"Where can I find NMaaS Administrator Guide?"},{"location":"faq/#what-applications-are-currently-supported-by-nmaas","text":"For the up to date information about the supported applications refer to page NMaaS Tools. It is also possible to browse all the applications in on NMaaS Portal directly at https://nmaas.eu .","title":"What applications are currently supported by NMaaS?"},{"location":"faq/#what-type-of-vpns-are-established-by-nmaas","text":"Two types of VPN connections are configured before a user is able to deploy and effectively used NMaaS applications: site-to-site VPN connection as a secure tunnel from the customer's management VLAN to NMaaS infrastructure, used for monitoring of the network equipment client-access VPN used by the network operators, from their own workstations, to access and configure the deployed network management applications within NMaaS.","title":"What type of VPNs are established by NMaaS?"},{"location":"faq/#what-vpn-solutions-are-supported-by-nmaas","text":"Currently, two site-to-site VPN technologies are actively supported: OpenVPN and WireGuard. For client-access VPN we are using OpenVPN.","title":"What VPN solutions are supported by NMaaS?"},{"location":"faq/#what-are-nmaas-vpn-requirements","text":"To use NMaaS, prospective customers require two VPN connections: site-to-site VPN connection, establishing a secure tunnel from the customer's management VLAN to NMaaS, used for monitoring of the network equipment client-access VPN used by the network operators, from their own workstations, to access and configure the deployed network management applications within NMaaS. Currently, two site-to-site VPN technologies are actively supported: OpenVPN and WireGuard. More details are available in the subsections below. Site-to-site VPN setup...","title":"What are NMaaS VPN requirements?"},{"location":"nmaas-presentations/","text":"NMaaS Presentations GN4-2 Presentations given as part of the G\u00c9ANT GN4-2 project. SuperComputing 2017 (SC17) Event Type: Demo Presenter(s): Jakub Gutkowski, Frederic Loui, Lukasz Lopatowski Event: SuperComputing 2017 (SC17) Event Homepage: https://sc17.supercomputing.org/index.html Date: 12-17 November 2017 Location: Denver, USA Slides: https://box.psnc.pl/f/c3d5727e61 SuperComputing 2018 (SC18) Event Type: Demo Presenter(s): Lukasz Lopatowski, Ivana Golub Event: SuperComputing 2018 (SC18) Event Homepage: https://sc18.supercomputing.org/index.html Date: 13-14 November 2018 Location: Dallas, USA Slides: https://box.psnc.pl/f/6303a85328 GN4-3 Presentations given as part of the G\u00c9ANT GN4-3 project. 6 th SIG-PMV Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: 6 th SIG-PMV Event Homepage: https://wiki.geant.org/display/PMV/6 th +SIG-PMV+Meeting+@+Dublin Date: 2-3 July 2019 Location: Dublin, Ireland Slides: https://box.psnc.pl/f/d8e1ac8b26 Workshop on Network Management and Monitoring Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: Workshop on Network Management and Monitoring Event Homepage: https://wiki.geant.org/display/PUB/Workshop+on+Network+Management+and+Monitoring Date: 21-22 October 2019 Location: Copenhagen, Denmark Slides: https://box.psnc.pl/f/b496d50542 18 th STF Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: 18 th Service and Technology Forum (STF) Event Homepage: https://wiki.geant.org/display/APM/18th+STF+-+Copenhagen%2C+October+2019 Date: 22-23 October 2019 Location: Copenhagen, Denmark Slides: https://box.psnc.pl/f/a396c1b98f G\u00c9ANT Project Symposium 2020 Event Type: Presentation Presenter(s): Lukasz Lopatowski, Vojdan Kjorveziroski Event: G\u00c9ANT Project Symposium 2020 Date: 4-5 February 2020 Location: Ljubljana, Slovenia Slides: https://box.psnc.pl/f/69d463b21e GARR Workshop 2021 Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui, Damiano Verzulli Event: GARR Workshop 2021 Date: 9 th November 2021 Location: Online Slides: https://box.psnc.pl/f/546af9f0de ACOnet Conference Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: ACOnet Conference Date: 19 th November 2020 Location: Online Slides: https://box.psnc.pl/f/9e0ef03a63 NMaaS Infoshare 2020 Event Type: Infoshare Presenter(s): Lukasz Lopatowski, Pavle Vuletic, Frederic Loui, Vojdan Kjorveziroski Event: NMaaS Infoshare 2020 Date: 25 th November 2020 Location: Online Slides: Introduction , Concept, Architecture and Deployment , Application portfolio , Infrastructure requirements , G\u00c9ANT production service Workshop on Network Management and Monitoring Tools Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: Workshop on Network Management and Monitoring Tools Event Homepage: https://events.geant.org/event/387/ Date: 24 th March 2021 Location: Online Slides: https://box.psnc.pl/f/427c7340b5 Networkshop 2021 Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: Networkshop 2021 Event Homepage: https://www.jisc.ac.uk/networkshop Date: 28 th April 2021 Location: Online Slides: https://box.psnc.pl/f/d5dccc4e14 G\u00c9ANT Infoshare: Tools for Campus Network Management as a Service (CNaaS) Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: G\u00c9ANT Infoshare: Tools for Campus Network Management as a Service (CNaaS) Event Homepage: https://events/geant.org/CNaaSTools Date: 28 th April 2021 Location: Online Slides: https://box.psnc.pl/f/67cf28cd51 TNC21 Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: TNC21 Event Homepage: https://tnc21.geant.org/ Date: 21-25 June 2021 Location: Online Slides: https://box.psnc.pl/f/1132ef30aa 2 nd Global Research Platform Workshop Event Type: Presentation Presenter(s): Pavle Vuletic Event: 2 nd Global Research Platform Workshop Event Homepage: https://grpworkshop2021.theglobalresearchplatform.net/ Date: 20-24 September 2021 Location: Online Slides: https://box.psnc.pl/f/2f62dd797e GARR Workshop 2021 Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: GARR Workshop 2021 Event Homepage: https://www.eventi.garr.it/en/ws21/home Date: 8-12 November 2021 Location: Online Slides: https://box.psnc.pl/f/546af9f0de NOMS 2022 Event Type: Demo Presenter(s): Vojdan Kjorveziroski Event: NOMS 2022 Event Homepage: https://noms2022.ieee-noms.org/program/demo-sessions Date: 25-29 April 2022 Location: Budapest, Hungary Slides: https://box.psnc.pl/f/0861da6b54 JRES 2022 Event Type: Presentations Presenter(s): Vojdan Kjorveziroski Event: JRES 2022 Event Homepage: https://www.jres.org/programme/ Date: 17-20 May 2022 Location: Marseille, France Slides: https://box.psnc.pl/f/c80e51a115 TNC22 Event Type: Presentations Presenter(s): Lukasz Lopatowski, Damiano Verzulli Event: TNC22 Event Homepage: https://tnc22.geant.org/ Date: 13-17 June 2022 Location: Trieste, Italy Slides: https://box.psnc.pl/f/edf86afb7f 27 th STF Event Type: Presentations Presenter(s): Lukasz Lopatowski Event: 27 th STF Event Homepage: https://wiki.geant.org/display/APM/27 th +STF+-+Zurich%2C+October+2022 Date: 20 th October 2022 Location: Zurich, Switzerland Slides: https://box.psnc.pl/f/707bcc4440 GN5-1 Presentations given as part of the G\u00c9ANT GN5-1 project. NMaaS Infoshare 2023 Event Type: Presentations Presenter(s): Roman Lapacz, Lukasz Lopatowski, Frederic Loui, Vojdan Kjorveziroski Event: NMaaS Infoshare 2023 Event Homepage: https://events.geant.org/event/1455/overview Date: 23 rd May 2023 Location: Online Slides: https://box.psnc.pl/f/58d94370a3 Internet2 Technology Exchange (TechEx) 2023 Event Type: Presentations Presenter(s): Lukasz Lopatowski, Vojdan Kjorveziroski Event: TechEx 2023 Event Homepage: Internet2 TechEx 2023 Program Date: 18-22 September 2023 Location: Minneapolis, MN, USA Slides (incl. videos): https://box.psnc.pl/f/6b709beffd RoEduNet 2023 Event Type: Presentations Presenter(s): Jovana Vuleta-Radoi\u010di\u0107 Event: RoEduNet 2023 Event Homepage: RoEduNet 2023 Homepage Date: 21-22 September 2023 Location: Craiova, Romania Slides (incl. videos): https://static.nmaas.eu/roedunet23/NMaaS-RoEduNet.pdf NMaaS Virtual Labs for Education Event Type: Presentations Presenter(s): Vojdan Kjorveziroski, Lukasz Lopatowski Event: NMaaS Virtual Labs for Education Infoshare 2023 Event Homepage: https://events.geant.org/event/1553/ Date: 30 November 2023 Location: Online Slides (incl. videos): https://box.psnc.pl/f/8fcec7c3eb YouTube: https://www.youtube.com/watch?v=xx1NxqYTIpA G\u00c9ANT Project Symposium 2023 Event Type: Presentations / Lightning talks Presenter(s): Vojdan Kjorveziroski Event: G\u00c9ANT Project Symposium 2023 Date: 12-14 December 2023 Location: Montpellier, France Slides: https://box.psnc.pl/f/e3bdc8d26a","title":"NMaaS Presentations"},{"location":"nmaas-presentations/#nmaas-presentations","text":"","title":"NMaaS Presentations"},{"location":"nmaas-presentations/#gn4-2","text":"Presentations given as part of the G\u00c9ANT GN4-2 project.","title":"GN4-2"},{"location":"nmaas-presentations/#supercomputing-2017-sc17","text":"Event Type: Demo Presenter(s): Jakub Gutkowski, Frederic Loui, Lukasz Lopatowski Event: SuperComputing 2017 (SC17) Event Homepage: https://sc17.supercomputing.org/index.html Date: 12-17 November 2017 Location: Denver, USA Slides: https://box.psnc.pl/f/c3d5727e61","title":"SuperComputing 2017 (SC17)"},{"location":"nmaas-presentations/#supercomputing-2018-sc18","text":"Event Type: Demo Presenter(s): Lukasz Lopatowski, Ivana Golub Event: SuperComputing 2018 (SC18) Event Homepage: https://sc18.supercomputing.org/index.html Date: 13-14 November 2018 Location: Dallas, USA Slides: https://box.psnc.pl/f/6303a85328","title":"SuperComputing 2018 (SC18)"},{"location":"nmaas-presentations/#gn4-3","text":"Presentations given as part of the G\u00c9ANT GN4-3 project.","title":"GN4-3"},{"location":"nmaas-presentations/#6th-sig-pmv","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: 6 th SIG-PMV Event Homepage: https://wiki.geant.org/display/PMV/6 th +SIG-PMV+Meeting+@+Dublin Date: 2-3 July 2019 Location: Dublin, Ireland Slides: https://box.psnc.pl/f/d8e1ac8b26","title":"6th SIG-PMV"},{"location":"nmaas-presentations/#workshop-on-network-management-and-monitoring","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: Workshop on Network Management and Monitoring Event Homepage: https://wiki.geant.org/display/PUB/Workshop+on+Network+Management+and+Monitoring Date: 21-22 October 2019 Location: Copenhagen, Denmark Slides: https://box.psnc.pl/f/b496d50542","title":"Workshop on Network Management and Monitoring"},{"location":"nmaas-presentations/#18th-stf","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: 18 th Service and Technology Forum (STF) Event Homepage: https://wiki.geant.org/display/APM/18th+STF+-+Copenhagen%2C+October+2019 Date: 22-23 October 2019 Location: Copenhagen, Denmark Slides: https://box.psnc.pl/f/a396c1b98f","title":"18th STF"},{"location":"nmaas-presentations/#geant-project-symposium-2020","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Vojdan Kjorveziroski Event: G\u00c9ANT Project Symposium 2020 Date: 4-5 February 2020 Location: Ljubljana, Slovenia Slides: https://box.psnc.pl/f/69d463b21e","title":"G\u00c9ANT Project Symposium 2020"},{"location":"nmaas-presentations/#garr-workshop-2021","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui, Damiano Verzulli Event: GARR Workshop 2021 Date: 9 th November 2021 Location: Online Slides: https://box.psnc.pl/f/546af9f0de","title":"GARR Workshop 2021"},{"location":"nmaas-presentations/#aconet-conference","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: ACOnet Conference Date: 19 th November 2020 Location: Online Slides: https://box.psnc.pl/f/9e0ef03a63","title":"ACOnet Conference"},{"location":"nmaas-presentations/#nmaas-infoshare-2020","text":"Event Type: Infoshare Presenter(s): Lukasz Lopatowski, Pavle Vuletic, Frederic Loui, Vojdan Kjorveziroski Event: NMaaS Infoshare 2020 Date: 25 th November 2020 Location: Online Slides: Introduction , Concept, Architecture and Deployment , Application portfolio , Infrastructure requirements , G\u00c9ANT production service","title":"NMaaS Infoshare 2020"},{"location":"nmaas-presentations/#workshop-on-network-management-and-monitoring-tools","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: Workshop on Network Management and Monitoring Tools Event Homepage: https://events.geant.org/event/387/ Date: 24 th March 2021 Location: Online Slides: https://box.psnc.pl/f/427c7340b5","title":"Workshop on Network Management and Monitoring Tools"},{"location":"nmaas-presentations/#networkshop-2021","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: Networkshop 2021 Event Homepage: https://www.jisc.ac.uk/networkshop Date: 28 th April 2021 Location: Online Slides: https://box.psnc.pl/f/d5dccc4e14","title":"Networkshop 2021"},{"location":"nmaas-presentations/#geant-infoshare-tools-for-campus-network-management-as-a-service-cnaas","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski Event: G\u00c9ANT Infoshare: Tools for Campus Network Management as a Service (CNaaS) Event Homepage: https://events/geant.org/CNaaSTools Date: 28 th April 2021 Location: Online Slides: https://box.psnc.pl/f/67cf28cd51","title":"G\u00c9ANT Infoshare: Tools for Campus Network Management as a Service (CNaaS)"},{"location":"nmaas-presentations/#tnc21","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: TNC21 Event Homepage: https://tnc21.geant.org/ Date: 21-25 June 2021 Location: Online Slides: https://box.psnc.pl/f/1132ef30aa","title":"TNC21"},{"location":"nmaas-presentations/#2nd-global-research-platform-workshop","text":"Event Type: Presentation Presenter(s): Pavle Vuletic Event: 2 nd Global Research Platform Workshop Event Homepage: https://grpworkshop2021.theglobalresearchplatform.net/ Date: 20-24 September 2021 Location: Online Slides: https://box.psnc.pl/f/2f62dd797e","title":"2nd Global Research Platform Workshop"},{"location":"nmaas-presentations/#garr-workshop-2021_1","text":"Event Type: Presentation Presenter(s): Lukasz Lopatowski, Frederic Loui Event: GARR Workshop 2021 Event Homepage: https://www.eventi.garr.it/en/ws21/home Date: 8-12 November 2021 Location: Online Slides: https://box.psnc.pl/f/546af9f0de","title":"GARR Workshop 2021"},{"location":"nmaas-presentations/#noms-2022","text":"Event Type: Demo Presenter(s): Vojdan Kjorveziroski Event: NOMS 2022 Event Homepage: https://noms2022.ieee-noms.org/program/demo-sessions Date: 25-29 April 2022 Location: Budapest, Hungary Slides: https://box.psnc.pl/f/0861da6b54","title":"NOMS 2022"},{"location":"nmaas-presentations/#jres-2022","text":"Event Type: Presentations Presenter(s): Vojdan Kjorveziroski Event: JRES 2022 Event Homepage: https://www.jres.org/programme/ Date: 17-20 May 2022 Location: Marseille, France Slides: https://box.psnc.pl/f/c80e51a115","title":"JRES 2022"},{"location":"nmaas-presentations/#tnc22","text":"Event Type: Presentations Presenter(s): Lukasz Lopatowski, Damiano Verzulli Event: TNC22 Event Homepage: https://tnc22.geant.org/ Date: 13-17 June 2022 Location: Trieste, Italy Slides: https://box.psnc.pl/f/edf86afb7f","title":"TNC22"},{"location":"nmaas-presentations/#27th-stf","text":"Event Type: Presentations Presenter(s): Lukasz Lopatowski Event: 27 th STF Event Homepage: https://wiki.geant.org/display/APM/27 th +STF+-+Zurich%2C+October+2022 Date: 20 th October 2022 Location: Zurich, Switzerland Slides: https://box.psnc.pl/f/707bcc4440","title":"27th STF"},{"location":"nmaas-presentations/#gn5-1","text":"Presentations given as part of the G\u00c9ANT GN5-1 project.","title":"GN5-1"},{"location":"nmaas-presentations/#nmaas-infoshare-2023","text":"Event Type: Presentations Presenter(s): Roman Lapacz, Lukasz Lopatowski, Frederic Loui, Vojdan Kjorveziroski Event: NMaaS Infoshare 2023 Event Homepage: https://events.geant.org/event/1455/overview Date: 23 rd May 2023 Location: Online Slides: https://box.psnc.pl/f/58d94370a3","title":"NMaaS Infoshare 2023"},{"location":"nmaas-presentations/#internet2-technology-exchange-techex-2023","text":"Event Type: Presentations Presenter(s): Lukasz Lopatowski, Vojdan Kjorveziroski Event: TechEx 2023 Event Homepage: Internet2 TechEx 2023 Program Date: 18-22 September 2023 Location: Minneapolis, MN, USA Slides (incl. videos): https://box.psnc.pl/f/6b709beffd","title":"Internet2 Technology Exchange (TechEx) 2023"},{"location":"nmaas-presentations/#roedunet-2023","text":"Event Type: Presentations Presenter(s): Jovana Vuleta-Radoi\u010di\u0107 Event: RoEduNet 2023 Event Homepage: RoEduNet 2023 Homepage Date: 21-22 September 2023 Location: Craiova, Romania Slides (incl. videos): https://static.nmaas.eu/roedunet23/NMaaS-RoEduNet.pdf","title":"RoEduNet 2023"},{"location":"nmaas-presentations/#nmaas-virtual-labs-for-education","text":"Event Type: Presentations Presenter(s): Vojdan Kjorveziroski, Lukasz Lopatowski Event: NMaaS Virtual Labs for Education Infoshare 2023 Event Homepage: https://events.geant.org/event/1553/ Date: 30 November 2023 Location: Online Slides (incl. videos): https://box.psnc.pl/f/8fcec7c3eb YouTube: https://www.youtube.com/watch?v=xx1NxqYTIpA","title":"NMaaS Virtual Labs for Education"},{"location":"nmaas-presentations/#geant-project-symposium-2023","text":"Event Type: Presentations / Lightning talks Presenter(s): Vojdan Kjorveziroski Event: G\u00c9ANT Project Symposium 2023 Date: 12-14 December 2023 Location: Montpellier, France Slides: https://box.psnc.pl/f/e3bdc8d26a","title":"G\u00c9ANT Project Symposium 2023"},{"location":"what-is-nmaas/","text":"What is NMaaS ? NMaaS is an open source framework originally developed within the G\u00c9ANT project for orchestration of on-demand deployment of applications in a Kubernetes-based cloud environment. With a simple self-service web interface, NMaaS applications are easily deployed within an isolated tenant environment assigned to a given institution or team. An application\u2019s lifecycle (configuration updates and re-deployments) is fully managed following a GitOps approach: a specific Git repository is tightly associated with every deployed application and a set of CI/CD pipelines ensure proper re-deployments of the applications following every update on the Git master branch.","title":"What is NMaaS?"},{"location":"what-is-nmaas/#what-is-nmaas","text":"NMaaS is an open source framework originally developed within the G\u00c9ANT project for orchestration of on-demand deployment of applications in a Kubernetes-based cloud environment. With a simple self-service web interface, NMaaS applications are easily deployed within an isolated tenant environment assigned to a given institution or team. An application\u2019s lifecycle (configuration updates and re-deployments) is fully managed following a GitOps approach: a specific Git repository is tightly associated with every deployed application and a set of CI/CD pipelines ensure proper re-deployments of the applications following every update on the Git master branch.","title":"What is NMaaS?"},{"location":"blog/blog1/nmaas-101-1/","text":"[ #001 ] NMaaS-101 - \"Hello NMaaS !\" The main objective [NMaaS 101] series is to help you to get started with NMaaS service without any prior knowledge. Requirements Having an eduGain account Identified as NMaaS Domain Manager on behalf of your organisation If you are not an NREN, have your local NREN endorsement for using NMaaS Overview Network Management as a Service (NMaaS) is a G\u00c9ANT service proposed to R&E institutions. It proposes the opportunity for any R&E organisation to subscribe and deploy Network Management tools in a cloud environment via an intuitive web portal. Most of G\u00c9ANT members have their own network management software suite. Some encompasses off the shelf tools, but others are using Open Source tools as per the last SIG-NOC tools report . But all the ~40 G\u00c9ANT community members are not equal in that perspective. Some have a fully integrated sophisticated network management system, usually sophistication implies also \"home made\" and some small NRENs have difficulties to maintain existing systems. NMaaS target customer audience is: Small and Emerging NRENs Smaller NRENs may have limited resources to develop their own NMS By using a shared and supported platform , NRENs can focus on the monitoring and management of their service components Campuses NMaaS platform is ideally suited for Campus Network Management Small Organisations NMaaS supports the needs of institutional users, either on an NREN managed NMaaS platform or the centralised G\u00c9ANT platform. Distributed research projects It can be a global research project like LSST, SKA, JIVE etc. In our case I'll expose you the particular case of RARE, which is a GN4-3 research project. Rare project brief description RARE ( R outer for A cademia, R esearch & E ducation) is an ongoing effort under the G\u00c9ANT 3 rd programme which focus on determining if a routing software platform solution can fit R&E use cases. The project aims to integrate different pieces of software related to these building blocks: control plane: RARE uses FreeRouter under the hood used as the control plane component data plane: P4 is used to describe the behavioral model of RARE data plane and communication interface between the control plane and data plane: Interface compliant to P4Runtime specification ensure this function In order to validate the code produced by the RARE team we deployed a P4 Lab distributed aming various European countries: NMaaS is used as the platform to supervise all the P4 switches deployed in this Testbed. We will see in subsequent articles how NMaaS platform proposition value is helping the RARE team to deploy and use Network Management Application. NMaaS flexibility concept, enabled us to add supervision tools following KISS approach. The NMaaS platform is step by step is becoming a turn key solution for P4 switch network monitoring and supervision. Article objective This article is meant to guide you and provide you the very first mandatory steps in order to create a NMaaS domain for your organization. Let's take the example of the RARE domain, the objective is to: Explain how to trigger a domain creation How to access it In the end you should have access the NMaaS portal specifically dedicated to your organization. i.e. your organization NMaaS domain. Diagram [ #001 ] - Cookbook Prerequisites eduGain R&E IDP Your organization should be part of the eduGain R&E federated Identity provider. Designated as NMaaS domain manager internally by your organisation Usually, this is CIO role, but at least you should have been granted the privileges to deploy applications on behalf of your institution. First time login to nmaas.eu Via your favorite browser, go to nmaas.eu, you should be granted by a welcome page: Click on \"Login / Register\" button and then \"Federated login\" You should be now familiar with eduGain authentication system You should be now familiar with national eduGain authentication system During first login you are asked to submit additional account information and login again At this point you should now have access to NMaaS portal but with no domain At that precise point your connection attempt is logged by the NMaaS team and your email contact associated to your eduGain account The final step is to send a mail to nmaas@lists.geant.org This mail should briefly present your organisation, eventually your project, mention the domain name (like RARE in my case) and have the endorsement of your local NREN. With these information the NMaaS team should be able to: create the NMaaS domain you specified in your request associate your eduGain account as Domain manager for your organisation Verification Check your NMaaS domain is created and that you are Domain manager for your organization Congratulations! Your organisation has now a NMaaS domain and you are Domain manager for your organisation ! Conclusion In this article you: Had a brief introduction to the mandatory steps to complete in order to obtain a NMaaS domain NMaaS is for organisation that would like to outsource their network management maintenance activity As NRENs, we have the possibility to publish application via NMaaS portal NMaaS presents a community aspect where sharing knowledge and experience is at the heart of the concept [ #001 ] NMaaS-101 - key take-away NMaaS is a way to subscribe and deploy easily Network Management application (for now) in the cloud NMaaS customer targets are small, medium R&E institutions that would like to outsource their network management Your organisation must have an eduGain Identity Provider","title":"NMaaS-101 - \"Hello NMaaS !\""},{"location":"blog/blog1/nmaas-101-1/#001-nmaas-101-hello-nmaas","text":"The main objective [NMaaS 101] series is to help you to get started with NMaaS service without any prior knowledge.","title":"[ #001 ] NMaaS-101 - \"Hello NMaaS !\""},{"location":"blog/blog1/nmaas-101-1/#overview","text":"Network Management as a Service (NMaaS) is a G\u00c9ANT service proposed to R&E institutions. It proposes the opportunity for any R&E organisation to subscribe and deploy Network Management tools in a cloud environment via an intuitive web portal. Most of G\u00c9ANT members have their own network management software suite. Some encompasses off the shelf tools, but others are using Open Source tools as per the last SIG-NOC tools report . But all the ~40 G\u00c9ANT community members are not equal in that perspective. Some have a fully integrated sophisticated network management system, usually sophistication implies also \"home made\" and some small NRENs have difficulties to maintain existing systems. NMaaS target customer audience is: Small and Emerging NRENs Smaller NRENs may have limited resources to develop their own NMS By using a shared and supported platform , NRENs can focus on the monitoring and management of their service components Campuses NMaaS platform is ideally suited for Campus Network Management Small Organisations NMaaS supports the needs of institutional users, either on an NREN managed NMaaS platform or the centralised G\u00c9ANT platform. Distributed research projects It can be a global research project like LSST, SKA, JIVE etc. In our case I'll expose you the particular case of RARE, which is a GN4-3 research project.","title":"Overview"},{"location":"blog/blog1/nmaas-101-1/#article-objective","text":"This article is meant to guide you and provide you the very first mandatory steps in order to create a NMaaS domain for your organization. Let's take the example of the RARE domain, the objective is to: Explain how to trigger a domain creation How to access it In the end you should have access the NMaaS portal specifically dedicated to your organization. i.e. your organization NMaaS domain.","title":"Article objective"},{"location":"blog/blog1/nmaas-101-1/#diagram","text":"","title":"Diagram"},{"location":"blog/blog1/nmaas-101-1/#001-cookbook","text":"Prerequisites eduGain R&E IDP Your organization should be part of the eduGain R&E federated Identity provider. Designated as NMaaS domain manager internally by your organisation Usually, this is CIO role, but at least you should have been granted the privileges to deploy applications on behalf of your institution. First time login to nmaas.eu Via your favorite browser, go to nmaas.eu, you should be granted by a welcome page: Click on \"Login / Register\" button and then \"Federated login\" You should be now familiar with eduGain authentication system You should be now familiar with national eduGain authentication system During first login you are asked to submit additional account information and login again At this point you should now have access to NMaaS portal but with no domain At that precise point your connection attempt is logged by the NMaaS team and your email contact associated to your eduGain account The final step is to send a mail to nmaas@lists.geant.org This mail should briefly present your organisation, eventually your project, mention the domain name (like RARE in my case) and have the endorsement of your local NREN. With these information the NMaaS team should be able to: create the NMaaS domain you specified in your request associate your eduGain account as Domain manager for your organisation","title":"[ #001 ] - Cookbook"},{"location":"blog/blog1/nmaas-101-1/#verification","text":"Check your NMaaS domain is created and that you are Domain manager for your organization Congratulations! Your organisation has now a NMaaS domain and you are Domain manager for your organisation !","title":"Verification"},{"location":"blog/blog1/nmaas-101-1/#conclusion","text":"In this article you: Had a brief introduction to the mandatory steps to complete in order to obtain a NMaaS domain NMaaS is for organisation that would like to outsource their network management maintenance activity As NRENs, we have the possibility to publish application via NMaaS portal NMaaS presents a community aspect where sharing knowledge and experience is at the heart of the concept","title":"Conclusion"},{"location":"blog/blog2/nmaas-101-2/","text":"[ #002 ] NMaaS-101 - \"I can help! But... Please could you open these two doors?\"I In article #001 your organisation has now a NMaaS domain and you are the domain manager for this domain. Requirements Use existing or deploy out of band management VLAN dedicated to your equipment Use existing or deploy an OpenVPN client on a separate server or VM Knowledge to implement OpenVPN tunnels Overview As it is now NMaaS is pretty useless for your organisation even if you deploy myriads of network management applications, and this is for 2 reasons: There is no particular connectivity enabling communication between NMaaS and the equipment to be supervised in your network. There is no particular connectivity enabling communication between your laptop and NMaaS network management application GUI. Article objective In this article, we will expose what is needed in order to enable communication between the NMaaS service and your equipment in your network and what is the process to configure your VPN client in order to use NMaaS services. Let's take the example of the RARE domain, described in article #001 , the objective is to: Check that you have an out of band management network enabling reachability to all your equipment Provide information required by the NMaaS team (list of users and also the internal out of band management subnet) Use existing or deploy a new OpenVPN client that has network reachability to the network above Establish a site to site OpenVPN tunnel towards the NMaaS OpenVPN server using the site to site OpenVPN profile (coming from the NMaaS team based on the information you provide) Configure a client to site OpenVPN tunnel towards the NMaaS OpenVPN server using the client to site OpenVPN profile (coming from the NMaaS team based on the information your provide) Diagram RARE lab The picture above depicts the four p4 switches connected by 10G circuit on top of G\u00c9ANT backbone. Each switch has: One console port (aka BMC port) connected to an equipment it slef connected to DSL (ISDN or even RTC) broadband network management network Ethernet management port connected to the P4 Lab out of band management network. [ #002 ] - Cookbook Prerequisites Network Administration knowledge If this management network does not exist beforehand, you should be able to implement or have it implemented by your network operation team. Network Management network isolation This management network should be only used to convey network management traffic (i.e. no user traffic or user interaction). This is also called a Data Communication Network ( DCN ). P4 switches out of band network management VPN In the RARE network example, this network is a multipoint to multipoint L2 VPLS implemented on top of G\u00c9ANT backbone by GEANT OC team. All the switches have their management Ethernet ports connected to this VPLS MPLS VPN. In this particular case, the P4 Lab network span multiple countries, hence the VPLS implementation, it could have been a full mesh of L2VPN point to point tunnels or a L2 EVPN. Most of the case, in your organisation, the OOBM network is a simple 802.1q VLAN that spans your internal L2 network. Required information for RARE support team Equipment IPv4 subnet In the example, all switches can be reached via their management ports inside 172.16.66.6.0/24 network in the VPLS VPN. This is required so that the NMaaS team can configure the proper routing within the NMaaS environment. List of users This includes the names and email addresses of the users that should be granted access. The NMaaS team uses this information to provision the VPN connection and to generate the necessary site-to-site and client-access VPN profiles. How this information is used by the RARE support team Equipment IPv4 subnet This information will be configured at NMaaS VPN server level in order to enable routing between NMaaS service and the network used to manage your equipment. List of users This information will be used to create your OpenVPN profile. One profile specific to user. Deploy an OpenVPN client in your out of band management VPN In the RARE network example, the VPN client is a PfSense firewall using the built-in OpenVPN plugin to establish the site-to-site VPN connection between the management subnet and the NMaaS network. Once deployed you'll have to use the site to site OpenVPN profile provided by the NMaaS team in order to setup up the DCN VPN tunnel towards the NMaaS VPN server. Once setup, you should have a full connectivity between the equipment and all the NMaaS services deployed in your domain. Your namespace is implemented inside a namespace that is specific to your domain, and your domain only. All domains are isolated between each other via this concept. This ensures that only people from your organization have access to your resources along with the deployed applications in the NMaaS environment. Configure yout OpenVPN client on your laptop using provided NMaaS profile Once setup, you should have a full connectivity between your laptop and all the NMaaS services deployed in your domain. Your namespace is implemented inside a namespace that is specific to your domain, and your domain only. All domains are isolated between each other via this concept. This ensures that only people from your organization have access to your resources along with the deployed applications in the NMaaS environment. Verification Check that your NMaaS domain is created and that you are the Domain Manager for your organization In order to test your site-to-site VPN connectivity you can execute the following steps: 1. Try to access your private reverse proxy that will be responsible for providing web access to network management services deployed inside your NMaaS domain. You can first test the access to this proxy from your VPN concentrator. The IP address will be provided to you by the NMaaS team during the on-boarding process. 1. Ensure that the correct routing table entries have been pushed to your concentrator during the VPN connection phase. 2. Try to access the same reverse proxy but this time from one of your client devices that you expect to be managed by NMaaS. In order for this test to work, you will have to configure the required routes on your devices so that traffic destined for NMaaS goes through your VPN concentrator. If you use the same device acting as a VPN concentrator as your default gateway in your network, then you are all set; if not, routing entries will have to be manually added or pushed to your client devices. Depending on the software being used on the VPN concentrator, the methods for configuring it as a router so that it will accept transit traffic will vary. The most common scenario, using a simple Linux VM would require enabling the ip forwarding option on your system and setting the necessary iptables FORWARDING rules. Once setup, you should have a full connectivity between your laptop and all the NMaaS services deployed in your domain. Note on GUI-less devices Since it is expected that most of your devices that you would like to manage are only providing console access, reachability of the reverse proxy can be tested with various tools, such as curl https:// or even establishing a TCP session to port 443 using the built-in telnet client: telnet 443. The telnet approach is expected to be more widely used since the majority of the devices in use today have a telnet client available. The same steps as above can be used to verify that you have access to your dedicated NMaaS domain while connected from your workstation using the client-to-site VPN. The reverse proxy IP address remains the same, and you can open your browser and navigate to the provided IP address where you should be greeted with a 404 HTTP page. Congratulations! From this point on: You should have enabled full connectivity between your equipment and NMaaS service You should have access to NMaaS service user interface via an interactive client to site OpenVPN access. Note on GUI-less devices Since it is expected that most of your devices that you would like to manage are only providing console access, reachability of the reverse proxy can be tested with various tools, such as curl https:// or even establishing a TCP session to port 443 using the built-in telnet client: telnet 443. The telnet approach is expected to be more widely used since the majority of the devices in use today have a telnet client available. Conclusion After performing all of the above steps you should be ready to deploy your first NMaaS application and start managing your network! We will see in the next article how to deploy our first NMaaS service and consider oxidized CMDB software. In this article you: Had a brief explanation regarding the mandatory connectivity required by NMaaS One is a permanent connectivity between the OOBM network and NMaaS services in which only network management information is conveyed, also called a Data Communication Network (DCN). The second one is an on demand connectivity enabled by an interactive VPN access. [ #002 ] NMaaS-101 - key take-away An existing OOBM network has to be implemented PfSense/OpenVPN is used as OpenVPN server, you can also deploy a OpenVPN client This manual step is a bit tedious but the good news is that it has to be configured only once. Once OpenVPN accesses are setup, they are valid for all NMaaS services available in the catalog.","title":"NMaaS-101 - \"I can help! But... Please could you open these two doors?\""},{"location":"blog/blog2/nmaas-101-2/#002-nmaas-101-i-can-help-but-please-could-you-open-these-two-doorsi","text":"In article #001 your organisation has now a NMaaS domain and you are the domain manager for this domain.","title":"[ #002 ] NMaaS-101 - \"I can help! But... Please could you open these two doors?\"I"},{"location":"blog/blog2/nmaas-101-2/#overview","text":"As it is now NMaaS is pretty useless for your organisation even if you deploy myriads of network management applications, and this is for 2 reasons: There is no particular connectivity enabling communication between NMaaS and the equipment to be supervised in your network. There is no particular connectivity enabling communication between your laptop and NMaaS network management application GUI.","title":"Overview"},{"location":"blog/blog2/nmaas-101-2/#article-objective","text":"In this article, we will expose what is needed in order to enable communication between the NMaaS service and your equipment in your network and what is the process to configure your VPN client in order to use NMaaS services. Let's take the example of the RARE domain, described in article #001 , the objective is to: Check that you have an out of band management network enabling reachability to all your equipment Provide information required by the NMaaS team (list of users and also the internal out of band management subnet) Use existing or deploy a new OpenVPN client that has network reachability to the network above Establish a site to site OpenVPN tunnel towards the NMaaS OpenVPN server using the site to site OpenVPN profile (coming from the NMaaS team based on the information you provide) Configure a client to site OpenVPN tunnel towards the NMaaS OpenVPN server using the client to site OpenVPN profile (coming from the NMaaS team based on the information your provide)","title":"Article objective"},{"location":"blog/blog2/nmaas-101-2/#diagram","text":"","title":"Diagram"},{"location":"blog/blog2/nmaas-101-2/#rare-lab","text":"The picture above depicts the four p4 switches connected by 10G circuit on top of G\u00c9ANT backbone. Each switch has: One console port (aka BMC port) connected to an equipment it slef connected to DSL (ISDN or even RTC) broadband network management network Ethernet management port connected to the P4 Lab out of band management network.","title":"RARE lab"},{"location":"blog/blog2/nmaas-101-2/#002-cookbook","text":"Prerequisites Network Administration knowledge If this management network does not exist beforehand, you should be able to implement or have it implemented by your network operation team. Network Management network isolation This management network should be only used to convey network management traffic (i.e. no user traffic or user interaction). This is also called a Data Communication Network ( DCN ). P4 switches out of band network management VPN In the RARE network example, this network is a multipoint to multipoint L2 VPLS implemented on top of G\u00c9ANT backbone by GEANT OC team. All the switches have their management Ethernet ports connected to this VPLS MPLS VPN. In this particular case, the P4 Lab network span multiple countries, hence the VPLS implementation, it could have been a full mesh of L2VPN point to point tunnels or a L2 EVPN. Most of the case, in your organisation, the OOBM network is a simple 802.1q VLAN that spans your internal L2 network. Required information for RARE support team Equipment IPv4 subnet In the example, all switches can be reached via their management ports inside 172.16.66.6.0/24 network in the VPLS VPN. This is required so that the NMaaS team can configure the proper routing within the NMaaS environment. List of users This includes the names and email addresses of the users that should be granted access. The NMaaS team uses this information to provision the VPN connection and to generate the necessary site-to-site and client-access VPN profiles. How this information is used by the RARE support team Equipment IPv4 subnet This information will be configured at NMaaS VPN server level in order to enable routing between NMaaS service and the network used to manage your equipment. List of users This information will be used to create your OpenVPN profile. One profile specific to user. Deploy an OpenVPN client in your out of band management VPN In the RARE network example, the VPN client is a PfSense firewall using the built-in OpenVPN plugin to establish the site-to-site VPN connection between the management subnet and the NMaaS network. Once deployed you'll have to use the site to site OpenVPN profile provided by the NMaaS team in order to setup up the DCN VPN tunnel towards the NMaaS VPN server. Once setup, you should have a full connectivity between the equipment and all the NMaaS services deployed in your domain. Your namespace is implemented inside a namespace that is specific to your domain, and your domain only. All domains are isolated between each other via this concept. This ensures that only people from your organization have access to your resources along with the deployed applications in the NMaaS environment. Configure yout OpenVPN client on your laptop using provided NMaaS profile Once setup, you should have a full connectivity between your laptop and all the NMaaS services deployed in your domain. Your namespace is implemented inside a namespace that is specific to your domain, and your domain only. All domains are isolated between each other via this concept. This ensures that only people from your organization have access to your resources along with the deployed applications in the NMaaS environment.","title":"[ #002 ] - Cookbook"},{"location":"blog/blog2/nmaas-101-2/#verification","text":"Check that your NMaaS domain is created and that you are the Domain Manager for your organization In order to test your site-to-site VPN connectivity you can execute the following steps: 1. Try to access your private reverse proxy that will be responsible for providing web access to network management services deployed inside your NMaaS domain. You can first test the access to this proxy from your VPN concentrator. The IP address will be provided to you by the NMaaS team during the on-boarding process. 1. Ensure that the correct routing table entries have been pushed to your concentrator during the VPN connection phase. 2. Try to access the same reverse proxy but this time from one of your client devices that you expect to be managed by NMaaS. In order for this test to work, you will have to configure the required routes on your devices so that traffic destined for NMaaS goes through your VPN concentrator. If you use the same device acting as a VPN concentrator as your default gateway in your network, then you are all set; if not, routing entries will have to be manually added or pushed to your client devices. Depending on the software being used on the VPN concentrator, the methods for configuring it as a router so that it will accept transit traffic will vary. The most common scenario, using a simple Linux VM would require enabling the ip forwarding option on your system and setting the necessary iptables FORWARDING rules. Once setup, you should have a full connectivity between your laptop and all the NMaaS services deployed in your domain.","title":"Verification"},{"location":"blog/blog2/nmaas-101-2/#conclusion","text":"After performing all of the above steps you should be ready to deploy your first NMaaS application and start managing your network! We will see in the next article how to deploy our first NMaaS service and consider oxidized CMDB software. In this article you: Had a brief explanation regarding the mandatory connectivity required by NMaaS One is a permanent connectivity between the OOBM network and NMaaS services in which only network management information is conveyed, also called a Data Communication Network (DCN). The second one is an on demand connectivity enabled by an interactive VPN access.","title":"Conclusion"},{"location":"blog/blog3/nmaas-101-3/","text":"[ #003 ] NMaaS-101 - \"My name is Oxidized and I'm a nifty configuration management tool\" In article #001 and #002 you essentially created a NMaaS domain and enabled connectivity between your dedicated and isolated domain to your out of band management equipment network. Requirements Completed #001 Completed #002 Basic knowledge related to configuration management Overview We are going to deploy our first NMaaS service for your organisation: Oxidized Article objective This is done in 2 steps: Oxidized application deployment via the NMaaS portal Oxidized configuration specific to RARE domain Diagram NMaaS portal: Oxidized [#003] - Cookbook Prerequisites Having completed #001 Having completed #002 Oxidized application deployment Once your domain is created and associated to your account, log into https://nmaas.eu as in #001 select Oxidized application select \"Deploy\" choose a name for your service instance, in our case we chose: \"p4-oxi-srv\" The name has a particular importance as it will dynamically create a FQDN for the NMaaS service in the form: <service_name>.<domain>.nmaas.eu In my example it is: oxidized.rare.nmaas.eu fill in the mandatory basic configuration information Oxidized access username we chose: oxidized Oxidized access password we chose: oxidized Device access username (login used by Oxidized to access the equipment via SSH) we chose: rare Device access password (password used to access the equipment via SSH) we chose: rare Device (IP address) we chose: 172.16.26.103,172.16.26.105,172.16.26.108,172.16.26.109 VPN Connectivity Warning It is important to note that you'll be connected inside a dedicated VPN so you'll be isolated from the outside world as if you were running your own Out of band management network. So we can assume that your domain is secured. Congratulation. You should have completed Oxidized deployment Oxidized application specific configuration In the RARE domain we had a specific requirement that requires a specific profiles for the RARE network equipment. We are using then NMaaS configuration feature (also refer to NMaaS configuration process), which actually will provide us the way to alter Oxidized configuration software. From the NMaaS portal service instance page select \"Update configuration\" button you should be provided a git command that will let you clone your Oxidized NMaaS configuration repository Oxidized base configuration 1 2 3 4 5 cd base ls -l total 16 -rw-r--r-- 1 loui staff 734 Jul 30 11:12 config -rw-r--r-- 1 loui staff 141 Jul 30 11:12 router.db Oxidized config file sample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 --- username: rare password: rare model: rare interval: 600 use_syslog: false debug: false threads: 30 timeout: 20 retries: 3 prompt: !ruby/regexp /([\\w.@-]+[#>]\\s?)$/ rest: 0.0.0.0:8888 vars: {} groups: wedge-bf100-32x: vars: ssh_port: 2001 pid: \"/storage/pid\" input: default: ssh debug: false ssh: secure: false output: default: git file: directory: \"/storage/configs\" git: single_repo: true user: oxidized email: oxidized@man.poznan.pl repo: \"/storage/oxidized.git\" source: default: csv csv: file: \"/root/.config/oxidized/router.db\" delimiter: !ruby/regexp /:/ map: name: 0 model: 1 group: 2 model_map: rare: rare cisco: ios juniper: junos Oxidized rare.rb file sample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class RARE < Oxidized::Model prompt /([\\w.@()-]+[#>]\\s?)$/ #prompt /^([\\w.@()-]+[#>]\\s?)$/ comment '! ' cmd :all do |cfg| # cfg.gsub! /\\cH+\\s{8}/, '' # example how to handle pager cfg.gsub! /\\cH+/, '' # example how to handle pager get rid of errors for commands that don't work on some devices cfg.gsub! /^% Invalid input detected at '\\^' marker\\.$|^\\s+\\^$/, '' cfg.cut_both end cmd :secret do |cfg| cfg.gsub! /^(snmp-server community).*/, '\\\\1 <configuration removed>' cfg.gsub! /^(snmp-server host \\S+( vrf \\S+)?( version (1|2c|3))?)\\s+\\S+((\\s+\\S*)*)\\s*/, '\\\\1 <secret hidden> \\\\5' cfg.gsub! /^(username .+ (password|secret) \\d) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(enable (password|secret)( level \\d+)? \\d) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+(?:password|secret)) (?:\\d )?\\S+/, '\\\\1 <secret hidden>' cfg.gsub! /^(.*wpa-psk ascii \\d) (\\S+)/, '\\\\1 <secret hidden>' cfg.gsub! /^(.*key 7) (\\d.+)/, '\\\\1 <secret hidden>' cfg.gsub! /^(tacacs-server (.+ )?key) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(crypto isakmp key) (\\S+) (.*)/, '\\\\1 <secret hidden> \\\\3' cfg.gsub! /^(\\s+ip ospf message-digest-key \\d+ md5) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+ip ospf authentication-key) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+neighbor \\S+ password) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+vrrp \\d+ authentication text) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+standby \\d+ authentication) .{1,8}$/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+standby \\d+ authentication md5 key-string) .+?( timeout \\d+)?$/, '\\\\1 <secret hidden> \\\\2' cfg.gsub! /^(\\s+key-string) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^((tacacs|radius) server [^\\n]+\\n(\\s+[^\\n]+\\n)*\\s+key) [^\\n]+$/m, '\\1 <secret hidden>' cfg end cmd 'show platform' do |cfg| comment \"TEST: show platform\" comments = [] comments << cfg.lines.first lines = cfg.lines lines.each_with_index do |line, i| if line !~ /^mem:|^uptime:/ comments << line.strip! end end comments << \"\\n\" comment comments.join \"\\n\" end cmd 'show interfaces description' do |cfg| comment cfg end cmd 'show running-config' do |cfg| cfg = cfg.each_line.to_a[3..-1] cfg = cfg.reject { |line| line.match /^ntp clock-period / }.join cfg.gsub! /^Current configuration : [^\\n]*\\n/, '' cfg.gsub! /^ tunnel mpls traffic-eng bandwidth[^\\n]*\\n*( (?: [^\\n]*\\n*)* tunnel mpls traffic-eng auto-bw)/mx, '\\1' cfg end cfg :telnet do username /^Username:/i password /^Password:/i end cfg :telnet, :ssh do # preferred way to handle additional passwords post_login do if vars(:enable) == true cmd \"enable\" elsif vars(:enable) cmd \"enable\", /^[pP]assword:/ cmd vars(:enable) end end post_login 'terminal length 0' post_login 'terminal width 0' pre_logout 'exit' end end Oxidized router.db file sampl 172.16.26.103:rare:wedge-bf100-32x 172.16.26.105:rare:wedge-bf100-32x 172.16.26.108:rare:wedge-bf100-32x 172.16.26.109:rare:wedge-bf100-32x Oxidized model files 1 2 3 4 5 cd model ls -l total 16 -rw-r--r-- 1 loui staff 2977 Jul 30 11:13 rare.rb -rw-r--r-- 1 loui staff 69 Jul 30 11:10 readme.txt Oxidized model configuration Oxidized has the property to associate a model file specific to your equipment. In RARE context we needed to define a specific profile specifying the prompt used and also the command of interest during configuration versioning process. Verification Check that you can access Oxidized using: . .nmaas.eu Congratulations! You have deployed your first NMaaS service specifically for your domain ! Conclusion In this article you: You have deployed a powerful CMDB software for your organisation You have learned how to apply specific configurations to it in order to match your requirements [ #003 ] NMaaS-101 - key take-away Deploying a NMaaS service is as easy as deploying an application on your mobile phone, you just have to log into the NMaaS portal and of course have the sufficient privileges to deploy application for your domain Deploying an application is a 2 steps process deploy the application via the portal configure the application via git tool Even if Oxidized deployment by NMaaS is made easy, it is mandatory to have a strong knowledge of the tool implemented. In this case, it is of course essential to read documentation from Oxidized GitHub .","title":"NMaaS-101 - \"My name is Oxidized and I'm a nifty configuration management tool\""},{"location":"blog/blog3/nmaas-101-3/#003-nmaas-101-my-name-is-oxidized-and-im-a-nifty-configuration-management-tool","text":"In article #001 and #002 you essentially created a NMaaS domain and enabled connectivity between your dedicated and isolated domain to your out of band management equipment network.","title":"[ #003 ] NMaaS-101 - \"My name is Oxidized and I'm a nifty configuration management tool\""},{"location":"blog/blog3/nmaas-101-3/#overview","text":"We are going to deploy our first NMaaS service for your organisation: Oxidized","title":"Overview"},{"location":"blog/blog3/nmaas-101-3/#article-objective","text":"This is done in 2 steps: Oxidized application deployment via the NMaaS portal Oxidized configuration specific to RARE domain","title":"Article objective"},{"location":"blog/blog3/nmaas-101-3/#diagram","text":"NMaaS portal: Oxidized","title":"Diagram"},{"location":"blog/blog3/nmaas-101-3/#003-cookbook","text":"Prerequisites Having completed #001 Having completed #002 Oxidized application deployment Once your domain is created and associated to your account, log into https://nmaas.eu as in #001 select Oxidized application select \"Deploy\" choose a name for your service instance, in our case we chose: \"p4-oxi-srv\" The name has a particular importance as it will dynamically create a FQDN for the NMaaS service in the form: <service_name>.<domain>.nmaas.eu In my example it is: oxidized.rare.nmaas.eu fill in the mandatory basic configuration information Oxidized access username we chose: oxidized Oxidized access password we chose: oxidized Device access username (login used by Oxidized to access the equipment via SSH) we chose: rare Device access password (password used to access the equipment via SSH) we chose: rare Device (IP address) we chose: 172.16.26.103,172.16.26.105,172.16.26.108,172.16.26.109 VPN Connectivity Warning It is important to note that you'll be connected inside a dedicated VPN so you'll be isolated from the outside world as if you were running your own Out of band management network. So we can assume that your domain is secured. Congratulation. You should have completed Oxidized deployment Oxidized application specific configuration In the RARE domain we had a specific requirement that requires a specific profiles for the RARE network equipment. We are using then NMaaS configuration feature (also refer to NMaaS configuration process), which actually will provide us the way to alter Oxidized configuration software. From the NMaaS portal service instance page select \"Update configuration\" button you should be provided a git command that will let you clone your Oxidized NMaaS configuration repository Oxidized base configuration 1 2 3 4 5 cd base ls -l total 16 -rw-r--r-- 1 loui staff 734 Jul 30 11:12 config -rw-r--r-- 1 loui staff 141 Jul 30 11:12 router.db Oxidized config file sample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 --- username: rare password: rare model: rare interval: 600 use_syslog: false debug: false threads: 30 timeout: 20 retries: 3 prompt: !ruby/regexp /([\\w.@-]+[#>]\\s?)$/ rest: 0.0.0.0:8888 vars: {} groups: wedge-bf100-32x: vars: ssh_port: 2001 pid: \"/storage/pid\" input: default: ssh debug: false ssh: secure: false output: default: git file: directory: \"/storage/configs\" git: single_repo: true user: oxidized email: oxidized@man.poznan.pl repo: \"/storage/oxidized.git\" source: default: csv csv: file: \"/root/.config/oxidized/router.db\" delimiter: !ruby/regexp /:/ map: name: 0 model: 1 group: 2 model_map: rare: rare cisco: ios juniper: junos Oxidized rare.rb file sample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class RARE < Oxidized::Model prompt /([\\w.@()-]+[#>]\\s?)$/ #prompt /^([\\w.@()-]+[#>]\\s?)$/ comment '! ' cmd :all do |cfg| # cfg.gsub! /\\cH+\\s{8}/, '' # example how to handle pager cfg.gsub! /\\cH+/, '' # example how to handle pager get rid of errors for commands that don't work on some devices cfg.gsub! /^% Invalid input detected at '\\^' marker\\.$|^\\s+\\^$/, '' cfg.cut_both end cmd :secret do |cfg| cfg.gsub! /^(snmp-server community).*/, '\\\\1 <configuration removed>' cfg.gsub! /^(snmp-server host \\S+( vrf \\S+)?( version (1|2c|3))?)\\s+\\S+((\\s+\\S*)*)\\s*/, '\\\\1 <secret hidden> \\\\5' cfg.gsub! /^(username .+ (password|secret) \\d) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(enable (password|secret)( level \\d+)? \\d) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+(?:password|secret)) (?:\\d )?\\S+/, '\\\\1 <secret hidden>' cfg.gsub! /^(.*wpa-psk ascii \\d) (\\S+)/, '\\\\1 <secret hidden>' cfg.gsub! /^(.*key 7) (\\d.+)/, '\\\\1 <secret hidden>' cfg.gsub! /^(tacacs-server (.+ )?key) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(crypto isakmp key) (\\S+) (.*)/, '\\\\1 <secret hidden> \\\\3' cfg.gsub! /^(\\s+ip ospf message-digest-key \\d+ md5) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+ip ospf authentication-key) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+neighbor \\S+ password) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+vrrp \\d+ authentication text) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+standby \\d+ authentication) .{1,8}$/, '\\\\1 <secret hidden>' cfg.gsub! /^(\\s+standby \\d+ authentication md5 key-string) .+?( timeout \\d+)?$/, '\\\\1 <secret hidden> \\\\2' cfg.gsub! /^(\\s+key-string) .+/, '\\\\1 <secret hidden>' cfg.gsub! /^((tacacs|radius) server [^\\n]+\\n(\\s+[^\\n]+\\n)*\\s+key) [^\\n]+$/m, '\\1 <secret hidden>' cfg end cmd 'show platform' do |cfg| comment \"TEST: show platform\" comments = [] comments << cfg.lines.first lines = cfg.lines lines.each_with_index do |line, i| if line !~ /^mem:|^uptime:/ comments << line.strip! end end comments << \"\\n\" comment comments.join \"\\n\" end cmd 'show interfaces description' do |cfg| comment cfg end cmd 'show running-config' do |cfg| cfg = cfg.each_line.to_a[3..-1] cfg = cfg.reject { |line| line.match /^ntp clock-period / }.join cfg.gsub! /^Current configuration : [^\\n]*\\n/, '' cfg.gsub! /^ tunnel mpls traffic-eng bandwidth[^\\n]*\\n*( (?: [^\\n]*\\n*)* tunnel mpls traffic-eng auto-bw)/mx, '\\1' cfg end cfg :telnet do username /^Username:/i password /^Password:/i end cfg :telnet, :ssh do # preferred way to handle additional passwords post_login do if vars(:enable) == true cmd \"enable\" elsif vars(:enable) cmd \"enable\", /^[pP]assword:/ cmd vars(:enable) end end post_login 'terminal length 0' post_login 'terminal width 0' pre_logout 'exit' end end Oxidized router.db file sampl 172.16.26.103:rare:wedge-bf100-32x 172.16.26.105:rare:wedge-bf100-32x 172.16.26.108:rare:wedge-bf100-32x 172.16.26.109:rare:wedge-bf100-32x Oxidized model files 1 2 3 4 5 cd model ls -l total 16 -rw-r--r-- 1 loui staff 2977 Jul 30 11:13 rare.rb -rw-r--r-- 1 loui staff 69 Jul 30 11:10 readme.txt Oxidized model configuration Oxidized has the property to associate a model file specific to your equipment. In RARE context we needed to define a specific profile specifying the prompt used and also the command of interest during configuration versioning process.","title":"[#003] - Cookbook"},{"location":"blog/blog3/nmaas-101-3/#verification","text":"Check that you can access Oxidized using: . .nmaas.eu Congratulations! You have deployed your first NMaaS service specifically for your domain !","title":"Verification"},{"location":"blog/blog3/nmaas-101-3/#conclusion","text":"In this article you: You have deployed a powerful CMDB software for your organisation You have learned how to apply specific configurations to it in order to match your requirements [ #003 ] NMaaS-101 - key take-away Deploying a NMaaS service is as easy as deploying an application on your mobile phone, you just have to log into the NMaaS portal and of course have the sufficient privileges to deploy application for your domain Deploying an application is a 2 steps process deploy the application via the portal configure the application via git tool Even if Oxidized deployment by NMaaS is made easy, it is mandatory to have a strong knowledge of the tool implemented. In this case, it is of course essential to read documentation from Oxidized GitHub .","title":"Conclusion"},{"location":"blog/blog4/nmaas-101-4/","text":"[ #004 ] NMaaS-101 - \"Prometheus\" In article #001 and #002 you essentially created a NMaaS domain and enabled connectivity between your dedicated and isolated domain to your out of band management equipment network. Requirements Completed #001 Completed #002 Basic knowledge related to configuration management Overview In this post, we are going to deploy an interesting and popular Metric collector in the micro-service world: Prometheus. For those who would like an introduction to Prometheus, please refer to this post from the RARE project blog . Article objective This is done in 2 steps: Prometheus application deployment via the NMaaS portal Prometheus configuration specific to RARE domain Diagram NMaaS portal: Oxidized [#003] - Cookbook Prerequisites Having completed #001 Having completed #002 Prometheus application deployment Once your domain is created and associated to your account, log into https://nmaas.eu as in #001 select Prometheus application select \"Deploy\" choose a name for your service instance, in our case we chose: \"prm\" The name has a particular importance as it will dynamically create a FQDN for the NMaaS service in the form: <service_name>.<domain>.nmaas.eu In my example it is: prm.rare.nmaas.eu Click on configure (blue bottom on the lefthand side) information Prometheus access username we chose: prometheus Prometheus access password we chose: prometheus Global scrape As per RARE blog article : 15s Global evaluation As per RARE blog article : 30s Jobs Job name: router Device (IP address) we chose: 192.168.0.1:9001 Apply configuration VPN Connectivity Warning It is important to note that you'll be connected inside a dedicated VPN so you'll be isolated from the outside world as if you were running your own Out of band management network. So we can assume that your domain is secured. Prometheus micro-service status will be update to \" Activation in progress \" After few minutes the deployment status will be set to \" Active \" Congratulation. You should have completed Prometheus deployment Prometheus application specific configuration In the RARE domain we have specifically configured a Prometheus agent on each P4 switch. In the configuration above we have only configured a dummy IP address. Subsequent configuration will be done through the usual NMaaS micro-service-configuration workflow using git . (Similar to Oxidized post ) We are using then NMaaS configuration feature (also refer to NMaaS configuration process ), which actually will provide us the way to alter Prometheus configuration software. From the NMaaS portal service instance page select \"configuration\" entry from the drop-down list you should be provided a git command that will let you clone your Prometheus NMaaS configuration repository From a terminal, clone oxidized configuration repository 1 2 3 4 5 6 7 git clone ssh://git@gitlab.nmaas.eu/groups-rare/rare-prometheus-382.git < enter my SSH credientials ... > cd rare-prometheus-382 \u256d\u2500[05/6/21|11:18:47]loui@MacBook-Pro-de-Frederic.local ~/rare-prometheus-382 \u2039master\u203a \u2570\u2500\u27a4 ls -l total 8 -rw-r--r-- 1 loui staff 297 May 6 11:17 prometheus.yml You can now configure prometheus with your target config and adjust it as you see fit For more information please refer to Prometheus official documentation . In our case we will use prometheus configuration from the RARE blog post . From a terminal, clone oxidized configuration repository 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 global: scrape_interval: 15s evaluation_interval: 30s alerting: alertmanagers: - static_configs: - targets: rule_files: scrape_configs: - job_name: 'router' metrics_path: /metrics scrape_interval: 15s static_configs: - targets: ['192.168.0.1:9001','192.168.0.2:9001'] labels: Verification Check that you can access Prometheus using: <svc-name>.<domain>.nmaas.eu Access the application \"Access the application\" button shortcut it will lead you to a dynamic FQDN: https://prm.rare.nmaas.eu You have now access to Prometheus console You can check if the configured agent is reachable In this case you have a problem to reach the Prometheus agent. (Check connectivity to the configured Agent 192.168.0.1:9001 in prometheus.yml) Congratulations! You have deployed and configured your Prometheus NMaaS service specifically for your domain ! Conclusion In this article you: You have deployed a powerful and flexible metric collector for your organisation Prometheus uses PUSH model similar to SNMP so every scrape minutes it will interrogate all the configured agents. You have learned how to apply specific configurations to it in order to match your requirements In this example, we used RARE/freeRtr prometheus agent whose configuration is described here . In your case, you agent will have its own different configuration (different IP, port, job name and metrics ) [ #004 ] NMaaS-101 - key take-away Deploying a NMaaS service is as easy as deploying an application on your mobile phone, you just have to log into the NMaaS portal and of course have the sufficient privileges to deploy application for your domain Deploying an application is a 2 steps process deploy the application via the portal configure the application via git tool Even if Prometheus deployment by NMaaS is made easy, it is mandatory to have a strong knowledge of the tool implemented. In this case, it is of course essential to read documentation from Prometheus web site.","title":"NMaaS-101 - \"Prometheus\""},{"location":"blog/blog4/nmaas-101-4/#004-nmaas-101-prometheus","text":"In article #001 and #002 you essentially created a NMaaS domain and enabled connectivity between your dedicated and isolated domain to your out of band management equipment network.","title":"[ #004 ] NMaaS-101 - \"Prometheus\""},{"location":"blog/blog4/nmaas-101-4/#overview","text":"In this post, we are going to deploy an interesting and popular Metric collector in the micro-service world: Prometheus. For those who would like an introduction to Prometheus, please refer to this post from the RARE project blog .","title":"Overview"},{"location":"blog/blog4/nmaas-101-4/#article-objective","text":"This is done in 2 steps: Prometheus application deployment via the NMaaS portal Prometheus configuration specific to RARE domain","title":"Article objective"},{"location":"blog/blog4/nmaas-101-4/#diagram","text":"NMaaS portal: Oxidized","title":"Diagram"},{"location":"blog/blog4/nmaas-101-4/#003-cookbook","text":"Prerequisites Having completed #001 Having completed #002 Prometheus application deployment Once your domain is created and associated to your account, log into https://nmaas.eu as in #001 select Prometheus application select \"Deploy\" choose a name for your service instance, in our case we chose: \"prm\" The name has a particular importance as it will dynamically create a FQDN for the NMaaS service in the form: <service_name>.<domain>.nmaas.eu In my example it is: prm.rare.nmaas.eu Click on configure (blue bottom on the lefthand side) information Prometheus access username we chose: prometheus Prometheus access password we chose: prometheus Global scrape As per RARE blog article : 15s Global evaluation As per RARE blog article : 30s Jobs Job name: router Device (IP address) we chose: 192.168.0.1:9001 Apply configuration VPN Connectivity Warning It is important to note that you'll be connected inside a dedicated VPN so you'll be isolated from the outside world as if you were running your own Out of band management network. So we can assume that your domain is secured. Prometheus micro-service status will be update to \" Activation in progress \" After few minutes the deployment status will be set to \" Active \" Congratulation. You should have completed Prometheus deployment Prometheus application specific configuration In the RARE domain we have specifically configured a Prometheus agent on each P4 switch. In the configuration above we have only configured a dummy IP address. Subsequent configuration will be done through the usual NMaaS micro-service-configuration workflow using git . (Similar to Oxidized post ) We are using then NMaaS configuration feature (also refer to NMaaS configuration process ), which actually will provide us the way to alter Prometheus configuration software. From the NMaaS portal service instance page select \"configuration\" entry from the drop-down list you should be provided a git command that will let you clone your Prometheus NMaaS configuration repository From a terminal, clone oxidized configuration repository 1 2 3 4 5 6 7 git clone ssh://git@gitlab.nmaas.eu/groups-rare/rare-prometheus-382.git < enter my SSH credientials ... > cd rare-prometheus-382 \u256d\u2500[05/6/21|11:18:47]loui@MacBook-Pro-de-Frederic.local ~/rare-prometheus-382 \u2039master\u203a \u2570\u2500\u27a4 ls -l total 8 -rw-r--r-- 1 loui staff 297 May 6 11:17 prometheus.yml You can now configure prometheus with your target config and adjust it as you see fit For more information please refer to Prometheus official documentation . In our case we will use prometheus configuration from the RARE blog post . From a terminal, clone oxidized configuration repository 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 global: scrape_interval: 15s evaluation_interval: 30s alerting: alertmanagers: - static_configs: - targets: rule_files: scrape_configs: - job_name: 'router' metrics_path: /metrics scrape_interval: 15s static_configs: - targets: ['192.168.0.1:9001','192.168.0.2:9001'] labels:","title":"[#003] - Cookbook"},{"location":"blog/blog4/nmaas-101-4/#verification","text":"Check that you can access Prometheus using: <svc-name>.<domain>.nmaas.eu Access the application \"Access the application\" button shortcut it will lead you to a dynamic FQDN: https://prm.rare.nmaas.eu You have now access to Prometheus console You can check if the configured agent is reachable In this case you have a problem to reach the Prometheus agent. (Check connectivity to the configured Agent 192.168.0.1:9001 in prometheus.yml) Congratulations! You have deployed and configured your Prometheus NMaaS service specifically for your domain !","title":"Verification"},{"location":"blog/blog4/nmaas-101-4/#conclusion","text":"In this article you: You have deployed a powerful and flexible metric collector for your organisation Prometheus uses PUSH model similar to SNMP so every scrape minutes it will interrogate all the configured agents. You have learned how to apply specific configurations to it in order to match your requirements In this example, we used RARE/freeRtr prometheus agent whose configuration is described here . In your case, you agent will have its own different configuration (different IP, port, job name and metrics ) [ #004 ] NMaaS-101 - key take-away Deploying a NMaaS service is as easy as deploying an application on your mobile phone, you just have to log into the NMaaS portal and of course have the sufficient privileges to deploy application for your domain Deploying an application is a 2 steps process deploy the application via the portal configure the application via git tool Even if Prometheus deployment by NMaaS is made easy, it is mandatory to have a strong knowledge of the tool implemented. In this case, it is of course essential to read documentation from Prometheus web site.","title":"Conclusion"},{"location":"guides/application-manager-guide/","text":"Application Manager Guide Warning This guide is currently a work in progress. Some sections might be missing or contain incomplete information. Introduction The information about applications supported by given NMaaS instance is managed from the NMaaS Portal level. A dedicated wizard composed of several forms was developed to ease this management operation and guide the user (with appropriate role assigned) through the process of adding new or updating existing application information. In order to access the applications management area user should open the Settings drop down menu available on the top navigation bar and click the Applications button. The main view lists all the applications available in this particular NMaaS installation or a filtered list of applications to which a given user has management access. For each application its Name and Owner user is provided. When an application entry is clicked subsequent information about available versions of particular application and their status is displayed. The application version statuses are the following: New - status assigned automatically after new version is submitted (application not yet visible for Portal users) Active - version displayed in the Portal and available for subscription and deployment Disabled - version displayed in the Portal but not available for deployment Deleted - version hidden in the Portal (including the Administrator panel) Info Only applications with at least one Active or Disabled version are visible in the Portal Transitions between application version statuses can be performed only by the System administrator When a version is marked as Disabled its deployed instances are not affected, but no new deployments can be triggered From this view an Application manager can perform the following actions: initiate the process of adding new application to the portfolio by clicking on the Add button located above the list of applications edit general information about an application by selecting Edit option from the application context menu (gearwheel icon next to the application name) add new version of given application by selecting Add new version option from the application context menu edit information about particular application version by selecting the Edit option from the application version context menu (gearwheel icon next to the application version identifier) Info The applications from the NMaaS portfolio are being deployed on Kubernetes. To this end each application has to be containerized and described in the form of a Helm chart. Info The application administration option is available only for users with System administrator or Application manager roles assigned. The Application manager has the possibility to add new applications to the portfolio as well as to manage applications user owns (meaning applications added by the user or for which the System administrator assigned the user as an owner. Adding New Application Once granted the Application manager role user is able to submit new applications to the system. A complete application definition in the system comprises on one side a general set of information about the application (e.g. its name and logo) and on the other side data specific to particular version of the application (e.g. its deployment details). It is assumed that the general part is common for all the versions of the applications however the specific details may vary for different versions. The required data will need to be provided on a number of forms. First user is requested to confirm that he has the right to publish particular application on NMaaS (for example by verifying its license conditions). In order to proceed user should check the checkbox and click on the Next button. Warning If users leaves the new application wizard before submitting the information on the last form all the entered data will be lost Info A newly pushed application needs to be reviewed and approved by the System administrator . Only then is becomes Active and available in the portfolio Providing Application Basic Information The first basic information form comprises the following fields: Name (mandatory) - name of the Application (max 30 characters) Version (mandatory) - version of the Application License - license applied to the original Application (e.g. Apache 2.0) License URL - link to the respective license text Project website - link to the original website with additional information about the Application Link to source code - link to the repository with source code of the Application (e.g. on GitHub) Link to project issues - link to the website for publishing and tracking issues related with Application (e.g. on GitHub) NMaaS Documentation URL - link to a custom NMaaS provider website containing additional documentation about the Application (e.g. deployment options and consideration) Select tags for application (mandatory) - selection of tags that best describe the Application from an existing list A dd new tags for your application - names of new (not found on the drop down selector) tags to be assigned to the Application (multiple tags can be provided, each tag needs to be confirmed with Enter ) Info Throughout the wizard filling in some fields is mandatory and entering data in in the rest is optional. The mandatory fields are marked with a star (*) next to the field name. In order to proceed user should click on the Next button. Providing Application Logo and Screenshots The second form allows the user to upload a Logo and a number of Screenshots or example images suitable for given Application (for presentation in the Portal). Once Choose button is clicked a file selection window is displayed allowing the user to browse and select a file or multiple files from his local machine. Info Multiple graphical file formats are supported including svg , png and jpg In order to proceed user should click on the Next button. Providing Application Descriptions Using the third form user is requested to enter two types of description of the Application to be used and displayed in different areas in the Portal: Brief description - few words long description of the Application presented on the main Portal view with all the applications under the Application logo (max 60 characters) Full description - complete description of the Application (e.g. purpose and main features) By default only input fields for texts in English are displayed. Dedicated fields for other languages can be displayed by checking given language on the drop down selector Select optional languages . Info It is mandatory to provide descriptions for the English language. Optionally appropriate texts can be provided for other supported languages Providing Application Deployment Specification The fourth form enables the Application manager to enter all the necessary information to allow for a fully automated deployment of new instances of particular Application. NMaaS applications are deployed using Helm thus is it mandatory to provide the respective Helm chart details and all the custom parameters to be passed as values during Helm chart installation. General information fields Chart name (mandatory) - name of the Helm chart (e.g. nmaas-zabbix ) prefixed with the name of appropriate Helm chart repository if one different from the default is used (e.g. netbox/netbox ) Chart version (mandatory) - version of the Helm chart (e.g. 4.0.1 ) Helm Chart repository name - name of a custom repository to be added that hosts Application Helm chart (e.g. netbox ) Helm Chart repository URL address - URL of the respective custom Helm chart repository (e.g. https://charts.boo.tc ) Main component name - if Application installation comprises multiple deployment or statefulset objects its necessary to indicate which object should be considered as the main one (one that is used to verify if the whole Application is up and - running). An example would be server used to point to the proper deployment of the these two examples pllab-zabbix-624-server and pllab-zabbix-624-web (this functionality assumes that names of all objects created for given Helm chart installation contain the release name string) Expose web user interface (checkbox) - if checked indicates that given Application exposes a web user interface Allow SSH Access (checkbox) - if checked indicates that for given Application a direct shell access to running container should be enabled Info In general enabling user direct access to running containers shell of given Application is strongly discouraged. However, in order to allow such access and mitigate at least some of the risks, a built-in shell terminal was made available in the Portal. Global Deploy Parameters DOMAIN_CODENAME = zabbixServer.service.annotations.\"metallb\\.universe\\.tf/address-pool\"=%VALUE% Static Global Deploy Parameters image.tag = 7.02 properties.database.password = %RANDOM_STRING_12% Storage Volumes Access Methods Providing Application Configuration Specification Adding New Application Version","title":"Application Manager Guide"},{"location":"guides/application-manager-guide/#application-manager-guide","text":"Warning This guide is currently a work in progress. Some sections might be missing or contain incomplete information.","title":"Application Manager Guide"},{"location":"guides/application-manager-guide/#introduction","text":"The information about applications supported by given NMaaS instance is managed from the NMaaS Portal level. A dedicated wizard composed of several forms was developed to ease this management operation and guide the user (with appropriate role assigned) through the process of adding new or updating existing application information. In order to access the applications management area user should open the Settings drop down menu available on the top navigation bar and click the Applications button. The main view lists all the applications available in this particular NMaaS installation or a filtered list of applications to which a given user has management access. For each application its Name and Owner user is provided. When an application entry is clicked subsequent information about available versions of particular application and their status is displayed. The application version statuses are the following: New - status assigned automatically after new version is submitted (application not yet visible for Portal users) Active - version displayed in the Portal and available for subscription and deployment Disabled - version displayed in the Portal but not available for deployment Deleted - version hidden in the Portal (including the Administrator panel) Info Only applications with at least one Active or Disabled version are visible in the Portal Transitions between application version statuses can be performed only by the System administrator When a version is marked as Disabled its deployed instances are not affected, but no new deployments can be triggered From this view an Application manager can perform the following actions: initiate the process of adding new application to the portfolio by clicking on the Add button located above the list of applications edit general information about an application by selecting Edit option from the application context menu (gearwheel icon next to the application name) add new version of given application by selecting Add new version option from the application context menu edit information about particular application version by selecting the Edit option from the application version context menu (gearwheel icon next to the application version identifier) Info The applications from the NMaaS portfolio are being deployed on Kubernetes. To this end each application has to be containerized and described in the form of a Helm chart. Info The application administration option is available only for users with System administrator or Application manager roles assigned. The Application manager has the possibility to add new applications to the portfolio as well as to manage applications user owns (meaning applications added by the user or for which the System administrator assigned the user as an owner.","title":"Introduction"},{"location":"guides/application-manager-guide/#adding-new-application","text":"Once granted the Application manager role user is able to submit new applications to the system. A complete application definition in the system comprises on one side a general set of information about the application (e.g. its name and logo) and on the other side data specific to particular version of the application (e.g. its deployment details). It is assumed that the general part is common for all the versions of the applications however the specific details may vary for different versions. The required data will need to be provided on a number of forms. First user is requested to confirm that he has the right to publish particular application on NMaaS (for example by verifying its license conditions). In order to proceed user should check the checkbox and click on the Next button. Warning If users leaves the new application wizard before submitting the information on the last form all the entered data will be lost Info A newly pushed application needs to be reviewed and approved by the System administrator . Only then is becomes Active and available in the portfolio","title":"Adding New Application"},{"location":"guides/application-manager-guide/#providing-application-basic-information","text":"The first basic information form comprises the following fields: Name (mandatory) - name of the Application (max 30 characters) Version (mandatory) - version of the Application License - license applied to the original Application (e.g. Apache 2.0) License URL - link to the respective license text Project website - link to the original website with additional information about the Application Link to source code - link to the repository with source code of the Application (e.g. on GitHub) Link to project issues - link to the website for publishing and tracking issues related with Application (e.g. on GitHub) NMaaS Documentation URL - link to a custom NMaaS provider website containing additional documentation about the Application (e.g. deployment options and consideration) Select tags for application (mandatory) - selection of tags that best describe the Application from an existing list A dd new tags for your application - names of new (not found on the drop down selector) tags to be assigned to the Application (multiple tags can be provided, each tag needs to be confirmed with Enter ) Info Throughout the wizard filling in some fields is mandatory and entering data in in the rest is optional. The mandatory fields are marked with a star (*) next to the field name. In order to proceed user should click on the Next button.","title":"Providing Application Basic Information"},{"location":"guides/application-manager-guide/#providing-application-logo-and-screenshots","text":"The second form allows the user to upload a Logo and a number of Screenshots or example images suitable for given Application (for presentation in the Portal). Once Choose button is clicked a file selection window is displayed allowing the user to browse and select a file or multiple files from his local machine. Info Multiple graphical file formats are supported including svg , png and jpg In order to proceed user should click on the Next button.","title":"Providing Application Logo and Screenshots"},{"location":"guides/application-manager-guide/#providing-application-descriptions","text":"Using the third form user is requested to enter two types of description of the Application to be used and displayed in different areas in the Portal: Brief description - few words long description of the Application presented on the main Portal view with all the applications under the Application logo (max 60 characters) Full description - complete description of the Application (e.g. purpose and main features) By default only input fields for texts in English are displayed. Dedicated fields for other languages can be displayed by checking given language on the drop down selector Select optional languages . Info It is mandatory to provide descriptions for the English language. Optionally appropriate texts can be provided for other supported languages","title":"Providing Application Descriptions"},{"location":"guides/application-manager-guide/#providing-application-deployment-specification","text":"The fourth form enables the Application manager to enter all the necessary information to allow for a fully automated deployment of new instances of particular Application. NMaaS applications are deployed using Helm thus is it mandatory to provide the respective Helm chart details and all the custom parameters to be passed as values during Helm chart installation.","title":"Providing Application Deployment Specification"},{"location":"guides/application-manager-guide/#general-information-fields","text":"Chart name (mandatory) - name of the Helm chart (e.g. nmaas-zabbix ) prefixed with the name of appropriate Helm chart repository if one different from the default is used (e.g. netbox/netbox ) Chart version (mandatory) - version of the Helm chart (e.g. 4.0.1 ) Helm Chart repository name - name of a custom repository to be added that hosts Application Helm chart (e.g. netbox ) Helm Chart repository URL address - URL of the respective custom Helm chart repository (e.g. https://charts.boo.tc ) Main component name - if Application installation comprises multiple deployment or statefulset objects its necessary to indicate which object should be considered as the main one (one that is used to verify if the whole Application is up and - running). An example would be server used to point to the proper deployment of the these two examples pllab-zabbix-624-server and pllab-zabbix-624-web (this functionality assumes that names of all objects created for given Helm chart installation contain the release name string) Expose web user interface (checkbox) - if checked indicates that given Application exposes a web user interface Allow SSH Access (checkbox) - if checked indicates that for given Application a direct shell access to running container should be enabled Info In general enabling user direct access to running containers shell of given Application is strongly discouraged. However, in order to allow such access and mitigate at least some of the risks, a built-in shell terminal was made available in the Portal.","title":"General information fields"},{"location":"guides/application-manager-guide/#global-deploy-parameters","text":"DOMAIN_CODENAME = zabbixServer.service.annotations.\"metallb\\.universe\\.tf/address-pool\"=%VALUE%","title":"Global Deploy Parameters"},{"location":"guides/application-manager-guide/#static-global-deploy-parameters","text":"image.tag = 7.02 properties.database.password = %RANDOM_STRING_12%","title":"Static Global Deploy Parameters"},{"location":"guides/application-manager-guide/#storage-volumes","text":"","title":"Storage Volumes"},{"location":"guides/application-manager-guide/#access-methods","text":"","title":"Access Methods"},{"location":"guides/application-manager-guide/#providing-application-configuration-specification","text":"","title":"Providing Application Configuration Specification"},{"location":"guides/application-manager-guide/#adding-new-application-version","text":"","title":"Adding New Application Version"},{"location":"guides/domain-admin-guide/","text":"Domain Admin Guide Domain Administrator Role Before being able to deploy and/or access application instances via the NMaaS Portal user needs to be assigned to a Domain. Info In order to apply for a new domain creation submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST . Within a domain user can be granted one of three roles as described in the NMaaS User Guide . Domain needs to have at least one Domain administrator . The initial assignment of that role in newly created domain is performed by administrators based on the received domain creation request. Only domain administrator has the possibility of subscribing to applications for his domain and triggering the deployment of instances of those applications. Additionally such user has access to some additional settings pages for his domain reachable from the Settings menu located on the top navigation bar. Viewing Domain Details After clicking on the Domains button from the Settings menu user is directed to a view listing all the domains for which he is assigned the administrator role. On this view only basic information about a given domain is displayed including the Codename, full Name and Active state indication. Domain details view can be displayed by clicking on the respective entry on the list. Domain details view includes several sections: domain name and technical details related with Kubernetes and VPN configuration application properties indicating some custom application settings for this domain (comprising information if particular application available in the marketplace is available in this domain and what is the limit of storage space that can be requested for given application instances deployed in this domain) list of users assigned to this domain and their assigned roles This view allows only for viewing the information and no data editions nor actions can be triggered from this view by domain administrators. Managing Domain Users After clicking on the Users button from the Settings menu user is directed to a view listing all the users added to the domain that is currently selected on the top navigation bar. Domain administrator can view some basic information about each of the users added to the domain including his currently assigned role, timestamp of last successful login and whether user account is currently active. Adding Users to a Domain Domain administrator is able to add additional users to the domain he is managing and grant them appropriate role. On the users list view domain administrator needs to open a dedicated view by clicking the Add users to domain button located in the top part of the view. Next, administrator is able to browse the list of available users and add the desired ones by clicking on the Grant USER role button from the actions menu (cogwheel icon) next to given user. Changing User Role in a Domain In order to change user's role assigned in a domain the domain administrator needs to open the user details view by clicking on the respective entry on the users lists, select proper role from the drop down selector in the Privileges section and confirm the new assignment by clicking on the Add/Update button. Info User is not allowed to update his own role in domain Removing User from a Domain On users list view, users can be removed from particular domain by clicking on the Remove from domain button from the actions menu (cogwheel icon) next to given user.","title":"Domain Admin Guide"},{"location":"guides/domain-admin-guide/#domain-admin-guide","text":"","title":"Domain Admin Guide"},{"location":"guides/domain-admin-guide/#domain-administrator-role","text":"Before being able to deploy and/or access application instances via the NMaaS Portal user needs to be assigned to a Domain. Info In order to apply for a new domain creation submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST . Within a domain user can be granted one of three roles as described in the NMaaS User Guide . Domain needs to have at least one Domain administrator . The initial assignment of that role in newly created domain is performed by administrators based on the received domain creation request. Only domain administrator has the possibility of subscribing to applications for his domain and triggering the deployment of instances of those applications. Additionally such user has access to some additional settings pages for his domain reachable from the Settings menu located on the top navigation bar.","title":"Domain Administrator Role"},{"location":"guides/domain-admin-guide/#viewing-domain-details","text":"After clicking on the Domains button from the Settings menu user is directed to a view listing all the domains for which he is assigned the administrator role. On this view only basic information about a given domain is displayed including the Codename, full Name and Active state indication. Domain details view can be displayed by clicking on the respective entry on the list. Domain details view includes several sections: domain name and technical details related with Kubernetes and VPN configuration application properties indicating some custom application settings for this domain (comprising information if particular application available in the marketplace is available in this domain and what is the limit of storage space that can be requested for given application instances deployed in this domain) list of users assigned to this domain and their assigned roles This view allows only for viewing the information and no data editions nor actions can be triggered from this view by domain administrators.","title":"Viewing Domain Details"},{"location":"guides/domain-admin-guide/#managing-domain-users","text":"After clicking on the Users button from the Settings menu user is directed to a view listing all the users added to the domain that is currently selected on the top navigation bar. Domain administrator can view some basic information about each of the users added to the domain including his currently assigned role, timestamp of last successful login and whether user account is currently active.","title":"Managing Domain Users"},{"location":"guides/domain-admin-guide/#adding-users-to-a-domain","text":"Domain administrator is able to add additional users to the domain he is managing and grant them appropriate role. On the users list view domain administrator needs to open a dedicated view by clicking the Add users to domain button located in the top part of the view. Next, administrator is able to browse the list of available users and add the desired ones by clicking on the Grant USER role button from the actions menu (cogwheel icon) next to given user.","title":"Adding Users to a Domain"},{"location":"guides/domain-admin-guide/#changing-user-role-in-a-domain","text":"In order to change user's role assigned in a domain the domain administrator needs to open the user details view by clicking on the respective entry on the users lists, select proper role from the drop down selector in the Privileges section and confirm the new assignment by clicking on the Add/Update button. Info User is not allowed to update his own role in domain","title":"Changing User Role in a Domain"},{"location":"guides/domain-admin-guide/#removing-user-from-a-domain","text":"On users list view, users can be removed from particular domain by clicking on the Remove from domain button from the actions menu (cogwheel icon) next to given user.","title":"Removing User from a Domain"},{"location":"guides/user-guide/","text":"User Guide Warning This guide is currently a work in progress. Some sections might be missing or contain incomplete information. 1. NMaaS Domains A domain in NMaaS corresponds to a dedicated and isolated tenant environment created within the system for particular institution, project, team or in general a group of users. Domain Assignment User can be assigned to multiple domains. Requesting a New Domain In order to apply for a new domain creation submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST . 2. Introduction to NMaaS User Roles NMaaS specifies user roles on two levels: global (system) level and user domain level. Roles on each level can be assigned independently. 2.1. Global Level Roles The Guest default global role assigned to each user after successful account registration or first federated login allows the user to browse, comment and rate the offered applications (even without being assigned to any of the domains). The remaining roles on the global level are: Operator - allows the user to view domain details and update status of particular DCN network upon its manual configuration or de-configuration Application manager - allows the user to add new applications and/or application versions to the offer through dedicated form built in the Portal as well as manage applications for which the System administrator assigned user as an owner System administrator - gives the user the complete system administration rights in the Portal (including user, domain and application management) Additional Information For Application manager and Domain administrator user guides visit NMaaS Application Manager Guide and NMaaS Domain Admin Guide 2.2 Domain Level Roles There are three user roles defined at the domain level: Guest - a basic role in given domain that allows the user to view the list of subscribed applications and currently deployed application instances however user is not allowed to view details any of running application instances User - with this role user is allowed to view details of running application instances including the access and configuration options Domain administrator - gives full control over the application subscriptions and application instances (including deployment, configuration and access) within given domain, also allows for user role management (within the scope of particular domain) These roles are assigned per user domain. A single user may have different roles assigned in multiple domains. Permission Hierarchy On the domain level, a higher role always includes all the permissions specified for all underlying lower level roles VPN Requirements In order to access the applications running within a particular domain user needs to connect to a dedicated VPN that is being set up independently of the user account within the Portal 3. NMaaS Portal NMaaS web-based graphical user interface can be accessed by browsing to address https://nmaas.eu . NMaaS landing page contains a basic set of information about the NMaaS concept and the service. Users are required to log in to gain access to the actual application market. The NMaaS Portal in available in four languages including English, French, German and Polish (though still not all texts might be properly translated in languages apart from English). 3.1 About The About page available from the top bar menu contains information about current and past NMaaS software versions and a contact form being the preferred way of reaching out to the NMaaS team regarding any subject. 4. User Login The user login form is available on the right side of the top bar menu. There are two login options to enter the Portal. First is to fill in credentials of a local user account created in the system: username and password and then clicking the Login button. The second option is to use an existing account from one of the IdPs federated under eduGAIN. After clicking on the Federated login button, user will be redirected to the eduGAIN authorization page. If performed for the first time, user is asked to provide additional information about his account including mandatory and unique username and email address. Users with accounts created directly in the system through the registration form are able to recover their password by clicking on the Forgot password link. A new input field will be displayed to provide the email address used during the registration to which a reset password link will be sent. Federated Login The federated login option is preferred and should be used whenever possible 5. User Registration For creating local account user has to select the Register tab in the login window. Registration form contains several mandatory fields, which are: Username , Password , Confirm password and a valid Email address . The provided Username has to be at least 3 letters long. The user also has to confirm that he has read the NMaaS Privacy Notice text. There are also few optional fields, namely First name , Last name and Domain selection . After submitting the registration form, user has to wait for the account being activated by the administrator. The user will be notified with an email that their account is active. A user needs to be assigned a specific role within particular domain in order to be able to view and deploy application instances in this domain. 6. Application Market After the user account has been activated by the NMaaS administrator (in the case when the user submitted the registration form), they are able to log in and are granted a basic access to the main NMaaS applications view. Same access rights are granted to users that log in through eduGAIN for the first time. On the Applications tab all of the applications supported by NMaaS are enlisted. Applications can be filtered by tags and sorted by few criteria. User can also search them by name. Single application tile consists of the logo, name, brief description and current rating of the application. Clicking on a tile redirects the user to the application\u2019s details page. Domain Selection User needs to verify or select a proper Domain from the selector located on the top bar menu 7. Application Subscriptions and Instances Once a user is granted a role inside a particular Domain they are able to view the content of the Subscriptions tab. This view comprises applications subscribed for his domain by a Domain administrator. Only these applications can be further deployed in the NMaaS cloud within the scope of particular domain. In order to subscribe to a given application user needs to open the details view of chosen application and click the Subscribe button. Application Subscriptions The subscribe option is only available for users with the Domain administrator role The third tab present on the top navigation bar named Instances contains information about all the application instances deployed within user\u2019s domain. By default the displayed list of application instances only includes instances deployed by given user. It is possible to display all instances in given domain by selecting All in the Show selector. In addition it is possible to display all the instances that were already undeployed and which are hidden by default. Application instances are described by custom Name assigned during deployment, name of the Application , selected Version of the application, user being the Owner of this instance (user who initiated the deployment), Deployment time and current State . 8. Application Instance Deployment 8.1 Application Details View On the application details page user can view a basic description of the application, example screenshots of the user interface, references to its website, code repository, website for registering issues and the versions of the application currently available on NMaaS. A user can rate an application by selecting the appropriate number of stars, view the average rating and the rating breakdown. They can also add comments for this application. Users can deploy instances of selected (subscribed) application clicking the Deploy button. Application Deployment Deploy option is only available for users with the Domain administrator role 8.2 Initiating Application Instance Deployment When deploying a new application instance a user is requested to provide or select: custom instance name (unique within the domain, up to 10 lowercase characters) version of the application (from a drop down menu) chose to enable or not fully automatic application upgrades (triggered when new versions become available in the Portal) domain (in which given instance should be deployed) The installation process comprises few steps including subscription validation, environment creation, verifying connectivity, application deployment, application first time configuration and activation. Once the installation process is completed the user is provided with a way or multiple ways of accessing the deployed application instance depending on the application (in majority of cases a link for accessing the web-based UI). Importance of the Provided Instance Name Providing a suitable instance name is important since it is later on used to create a FQDN unique for this application instance following pattern: <instance name>.<user domain name>.<NMaaS base domain> (e.g. vminstance.pllab.nmaas.eu) Application Deployment Notifications User is notified with an email once the new application instance becomes available 8.3 Application Instance Initial Configuration During the installation process, once the application instance is initially deployed, the user is asked to provide a initial configuration parameters for the application that is being installed. This data is entered through a configuration wizard presented in a window after clicking the Configure button which becomes visible on the application instance details page once the application transits to Deployed state. Different type of data may be required depending on the application. Typically the user is requested to provide credentials for a default account to be created at application startup or basic set of information about the equipment to be monitored by this application instance. Configuration parameters to be filled in are distributed over two or three tabs depending on the application. Once all required fields are populated user can select the Apply configuration button to proceed with the application activation process. 8.4 Accessing Application Instance Once the application instance reaches the Active state it can be accessed by the user. Multiple access methods are supported by NMaaS and each of the applications supports one or more of them. Four types of access are possible: public - application user interface is accessible directly from the public Internet external - application user interface is accessible over HTTPS from within a dedicated client VPN internal - application is accessible over a different protocol than HTTP on a dedicated IP address (assigned by the system) and application specific port local - a Kubernetes service name that can be used to access this application instance from another application instance running within the same user domain (e.g. the local access information for a Prometheus instance can be used to configure data source in Grafana instance deployed within the same domain) Single Access Method If a given application supports only a single external access option then when selecting the Access button user will be redirected to the application interface directly VPN Requirement for Accessing Deployed Applications In order to access the applications running within a particular domain user needs to connect to a dedicated VPN 8.5 Configuring Application Instance Some of the applications support the option of updating their configuration during application instance runtime. In such case, when instance is in Active state, the Configure button from the Actions menu on the application instance details page should be used to open a window presenting the configuration options. Typically a git clone link is provided that can be used by the user to locally clone the git repository created specifically for this application instance. Then user can apply the desired changes to the pre-propulated configuration files added to the repository by default or add new additional files. After the files are committed and pushed back to the repository the configuration of the respective application is automatically reloaded within a couple of minutes. Accessing the Configuration Repositories When cloning, the user is authenticated using their private SSH key therefore is it necessary to upload the public SSH key on the user's Profile page prior to accessing the repository Info The user that initiates a given application instance deployment is automatically added to GitLab as a member of the newly created repository. Other users, in order to have the same SSH-based access to the repository, have to be added as members to particular application instance using the Members button from the Actions menu. This operation can be performed by a Domain administrator. A Domain administrator can only select users that are added to their domain and have previously uploaded their SSH keys (see section 9.3 ). 8.6 Managing Application Instance Upgrades Once an application instance is already running, the user is able to alter their choice regarding enabling automatic application upgrades using proper option available in the Actions menu. If during the initial deployment request user opted not to enable the upgrades he is provided with an option to Enable automatic upgrades and vice versa. In case the automatic upgrades were not enabled, the user is still able to trigger application instance upgrades manually once a newer version of his deployed application is made available in the marketplace. In order to trigger the upgrade user should click on the Upgrade button from the Actions menu. Once clicked a window is displayed presenting detailed information about the possible upgrade to be performed including target application versions and corresponding target Helm chart version. Once confirmed, the upgrade process begins in the background. The fact that a particular application instance can be upgraded is indicated on the Instances view by an up arrow icon displayed next to application instance. Upgrade Availability Notifications User is notified with an email once a manual upgrade of any of his running application instances becomes possible Successful Update Notification User is notified with an email once the upgraded application instance becomes active 8.7 Initiating Application Instance Removal In order to shutdown a particular application instance and free up resources that are no longer in use, user should click the Undeploy button from the Actions menu and confirm the action in window that pops up. 8.8 Managing Failed Application Instance Deployments In unforeseen situations the deployment process may fail at some stage. One of the following actions can be triggered by the user from the application instance view once deployment process ends up in Failure state: Check state - verifying if application instance is already running Redeploy - attempt to re-run the deployment process Remove - complete removal of the failed instance allowing a fresh deployment with the same custom instance name Requesting Support for Failed Deployments Administrators are notified with an email automatically once an application deployment process fails. Users are encouraged to additionally inform administrators about the incident using the Contact Form. 9. User Settings 9.1 User Profile A User can view their account details and other personal settings by selecting the Profile option from the drop-down menu displayed after hovering over the username field on the top navigation bar. The Profile view contains user account information such as: Username , First name , Last name and Email . On the bottom of the page the user can also see their roles granted in particular domains. By clicking on the flag icon located in the top right section of the view the user can select their preferred language in which the content of the Portal will be displayed. 9.2 Setting a User's Default Domain One of the available options on the user's Profile view is specifying user's default domain. This setting is particularly useful if a given user belongs to multiple domains and would like a specific domain to be selected by default after login. 9.3 Setting User SSH Keys For applications that support the Git-based configuration management model, meaning the possibility to update the application configuration during runtime by pushing updated configuration files to a dedicated Git repository, it is required that all users willing to use this option upload their public SSH keys using the form available on the Profile view. Upon key upload or update in the Portal, user information is synchronized with the user account created on the GitLab instance associated with given NMaaS installation. 9.4 Password Change On clicking the Change password button, a new window will be displayed where the user can change their own password (see picture below). Password Reset Availability This option is not available for users that log in using the Federated / SSO option 10. Contact Form An easy and recommended way for contacting the NMaaS Team is through the Contact Form. The Contact Form is available on the About page along with the information about the versions of the NMaaS software. The user can select one of five form types that best matches the subject of his message: Contact - generic request form Access request - for requests related with new account creation or role assignment Issue report - for reporting any encountered issues with the Portal or deployed application instances New domain request - for requests related with new domain creation Enhancement or new application request - for placing suggestions of enhancements, new features or integration of new applications Form Fields Each type of form contains a different set of mandatory fields to be populated to best describe the subject of the message","title":"User Guide"},{"location":"guides/user-guide/#user-guide","text":"Warning This guide is currently a work in progress. Some sections might be missing or contain incomplete information.","title":"User Guide"},{"location":"guides/user-guide/#1-nmaas-domains","text":"A domain in NMaaS corresponds to a dedicated and isolated tenant environment created within the system for particular institution, project, team or in general a group of users. Domain Assignment User can be assigned to multiple domains. Requesting a New Domain In order to apply for a new domain creation submit the form available at https://nmaas.eu/about?type=NEW_DOMAIN_REQUEST .","title":"1. NMaaS Domains"},{"location":"guides/user-guide/#2-introduction-to-nmaas-user-roles","text":"NMaaS specifies user roles on two levels: global (system) level and user domain level. Roles on each level can be assigned independently.","title":"2. Introduction to NMaaS User Roles"},{"location":"guides/user-guide/#21-global-level-roles","text":"The Guest default global role assigned to each user after successful account registration or first federated login allows the user to browse, comment and rate the offered applications (even without being assigned to any of the domains). The remaining roles on the global level are: Operator - allows the user to view domain details and update status of particular DCN network upon its manual configuration or de-configuration Application manager - allows the user to add new applications and/or application versions to the offer through dedicated form built in the Portal as well as manage applications for which the System administrator assigned user as an owner System administrator - gives the user the complete system administration rights in the Portal (including user, domain and application management) Additional Information For Application manager and Domain administrator user guides visit NMaaS Application Manager Guide and NMaaS Domain Admin Guide","title":"2.1. Global Level Roles"},{"location":"guides/user-guide/#22-domain-level-roles","text":"There are three user roles defined at the domain level: Guest - a basic role in given domain that allows the user to view the list of subscribed applications and currently deployed application instances however user is not allowed to view details any of running application instances User - with this role user is allowed to view details of running application instances including the access and configuration options Domain administrator - gives full control over the application subscriptions and application instances (including deployment, configuration and access) within given domain, also allows for user role management (within the scope of particular domain) These roles are assigned per user domain. A single user may have different roles assigned in multiple domains. Permission Hierarchy On the domain level, a higher role always includes all the permissions specified for all underlying lower level roles VPN Requirements In order to access the applications running within a particular domain user needs to connect to a dedicated VPN that is being set up independently of the user account within the Portal","title":"2.2 Domain Level Roles"},{"location":"guides/user-guide/#3-nmaas-portal","text":"NMaaS web-based graphical user interface can be accessed by browsing to address https://nmaas.eu . NMaaS landing page contains a basic set of information about the NMaaS concept and the service. Users are required to log in to gain access to the actual application market. The NMaaS Portal in available in four languages including English, French, German and Polish (though still not all texts might be properly translated in languages apart from English).","title":"3. NMaaS Portal"},{"location":"guides/user-guide/#31-about","text":"The About page available from the top bar menu contains information about current and past NMaaS software versions and a contact form being the preferred way of reaching out to the NMaaS team regarding any subject.","title":"3.1 About"},{"location":"guides/user-guide/#4-user-login","text":"The user login form is available on the right side of the top bar menu. There are two login options to enter the Portal. First is to fill in credentials of a local user account created in the system: username and password and then clicking the Login button. The second option is to use an existing account from one of the IdPs federated under eduGAIN. After clicking on the Federated login button, user will be redirected to the eduGAIN authorization page. If performed for the first time, user is asked to provide additional information about his account including mandatory and unique username and email address. Users with accounts created directly in the system through the registration form are able to recover their password by clicking on the Forgot password link. A new input field will be displayed to provide the email address used during the registration to which a reset password link will be sent. Federated Login The federated login option is preferred and should be used whenever possible","title":"4. User Login"},{"location":"guides/user-guide/#5-user-registration","text":"For creating local account user has to select the Register tab in the login window. Registration form contains several mandatory fields, which are: Username , Password , Confirm password and a valid Email address . The provided Username has to be at least 3 letters long. The user also has to confirm that he has read the NMaaS Privacy Notice text. There are also few optional fields, namely First name , Last name and Domain selection . After submitting the registration form, user has to wait for the account being activated by the administrator. The user will be notified with an email that their account is active. A user needs to be assigned a specific role within particular domain in order to be able to view and deploy application instances in this domain.","title":"5. User Registration"},{"location":"guides/user-guide/#6-application-market","text":"After the user account has been activated by the NMaaS administrator (in the case when the user submitted the registration form), they are able to log in and are granted a basic access to the main NMaaS applications view. Same access rights are granted to users that log in through eduGAIN for the first time. On the Applications tab all of the applications supported by NMaaS are enlisted. Applications can be filtered by tags and sorted by few criteria. User can also search them by name. Single application tile consists of the logo, name, brief description and current rating of the application. Clicking on a tile redirects the user to the application\u2019s details page. Domain Selection User needs to verify or select a proper Domain from the selector located on the top bar menu","title":"6. Application Market"},{"location":"guides/user-guide/#7-application-subscriptions-and-instances","text":"Once a user is granted a role inside a particular Domain they are able to view the content of the Subscriptions tab. This view comprises applications subscribed for his domain by a Domain administrator. Only these applications can be further deployed in the NMaaS cloud within the scope of particular domain. In order to subscribe to a given application user needs to open the details view of chosen application and click the Subscribe button. Application Subscriptions The subscribe option is only available for users with the Domain administrator role The third tab present on the top navigation bar named Instances contains information about all the application instances deployed within user\u2019s domain. By default the displayed list of application instances only includes instances deployed by given user. It is possible to display all instances in given domain by selecting All in the Show selector. In addition it is possible to display all the instances that were already undeployed and which are hidden by default. Application instances are described by custom Name assigned during deployment, name of the Application , selected Version of the application, user being the Owner of this instance (user who initiated the deployment), Deployment time and current State .","title":"7. Application Subscriptions and Instances"},{"location":"guides/user-guide/#8-application-instance-deployment","text":"","title":"8. Application Instance Deployment"},{"location":"guides/user-guide/#81-application-details-view","text":"On the application details page user can view a basic description of the application, example screenshots of the user interface, references to its website, code repository, website for registering issues and the versions of the application currently available on NMaaS. A user can rate an application by selecting the appropriate number of stars, view the average rating and the rating breakdown. They can also add comments for this application. Users can deploy instances of selected (subscribed) application clicking the Deploy button. Application Deployment Deploy option is only available for users with the Domain administrator role","title":"8.1 Application Details View"},{"location":"guides/user-guide/#82-initiating-application-instance-deployment","text":"When deploying a new application instance a user is requested to provide or select: custom instance name (unique within the domain, up to 10 lowercase characters) version of the application (from a drop down menu) chose to enable or not fully automatic application upgrades (triggered when new versions become available in the Portal) domain (in which given instance should be deployed) The installation process comprises few steps including subscription validation, environment creation, verifying connectivity, application deployment, application first time configuration and activation. Once the installation process is completed the user is provided with a way or multiple ways of accessing the deployed application instance depending on the application (in majority of cases a link for accessing the web-based UI). Importance of the Provided Instance Name Providing a suitable instance name is important since it is later on used to create a FQDN unique for this application instance following pattern: <instance name>.<user domain name>.<NMaaS base domain> (e.g. vminstance.pllab.nmaas.eu) Application Deployment Notifications User is notified with an email once the new application instance becomes available","title":"8.2 Initiating Application Instance Deployment"},{"location":"guides/user-guide/#83-application-instance-initial-configuration","text":"During the installation process, once the application instance is initially deployed, the user is asked to provide a initial configuration parameters for the application that is being installed. This data is entered through a configuration wizard presented in a window after clicking the Configure button which becomes visible on the application instance details page once the application transits to Deployed state. Different type of data may be required depending on the application. Typically the user is requested to provide credentials for a default account to be created at application startup or basic set of information about the equipment to be monitored by this application instance. Configuration parameters to be filled in are distributed over two or three tabs depending on the application. Once all required fields are populated user can select the Apply configuration button to proceed with the application activation process.","title":"8.3 Application Instance Initial Configuration"},{"location":"guides/user-guide/#84-accessing-application-instance","text":"Once the application instance reaches the Active state it can be accessed by the user. Multiple access methods are supported by NMaaS and each of the applications supports one or more of them. Four types of access are possible: public - application user interface is accessible directly from the public Internet external - application user interface is accessible over HTTPS from within a dedicated client VPN internal - application is accessible over a different protocol than HTTP on a dedicated IP address (assigned by the system) and application specific port local - a Kubernetes service name that can be used to access this application instance from another application instance running within the same user domain (e.g. the local access information for a Prometheus instance can be used to configure data source in Grafana instance deployed within the same domain) Single Access Method If a given application supports only a single external access option then when selecting the Access button user will be redirected to the application interface directly VPN Requirement for Accessing Deployed Applications In order to access the applications running within a particular domain user needs to connect to a dedicated VPN","title":"8.4 Accessing Application Instance"},{"location":"guides/user-guide/#85-configuring-application-instance","text":"Some of the applications support the option of updating their configuration during application instance runtime. In such case, when instance is in Active state, the Configure button from the Actions menu on the application instance details page should be used to open a window presenting the configuration options. Typically a git clone link is provided that can be used by the user to locally clone the git repository created specifically for this application instance. Then user can apply the desired changes to the pre-propulated configuration files added to the repository by default or add new additional files. After the files are committed and pushed back to the repository the configuration of the respective application is automatically reloaded within a couple of minutes. Accessing the Configuration Repositories When cloning, the user is authenticated using their private SSH key therefore is it necessary to upload the public SSH key on the user's Profile page prior to accessing the repository Info The user that initiates a given application instance deployment is automatically added to GitLab as a member of the newly created repository. Other users, in order to have the same SSH-based access to the repository, have to be added as members to particular application instance using the Members button from the Actions menu. This operation can be performed by a Domain administrator. A Domain administrator can only select users that are added to their domain and have previously uploaded their SSH keys (see section 9.3 ).","title":"8.5 Configuring Application Instance"},{"location":"guides/user-guide/#86-managing-application-instance-upgrades","text":"Once an application instance is already running, the user is able to alter their choice regarding enabling automatic application upgrades using proper option available in the Actions menu. If during the initial deployment request user opted not to enable the upgrades he is provided with an option to Enable automatic upgrades and vice versa. In case the automatic upgrades were not enabled, the user is still able to trigger application instance upgrades manually once a newer version of his deployed application is made available in the marketplace. In order to trigger the upgrade user should click on the Upgrade button from the Actions menu. Once clicked a window is displayed presenting detailed information about the possible upgrade to be performed including target application versions and corresponding target Helm chart version. Once confirmed, the upgrade process begins in the background. The fact that a particular application instance can be upgraded is indicated on the Instances view by an up arrow icon displayed next to application instance. Upgrade Availability Notifications User is notified with an email once a manual upgrade of any of his running application instances becomes possible Successful Update Notification User is notified with an email once the upgraded application instance becomes active","title":"8.6 Managing Application Instance Upgrades"},{"location":"guides/user-guide/#87-initiating-application-instance-removal","text":"In order to shutdown a particular application instance and free up resources that are no longer in use, user should click the Undeploy button from the Actions menu and confirm the action in window that pops up.","title":"8.7 Initiating Application Instance Removal"},{"location":"guides/user-guide/#88-managing-failed-application-instance-deployments","text":"In unforeseen situations the deployment process may fail at some stage. One of the following actions can be triggered by the user from the application instance view once deployment process ends up in Failure state: Check state - verifying if application instance is already running Redeploy - attempt to re-run the deployment process Remove - complete removal of the failed instance allowing a fresh deployment with the same custom instance name Requesting Support for Failed Deployments Administrators are notified with an email automatically once an application deployment process fails. Users are encouraged to additionally inform administrators about the incident using the Contact Form.","title":"8.8 Managing Failed Application Instance Deployments"},{"location":"guides/user-guide/#9-user-settings","text":"","title":"9. User Settings"},{"location":"guides/user-guide/#91-user-profile","text":"A User can view their account details and other personal settings by selecting the Profile option from the drop-down menu displayed after hovering over the username field on the top navigation bar. The Profile view contains user account information such as: Username , First name , Last name and Email . On the bottom of the page the user can also see their roles granted in particular domains. By clicking on the flag icon located in the top right section of the view the user can select their preferred language in which the content of the Portal will be displayed.","title":"9.1 User Profile"},{"location":"guides/user-guide/#92-setting-a-users-default-domain","text":"One of the available options on the user's Profile view is specifying user's default domain. This setting is particularly useful if a given user belongs to multiple domains and would like a specific domain to be selected by default after login.","title":"9.2 Setting a User's Default Domain"},{"location":"guides/user-guide/#93-setting-user-ssh-keys","text":"For applications that support the Git-based configuration management model, meaning the possibility to update the application configuration during runtime by pushing updated configuration files to a dedicated Git repository, it is required that all users willing to use this option upload their public SSH keys using the form available on the Profile view. Upon key upload or update in the Portal, user information is synchronized with the user account created on the GitLab instance associated with given NMaaS installation.","title":"9.3 Setting User SSH Keys"},{"location":"guides/user-guide/#94-password-change","text":"On clicking the Change password button, a new window will be displayed where the user can change their own password (see picture below). Password Reset Availability This option is not available for users that log in using the Federated / SSO option","title":"9.4 Password Change"},{"location":"guides/user-guide/#10-contact-form","text":"An easy and recommended way for contacting the NMaaS Team is through the Contact Form. The Contact Form is available on the About page along with the information about the versions of the NMaaS software. The user can select one of five form types that best matches the subject of his message: Contact - generic request form Access request - for requests related with new account creation or role assignment Issue report - for reporting any encountered issues with the Portal or deployed application instances New domain request - for requests related with new domain creation Enhancement or new application request - for placing suggestions of enhancements, new features or integration of new applications Form Fields Each type of form contains a different set of mandatory fields to be populated to best describe the subject of the message","title":"10. Contact Form"},{"location":"managed-nmaas/introduction/","text":"Introduction to Managed NMaaS Work in progress. Content will be provided soon!","title":"Introduction"},{"location":"managed-nmaas/introduction/#introduction-to-managed-nmaas","text":"Work in progress. Content will be provided soon!","title":"Introduction to Managed NMaaS"},{"location":"managed-nmaas/nmaas-playground-instance/","text":"NMaaS Playground Instance Introduction NMaaS Playground is an NMaaS central installation that can be used by anyone interested in testing latest versions of NMaaS. It is available at https://nmaas.geant.org . NMaaS Playground is deployed on G\u00c9ANT's infrastructure and is maintained by the NMaaS Team. Any questions or requests related with using the NMaaS Playground should be directed to nmaas@lists.geant.org . It is important to note that the NMaaS Playground is tailored to enable users to browse and deploy NMaaS tools right away without any unnecessary overhead. However, this implies that the user isolation, access and data security rules applied on this NMaaS installation are not so strict as in the case of the official NMaaS production service (e.g. no dedicated VPNs are deployed). Warning NMaaS Playground should be used only for testing purposes and not for monitoring of actual user equipment For any information on how to use NMaaS refer the official NMaaS User Guide. Accessing the Playground In order to use the Playground a new user should either fill in the registration form to create a local account in the system or use the Federated login option. In both cases, the system administrator will have to manually add the new user to a Test domain that is pre-configured in the system. NMaaS domain corresponds to an institution, team or project (e.g. NREN, end institution, team within the G\u00c9ANT Project) whose users will be able to deploy instances of tools available in the NMaaS portfolio in order to manage and/or monitor the equipment within that domain. Deploying NMaaS Tools The main purpose of using the NMaaS Playground is to deploy and access test instances of NMaaS Tools. From more information about the tools currently supported by NMaaS refer to the application list . Running a network management tool without any equipment that can be monitored would not present the full potential of NMaaS. Therefore a virtual user network with various types of devices has been deployed and connected to the Test domain. While deploying a tool in the NMaaS Playground users can choose any subset of available devices to be monitored. The following table presents all the equipment available in the virtual user network together with any relevant information that later on needs to be provided in the configuration wizard during deployment of particular tool. For example when deploying new instance of the Oxidized application, the user will be asked to provide a list of IP addresses of devices to be interrogated and the SSH username and password to be used for accessing them. Device Identifier Device Type IP Address/URL SSH Username/Password SNMP Version/Community ... ... ... ... ... vmx-31 Virtual Juniper MX Router 10.0.0.31 geant / geant123 v2c / nmaas-public vmx-c1 Virtual Juniper MX Router 10.0.0.1 geant / geant123 v2c / nmaas-public vmx-c2 Virtual Juniper MX Router 10.0.0.2 geant / geant123 v2c / nmaas-public Demo Instances of NMaaS Applications A set of tools have been deployed by default in the Test domain and configured to monitor the resources of the virtual user network and servers. Those tools are run for demo purposed and are reachable over the Internet. In the production setup, the user web interface of any deployed tool is only accessible from within a dedicated user VPN. Application URL Login Credentials Comments SNMP Version/Community Oxidized https://oxi-virt-1.test.nmaas.geant.org admin / oxidized Configured 16 Juniper vMX routers which configuration is being backed up v2c / nmaas-public LibreNMS https://lib-virt-1.test.nmaas.geant.org admin / librenms Polling information from 16 routers v2c / nmaas-public Prometheus https://pro-virt-1.test.nmaas.geant.org admin / prometheus Added 3 target virtual machines with node exporter installed v2c / nmaas-public Grafana https://gra-virt-1.test.nmaas.geant.org admin / grafana The pro-virt-1 Prometheus instance is configured as data source. Default dashboard or node exporters is added. Booked https://booked.test.nmaas.geant.org admin / booked Gallery","title":"NMaaS Playground Instance"},{"location":"managed-nmaas/nmaas-playground-instance/#nmaas-playground-instance","text":"","title":"NMaaS Playground Instance"},{"location":"managed-nmaas/nmaas-playground-instance/#introduction","text":"NMaaS Playground is an NMaaS central installation that can be used by anyone interested in testing latest versions of NMaaS. It is available at https://nmaas.geant.org . NMaaS Playground is deployed on G\u00c9ANT's infrastructure and is maintained by the NMaaS Team. Any questions or requests related with using the NMaaS Playground should be directed to nmaas@lists.geant.org . It is important to note that the NMaaS Playground is tailored to enable users to browse and deploy NMaaS tools right away without any unnecessary overhead. However, this implies that the user isolation, access and data security rules applied on this NMaaS installation are not so strict as in the case of the official NMaaS production service (e.g. no dedicated VPNs are deployed). Warning NMaaS Playground should be used only for testing purposes and not for monitoring of actual user equipment For any information on how to use NMaaS refer the official NMaaS User Guide.","title":"Introduction"},{"location":"managed-nmaas/nmaas-playground-instance/#accessing-the-playground","text":"In order to use the Playground a new user should either fill in the registration form to create a local account in the system or use the Federated login option. In both cases, the system administrator will have to manually add the new user to a Test domain that is pre-configured in the system. NMaaS domain corresponds to an institution, team or project (e.g. NREN, end institution, team within the G\u00c9ANT Project) whose users will be able to deploy instances of tools available in the NMaaS portfolio in order to manage and/or monitor the equipment within that domain.","title":"Accessing the Playground"},{"location":"managed-nmaas/nmaas-playground-instance/#deploying-nmaas-tools","text":"The main purpose of using the NMaaS Playground is to deploy and access test instances of NMaaS Tools. From more information about the tools currently supported by NMaaS refer to the application list . Running a network management tool without any equipment that can be monitored would not present the full potential of NMaaS. Therefore a virtual user network with various types of devices has been deployed and connected to the Test domain. While deploying a tool in the NMaaS Playground users can choose any subset of available devices to be monitored. The following table presents all the equipment available in the virtual user network together with any relevant information that later on needs to be provided in the configuration wizard during deployment of particular tool. For example when deploying new instance of the Oxidized application, the user will be asked to provide a list of IP addresses of devices to be interrogated and the SSH username and password to be used for accessing them. Device Identifier Device Type IP Address/URL SSH Username/Password SNMP Version/Community ... ... ... ... ... vmx-31 Virtual Juniper MX Router 10.0.0.31 geant / geant123 v2c / nmaas-public vmx-c1 Virtual Juniper MX Router 10.0.0.1 geant / geant123 v2c / nmaas-public vmx-c2 Virtual Juniper MX Router 10.0.0.2 geant / geant123 v2c / nmaas-public","title":"Deploying NMaaS Tools"},{"location":"managed-nmaas/nmaas-playground-instance/#demo-instances-of-nmaas-applications","text":"A set of tools have been deployed by default in the Test domain and configured to monitor the resources of the virtual user network and servers. Those tools are run for demo purposed and are reachable over the Internet. In the production setup, the user web interface of any deployed tool is only accessible from within a dedicated user VPN. Application URL Login Credentials Comments SNMP Version/Community Oxidized https://oxi-virt-1.test.nmaas.geant.org admin / oxidized Configured 16 Juniper vMX routers which configuration is being backed up v2c / nmaas-public LibreNMS https://lib-virt-1.test.nmaas.geant.org admin / librenms Polling information from 16 routers v2c / nmaas-public Prometheus https://pro-virt-1.test.nmaas.geant.org admin / prometheus Added 3 target virtual machines with node exporter installed v2c / nmaas-public Grafana https://gra-virt-1.test.nmaas.geant.org admin / grafana The pro-virt-1 Prometheus instance is configured as data source. Default dashboard or node exporters is added. Booked https://booked.test.nmaas.geant.org admin / booked","title":"Demo Instances of NMaaS Applications"},{"location":"managed-nmaas/nmaas-playground-instance/#gallery","text":"","title":"Gallery"},{"location":"nmaas-applications/application-list/","text":"List of Supported Applications This is a continuously updated list of currently supported applications on NMaaS. Note that not all applications are supported across all environments, some are supported only on the managed server, while others can only be supported on self-hosted installations. No Application name Helm chart name App Version (Helm chart version given in brackets) Environment 1 Oxidized nmaas-oxidized 0.25.1 (2.0.1); 0.28.0 (2.0.1); Managed + Self-Hosted 2 LibreNMS nmaas-librenms 1.4.7 (2.0.1); Managed + Self-Hosted 3 NAV nav 4.8.6 (2.0.1); Managed + Self-Hosted 4 Prometheus nmaas-prometheus 2.8.0 (2.0.1); 2.39.1 (2.0.28); 2.40.4 (3.0.0); 2.40.5 (3.0.1); Managed + Self-Hosted 5 Grafana nmaas-grafana 7.2.0 (2.0.1); 7.3.4 (2.0.1); 7.5.16 (3.0.7); 8.0.7 (2.0.1); 8.5.11 (4.0.23); 9.1.4 (5.0.3); 9.3.1 (6.0.0); Managed + Self-Hosted 6 Bastion nmaas-bastion 18.04 (2.1.0); 20.04 (2.1.2); 20.04-v2 (2.1.4); Managed + Self-Hosted 7 Booked nmaas-booked 2.7.7 (2.0.1); 2.8.5 (3.0.0); Managed + Self-Hosted 8 Statping nmaas-statping 0.90.17 (2.0.1); DEPRECATED 9 SPA Inventory nmaas-spa-inventory 2.0 (2.0.1); Managed + Self-Hosted 10 perfSONAR PWA nmaas-perfsonar-pwa 4.2.2 (2.0.1); 4.3.2 (2.1.0); Managed + Self-Hosted 11 perfSONAR MaDDash nmaas-perfsonar-maddash 4.3.4 (2.2.4); Managed + Self-Hosted 12 perfSONAR esmond nmaas-perfsonar-esmond 4.2.4-1 (2.0.1); 4.3.4 (2.2.0); Managed + Self-Hosted 13 perfSONAR Central Management nmaas-perfsonar-centralmanagement 4.2.4 (2.0.1); 4.3.4 (2.2.0); Managed + Self-Hosted 14 Debian package repository (Reprepro) nmaas-reprepro 1.0 (2.0.1); Managed + Self-Hosted 15 InfluxDB influxdata/influxdb 1.7.10 (4.4.8); Managed + Self-Hosted 16 Jenkins nmaas-jenkins 2.277.3 (4.0.0); Managed + Self-Hosted 17 ELK Stack elastic-stack 7.7.1 (1.8.0); Managed + Self-Hosted 18 WiFiMon (with ELK) nmaas-wifimon 1.6.0 (2.0.2); Managed + Self-Hosted 19 Icinga2 nmaas-icinga2 2.11.4 (2.0.1); Managed + Self-Hosted 20 Victoria Metrics nmaas-victoria 1.46.0 (2.0.1); 1.81.2 (2.0.16); 1.82.1 (2.0.17); 1.83.1 (2.0.18); 1.84.0 (2.0.19); 1.85.1 (3.0.0); Managed + Self-Hosted 21 Matrix / Synapse nmaas-matrix 1.22.1 (3.0.1); Managed + Self-Hosted 22 Routinator nmaas-routinator 0.8.3 (2.0.0), 0.11.3 (2.0.3); Managed + Self-Hosted 23 CodiMD nmaas-codimd 2.4.1 (1.0.0); Managed + Self-Hosted 24 WebDAV nmaas-webdav 1.0.0 (1.0.0); Managed + Self-Hosted 25 Uptime Kuma nmaas-uptimekuma 1.10.2 (1.0.0); 1.15.1 (1.0.2); 1.16.1 (1.0.3); 1.18.0 (1.0.4); 1.18.1 (1.0.5); 1.18.4 (1.0.6); 1.18.5 (1.0.7); 1.21.3 (2.0.0); Managed + Self-Hosted 26 Zabbix nmaas-zabbix 5.0.20 (1.0.0); 5.0.21 (1.0.1); 5.0.22 (1.0.2); 5.0.27 (1.0.3); 6.0.5 (2.0.2); 6.0.8 (2.0.3); 6.2.2 (3.0.0); 6.2.4 (3.0.2); 6.2.5 (3.0.3); Managed + Self-Hosted 27 Healthchecks nmaas-healthchecks 2.1 (1.0.2); 2.3 (1.0.4); 2.4.1 (1.0.5); 2.5.0 (1.0.6); 2.7.0 (1.0.7); 2.8.0 (1.0.8); Managed + Self-Hosted 28 SPA nmaas-spa 1.3.3-1 (1.0.4); Managed + Self-Hosted 29 Netbox netbox/netbox nmaas-netbox (from 6.0.0) 3.0.11 (4.0.1); 3.2.8 (4.1.1); 3.5.2 (6.0.0); Managed + Self-Hosted 30 CTFd nmaas-ctfd 3.5.1 (1.0.1); Self-Hosted 31 JuiceShop nmaas-juiceshop 14.5.1 (1.0.0); Self-Hosted 32 Adminer nmaas-adminer 4.8.1 (3.0.0); Managed + Self-Hosted 33 Changedetection.io nmaas-changedetection 0.44.1 (1.0.2); Managed + Self-Hosted","title":"List of Supported Applications"},{"location":"nmaas-applications/application-list/#list-of-supported-applications","text":"This is a continuously updated list of currently supported applications on NMaaS. Note that not all applications are supported across all environments, some are supported only on the managed server, while others can only be supported on self-hosted installations. No Application name Helm chart name App Version (Helm chart version given in brackets) Environment 1 Oxidized nmaas-oxidized 0.25.1 (2.0.1); 0.28.0 (2.0.1); Managed + Self-Hosted 2 LibreNMS nmaas-librenms 1.4.7 (2.0.1); Managed + Self-Hosted 3 NAV nav 4.8.6 (2.0.1); Managed + Self-Hosted 4 Prometheus nmaas-prometheus 2.8.0 (2.0.1); 2.39.1 (2.0.28); 2.40.4 (3.0.0); 2.40.5 (3.0.1); Managed + Self-Hosted 5 Grafana nmaas-grafana 7.2.0 (2.0.1); 7.3.4 (2.0.1); 7.5.16 (3.0.7); 8.0.7 (2.0.1); 8.5.11 (4.0.23); 9.1.4 (5.0.3); 9.3.1 (6.0.0); Managed + Self-Hosted 6 Bastion nmaas-bastion 18.04 (2.1.0); 20.04 (2.1.2); 20.04-v2 (2.1.4); Managed + Self-Hosted 7 Booked nmaas-booked 2.7.7 (2.0.1); 2.8.5 (3.0.0); Managed + Self-Hosted 8 Statping nmaas-statping 0.90.17 (2.0.1); DEPRECATED 9 SPA Inventory nmaas-spa-inventory 2.0 (2.0.1); Managed + Self-Hosted 10 perfSONAR PWA nmaas-perfsonar-pwa 4.2.2 (2.0.1); 4.3.2 (2.1.0); Managed + Self-Hosted 11 perfSONAR MaDDash nmaas-perfsonar-maddash 4.3.4 (2.2.4); Managed + Self-Hosted 12 perfSONAR esmond nmaas-perfsonar-esmond 4.2.4-1 (2.0.1); 4.3.4 (2.2.0); Managed + Self-Hosted 13 perfSONAR Central Management nmaas-perfsonar-centralmanagement 4.2.4 (2.0.1); 4.3.4 (2.2.0); Managed + Self-Hosted 14 Debian package repository (Reprepro) nmaas-reprepro 1.0 (2.0.1); Managed + Self-Hosted 15 InfluxDB influxdata/influxdb 1.7.10 (4.4.8); Managed + Self-Hosted 16 Jenkins nmaas-jenkins 2.277.3 (4.0.0); Managed + Self-Hosted 17 ELK Stack elastic-stack 7.7.1 (1.8.0); Managed + Self-Hosted 18 WiFiMon (with ELK) nmaas-wifimon 1.6.0 (2.0.2); Managed + Self-Hosted 19 Icinga2 nmaas-icinga2 2.11.4 (2.0.1); Managed + Self-Hosted 20 Victoria Metrics nmaas-victoria 1.46.0 (2.0.1); 1.81.2 (2.0.16); 1.82.1 (2.0.17); 1.83.1 (2.0.18); 1.84.0 (2.0.19); 1.85.1 (3.0.0); Managed + Self-Hosted 21 Matrix / Synapse nmaas-matrix 1.22.1 (3.0.1); Managed + Self-Hosted 22 Routinator nmaas-routinator 0.8.3 (2.0.0), 0.11.3 (2.0.3); Managed + Self-Hosted 23 CodiMD nmaas-codimd 2.4.1 (1.0.0); Managed + Self-Hosted 24 WebDAV nmaas-webdav 1.0.0 (1.0.0); Managed + Self-Hosted 25 Uptime Kuma nmaas-uptimekuma 1.10.2 (1.0.0); 1.15.1 (1.0.2); 1.16.1 (1.0.3); 1.18.0 (1.0.4); 1.18.1 (1.0.5); 1.18.4 (1.0.6); 1.18.5 (1.0.7); 1.21.3 (2.0.0); Managed + Self-Hosted 26 Zabbix nmaas-zabbix 5.0.20 (1.0.0); 5.0.21 (1.0.1); 5.0.22 (1.0.2); 5.0.27 (1.0.3); 6.0.5 (2.0.2); 6.0.8 (2.0.3); 6.2.2 (3.0.0); 6.2.4 (3.0.2); 6.2.5 (3.0.3); Managed + Self-Hosted 27 Healthchecks nmaas-healthchecks 2.1 (1.0.2); 2.3 (1.0.4); 2.4.1 (1.0.5); 2.5.0 (1.0.6); 2.7.0 (1.0.7); 2.8.0 (1.0.8); Managed + Self-Hosted 28 SPA nmaas-spa 1.3.3-1 (1.0.4); Managed + Self-Hosted 29 Netbox netbox/netbox nmaas-netbox (from 6.0.0) 3.0.11 (4.0.1); 3.2.8 (4.1.1); 3.5.2 (6.0.0); Managed + Self-Hosted 30 CTFd nmaas-ctfd 3.5.1 (1.0.1); Self-Hosted 31 JuiceShop nmaas-juiceshop 14.5.1 (1.0.0); Self-Hosted 32 Adminer nmaas-adminer 4.8.1 (3.0.0); Managed + Self-Hosted 33 Changedetection.io nmaas-changedetection 0.44.1 (1.0.2); Managed + Self-Hosted","title":"List of Supported Applications"},{"location":"nmaas-applications/general-app-deployment/","text":"General Application Deployment This page explains the basic set of steps that need to be undertaken during application deployment on NMaaS. NMaaS Tool Deployment Process A basic set of steps required to deploy an instance of an NMaaS application is the following: Log in to NMaaS Portal Choose application from the market Request deployment and provide a custom name for the new instance Follow the automated installation steps Provide basic configuration for the new instance through a custom wizard Wait for the application deployment and verification process to complete Access the application UI following unique URL The whole process shouldn't take more than several minutes. NMaaS Tool Configuration Process During the tool deployment process user is asked to fill in a form and provide basic configuration data for the new tool instance. This data might comprise default user credentials, IP addresses of devices to be monitored and/or requested storage space to persist monitoring data. For some of the tools this data provided by the user is used to populate tool specific configurations files that are later on uploaded to a dedicated Git repositories (a new repository is created for each tool instance). From this point any change to the configuration of a running tool instance should be done following these steps: Open the tool instance page and view the Git clone link displayed after clicking the Update configuration button, Use the command to clone the repository locally using the SSH key provided beforehand. Apply desired modifications, commit and push altered files back to the remote repository. Wait for a couple of minutes in order for the new configuration to be loaded and applied by the tool instance. Note: Git repositories containing application configuration files are hosted on a dedicated private GitLab instance operated by the NMaaS Team. Note: Users should upload their public SSH key using the Profile page before deploying a new instance of a tool in order to be able to clone the Git repository afterwards. Specific Application Tutorials Tutorials for each of the supported applications currently in the NMaaS catalog are available in the Application Deployment Tutorials Section .","title":"General Application Deployment"},{"location":"nmaas-applications/general-app-deployment/#general-application-deployment","text":"This page explains the basic set of steps that need to be undertaken during application deployment on NMaaS.","title":"General Application Deployment"},{"location":"nmaas-applications/general-app-deployment/#nmaas-tool-deployment-process","text":"A basic set of steps required to deploy an instance of an NMaaS application is the following: Log in to NMaaS Portal Choose application from the market Request deployment and provide a custom name for the new instance Follow the automated installation steps Provide basic configuration for the new instance through a custom wizard Wait for the application deployment and verification process to complete Access the application UI following unique URL The whole process shouldn't take more than several minutes.","title":"NMaaS Tool Deployment Process"},{"location":"nmaas-applications/general-app-deployment/#nmaas-tool-configuration-process","text":"During the tool deployment process user is asked to fill in a form and provide basic configuration data for the new tool instance. This data might comprise default user credentials, IP addresses of devices to be monitored and/or requested storage space to persist monitoring data. For some of the tools this data provided by the user is used to populate tool specific configurations files that are later on uploaded to a dedicated Git repositories (a new repository is created for each tool instance). From this point any change to the configuration of a running tool instance should be done following these steps: Open the tool instance page and view the Git clone link displayed after clicking the Update configuration button, Use the command to clone the repository locally using the SSH key provided beforehand. Apply desired modifications, commit and push altered files back to the remote repository. Wait for a couple of minutes in order for the new configuration to be loaded and applied by the tool instance. Note: Git repositories containing application configuration files are hosted on a dedicated private GitLab instance operated by the NMaaS Team. Note: Users should upload their public SSH key using the Profile page before deploying a new instance of a tool in order to be able to clone the Git repository afterwards.","title":"NMaaS Tool Configuration Process"},{"location":"nmaas-applications/general-app-deployment/#specific-application-tutorials","text":"Tutorials for each of the supported applications currently in the NMaaS catalog are available in the Application Deployment Tutorials Section .","title":"Specific Application Tutorials"},{"location":"nmaas-applications/new-application/","text":"Adding a new Application Anyone can submit an application to be included to the NMaaS catalog, thus making it available to all users of the production instance. Each application should have at least one official maintainer who will regularly pull changes from the upstream project and provide updated Docker images and Helm charts. The source code for each Helm chart should be hosted in a separate Git repository. A brief guide on how a new chart repository can be set up using the GitHub platform is presented below. Please note that we do not require the use of GitHub or mandate a specific code hosting service. Any platform that is publicly accessible would suffice. Process Explanation Applying for an application to be added to the NMaaS catalog is a two-step process. First, the chart needs to be created, and then a brief proposal submitted to the NMaaS team via email. After reviewing the chart, the user who submitted it will be assigned a new role on the production instance of NMaaS ( https://nmaas.eu ) \u2013 tool manager , which allows uploading of new versions and parameter changes. Step 1: Create a new GitHub Repository Login or register a new account on GitHub and create a new public repository. Repositories can be created either as an individual user or as an organization. Creating a New GitHub Repository Step 2: Configure GitHub Pages for Hosting the Helm Repository GitHub has a free option for hosting static files for public repositories called GitHub Pages. This is a hugely popular tool for publicly hosting simple blogs or websites created using static site generators such as Hugo or Jekyll. However, in our case, this is also a perfect opportunity to host the index.yaml metadata file required for every Helm repository. To enable GitHub Pages for your project, the following steps need to be performed: Clone the newly created repository locally and a dummy .gitignore file which can be used later. 1 2 3 4 5 git clone git@github.com:USERNAME/REPOSITORY_NAME.git touch .gitignore git add . git commit -m \"add .gitignore\" git push --set-upstream origin master Warning Before pushing the changes to the remote and executing the git push command, make sure to correctly identify the name of the default Git branch. This varies from environment to environment, and in the case of GitHub, can be directly checked from the settings screen of the given repository (Settings \u2192 Branches). Create a new branch called gh-pages 1 2 3 4 git checkout --orphan gh-pages git rm -rf . git commit -m \"Initial commit\" --allow-empty git push --set-upstream origin gh-pages Once the branch is created, GitHub Pages can be officially enabled from the Settings page of your repository Enabling GitHub Pages If desirable, you can add any index.html file to the gh-pages branch, so that users are not presented with a 404 error when directly accessing the Helm repository root URL. Note that this has no effect on the functionality of the Helm repository itself. Step 3: Preparing the Chart We are now ready to publish the source code for our chart. The GitHub Actions that we will configure in the next step mandate that our charts are placed in a charts directory within the repository. Switch to the master branch of the repository 1 git checkout master Create the necessary directory tree 1 2 mkdir charts cd charts Create a new chart or copy the source files of an existing chart 1 helm create chart-name Step 4: Automatic Publishing of New Chart Versions It would be tedious to manually package each new chart version, update the artifacts to GitHub, create a new release, and update the index.yaml file on the gh-pages brach which contains the Helm repository metadata. Instead, we can automate all of these tasks using GitHub actions. To do so, we will configure automatic linting of our charts as well as publishing. Switch to the master branch of your repository and create a new folder, .github/workflows which would contain the definition for our GitHub pipelines. 1 2 git checkout master mkdir -p .github/workflows Create a new file called linting.yaml with the content available below. This job will execute whenever there is a new pull request and will check whether it conforms to the best Helm charts writing practices. .github/workflows/linting.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 name : Helm Chart Linting on : pull_request : paths : - 'charts/**' jobs : lint-chart : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 - name : Set up Helm uses : azure/setup-helm@v1 with : version : v3.4.0 - uses : actions/setup-python@v2 with : python-version : 3.7 - name : Set up chart-testing uses : helm/chart-testing-action@v2.1.0 - name : Run chart-testing (list-changed) id : list-changed run : | changed=$(ct list-changed) if [[ -n \"$changed\" ]]; then echo \"::set-output name=changed::true\" fi - name : Run chart-testing (lint) run : ct lint --debug Once a pull request has been merged to master we want to automatically release a new version of the chart. For this purpose, we create a new workflow by defining the file release.yaml . .github/workflows/release.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 name : Release Charts on : push : branches : - master paths : - 'charts/**' jobs : release : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 - name : Configure Git run : | git config user.name \"$GITHUB_ACTOR\" git config user.email \"$GITHUB_ACTOR@users.noreply.github.com\" - name : Run chart-releaser uses : helm/chart-releaser-action@v1.2.1 env : CR_TOKEN : \"${{ secrets.GITHUB_TOKEN }}\" Commit the changes to these new files 1 2 3 git add . git commit -m \"add helm automation\" git push Step 5: Testing the Automations We have prepared the source code of the Helm chart in Step 3 and set up the required GitHub actions in Step 4. We are now ready to test our automation tools. Create a new branch with an arbitrary name 1 git checkout -b new-chart-version Open the charts/my-chart/Chart.yaml file and increment the version field of the chart Push the changes to GitHub 1 2 3 git add . git commit -m \"new chart version\" git push --set-upstream origin new-chart-version Go to your repository on GitHub and open a new pull request from the Pull requests page. As source branch choose the newly created one \u2013 new-chart-version . Opening a New Pull Request Choosing a Source Branch for the Pull Request Comparing Changes Between the Branches Once the pull request is created the lint workflow should be automatically triggered. You can check the status from Actions page on your GitHub repository. Check Status for the Lint Workflow Should everything go well, we are ready to merge the changes to master. Choose Pull requests and select the previously created one. Choose the option to automatically merge its changes. Merge Pull Request With the merging of the pull request, the second workflow that we defined should have automatically been triggered. Helm Chart Publishing Workflow As a result of this workflow, a new Release should have also been made in our repository. Previewing the Repository Release Release Details If we switch to the gh-pages branch, we can see that there is a new file that has been automatically created \u2013 index.yaml which contains the necessary metadata for the Helm Repository. index.yaml Metadata Step 6: Using the Helm Repository We are now ready to use our Helm repository by simply adding it to our list with the Helm client. 1 2 3 helm repo add local-repo-name https://github-username.github.io/repository-name helm repo update helm install release-name local-repo-name/chart-name You can find the generated link to your GitHub Pages website by navigating to Settings \u2192 Pages. Discovering the GitHub Pages URL Step 7: Generating a README File with Default Values for the Chart Each chart submitted for addition to the NMaaS catalog must have a README file containing all of the parameters that can be altered during its deployment. Such a README file can either be created manually or automatically. Helm-docs is one such tool for automated generation of chart descriptions. Download the latest release of helm-docs from the official Releases page: https://github.com/norwoodj/helm-docs/releases Install it locally: 1 sudo dpkg -i helm-docs_* Set the root of your Git repository as the working directory and execute the following command: 1 helm-docs --output-file \"../../README.md\" --dry-run We need to specify the --output-file parameter so that the README.md file will be created in the root of our repository instead of directly where the chart is located ( charts/my_chart ). If the output is satisfactory, execute the same command, but now without the --dry-run parameter and push the changes either to a new branch or directly to master . 1 2 3 4 helm-docs --output-file \"../../README.md\" git add . git commit -m \"add readme.md\" git push Conclusion We have created an automated pipeline using GitHub Actions which would automatically check all new changes to our chart and if accepted will release a new version of it, ready to be installed in an existing Kubernetes cluster. The workflow for releasing a new version of a chart is: creating a new branch and make the necessary changes, incrementing the version field in the Chart.yaml file. creating a new pull request to merge these changes to master . At this point the linting task will be executed. merge the changes to the master branch. At this point the release task will be executed. If you want to see your chart added to the NMaaS catalog please contact nmaas-admin@lists.geant.org with the following information: URL to the upstream source-code repository of the proposed application Brief description of its features URL to the Docker image backing the chart URL to the Helm repository A list of maintainers of the Helm repository","title":"Adding a New Application"},{"location":"nmaas-applications/new-application/#adding-a-new-application","text":"Anyone can submit an application to be included to the NMaaS catalog, thus making it available to all users of the production instance. Each application should have at least one official maintainer who will regularly pull changes from the upstream project and provide updated Docker images and Helm charts. The source code for each Helm chart should be hosted in a separate Git repository. A brief guide on how a new chart repository can be set up using the GitHub platform is presented below. Please note that we do not require the use of GitHub or mandate a specific code hosting service. Any platform that is publicly accessible would suffice. Process Explanation Applying for an application to be added to the NMaaS catalog is a two-step process. First, the chart needs to be created, and then a brief proposal submitted to the NMaaS team via email. After reviewing the chart, the user who submitted it will be assigned a new role on the production instance of NMaaS ( https://nmaas.eu ) \u2013 tool manager , which allows uploading of new versions and parameter changes.","title":"Adding a new Application"},{"location":"nmaas-applications/new-application/#step-1-create-a-new-github-repository","text":"Login or register a new account on GitHub and create a new public repository. Repositories can be created either as an individual user or as an organization. Creating a New GitHub Repository","title":"Step 1: Create a new GitHub Repository"},{"location":"nmaas-applications/new-application/#step-2-configure-github-pages-for-hosting-the-helm-repository","text":"GitHub has a free option for hosting static files for public repositories called GitHub Pages. This is a hugely popular tool for publicly hosting simple blogs or websites created using static site generators such as Hugo or Jekyll. However, in our case, this is also a perfect opportunity to host the index.yaml metadata file required for every Helm repository. To enable GitHub Pages for your project, the following steps need to be performed: Clone the newly created repository locally and a dummy .gitignore file which can be used later. 1 2 3 4 5 git clone git@github.com:USERNAME/REPOSITORY_NAME.git touch .gitignore git add . git commit -m \"add .gitignore\" git push --set-upstream origin master Warning Before pushing the changes to the remote and executing the git push command, make sure to correctly identify the name of the default Git branch. This varies from environment to environment, and in the case of GitHub, can be directly checked from the settings screen of the given repository (Settings \u2192 Branches). Create a new branch called gh-pages 1 2 3 4 git checkout --orphan gh-pages git rm -rf . git commit -m \"Initial commit\" --allow-empty git push --set-upstream origin gh-pages Once the branch is created, GitHub Pages can be officially enabled from the Settings page of your repository Enabling GitHub Pages If desirable, you can add any index.html file to the gh-pages branch, so that users are not presented with a 404 error when directly accessing the Helm repository root URL. Note that this has no effect on the functionality of the Helm repository itself.","title":"Step 2: Configure GitHub Pages for Hosting the Helm Repository"},{"location":"nmaas-applications/new-application/#step-3-preparing-the-chart","text":"We are now ready to publish the source code for our chart. The GitHub Actions that we will configure in the next step mandate that our charts are placed in a charts directory within the repository. Switch to the master branch of the repository 1 git checkout master Create the necessary directory tree 1 2 mkdir charts cd charts Create a new chart or copy the source files of an existing chart 1 helm create chart-name","title":"Step 3: Preparing the Chart"},{"location":"nmaas-applications/new-application/#step-4-automatic-publishing-of-new-chart-versions","text":"It would be tedious to manually package each new chart version, update the artifacts to GitHub, create a new release, and update the index.yaml file on the gh-pages brach which contains the Helm repository metadata. Instead, we can automate all of these tasks using GitHub actions. To do so, we will configure automatic linting of our charts as well as publishing. Switch to the master branch of your repository and create a new folder, .github/workflows which would contain the definition for our GitHub pipelines. 1 2 git checkout master mkdir -p .github/workflows Create a new file called linting.yaml with the content available below. This job will execute whenever there is a new pull request and will check whether it conforms to the best Helm charts writing practices. .github/workflows/linting.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 name : Helm Chart Linting on : pull_request : paths : - 'charts/**' jobs : lint-chart : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 - name : Set up Helm uses : azure/setup-helm@v1 with : version : v3.4.0 - uses : actions/setup-python@v2 with : python-version : 3.7 - name : Set up chart-testing uses : helm/chart-testing-action@v2.1.0 - name : Run chart-testing (list-changed) id : list-changed run : | changed=$(ct list-changed) if [[ -n \"$changed\" ]]; then echo \"::set-output name=changed::true\" fi - name : Run chart-testing (lint) run : ct lint --debug Once a pull request has been merged to master we want to automatically release a new version of the chart. For this purpose, we create a new workflow by defining the file release.yaml . .github/workflows/release.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 name : Release Charts on : push : branches : - master paths : - 'charts/**' jobs : release : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 - name : Configure Git run : | git config user.name \"$GITHUB_ACTOR\" git config user.email \"$GITHUB_ACTOR@users.noreply.github.com\" - name : Run chart-releaser uses : helm/chart-releaser-action@v1.2.1 env : CR_TOKEN : \"${{ secrets.GITHUB_TOKEN }}\" Commit the changes to these new files 1 2 3 git add . git commit -m \"add helm automation\" git push","title":"Step 4: Automatic Publishing of New Chart Versions"},{"location":"nmaas-applications/new-application/#step-5-testing-the-automations","text":"We have prepared the source code of the Helm chart in Step 3 and set up the required GitHub actions in Step 4. We are now ready to test our automation tools. Create a new branch with an arbitrary name 1 git checkout -b new-chart-version Open the charts/my-chart/Chart.yaml file and increment the version field of the chart Push the changes to GitHub 1 2 3 git add . git commit -m \"new chart version\" git push --set-upstream origin new-chart-version Go to your repository on GitHub and open a new pull request from the Pull requests page. As source branch choose the newly created one \u2013 new-chart-version . Opening a New Pull Request Choosing a Source Branch for the Pull Request Comparing Changes Between the Branches Once the pull request is created the lint workflow should be automatically triggered. You can check the status from Actions page on your GitHub repository. Check Status for the Lint Workflow Should everything go well, we are ready to merge the changes to master. Choose Pull requests and select the previously created one. Choose the option to automatically merge its changes. Merge Pull Request With the merging of the pull request, the second workflow that we defined should have automatically been triggered. Helm Chart Publishing Workflow As a result of this workflow, a new Release should have also been made in our repository. Previewing the Repository Release Release Details If we switch to the gh-pages branch, we can see that there is a new file that has been automatically created \u2013 index.yaml which contains the necessary metadata for the Helm Repository. index.yaml Metadata","title":"Step 5: Testing the Automations"},{"location":"nmaas-applications/new-application/#step-6-using-the-helm-repository","text":"We are now ready to use our Helm repository by simply adding it to our list with the Helm client. 1 2 3 helm repo add local-repo-name https://github-username.github.io/repository-name helm repo update helm install release-name local-repo-name/chart-name You can find the generated link to your GitHub Pages website by navigating to Settings \u2192 Pages. Discovering the GitHub Pages URL","title":"Step 6: Using the Helm Repository"},{"location":"nmaas-applications/new-application/#step-7-generating-a-readme-file-with-default-values-for-the-chart","text":"Each chart submitted for addition to the NMaaS catalog must have a README file containing all of the parameters that can be altered during its deployment. Such a README file can either be created manually or automatically. Helm-docs is one such tool for automated generation of chart descriptions. Download the latest release of helm-docs from the official Releases page: https://github.com/norwoodj/helm-docs/releases Install it locally: 1 sudo dpkg -i helm-docs_* Set the root of your Git repository as the working directory and execute the following command: 1 helm-docs --output-file \"../../README.md\" --dry-run We need to specify the --output-file parameter so that the README.md file will be created in the root of our repository instead of directly where the chart is located ( charts/my_chart ). If the output is satisfactory, execute the same command, but now without the --dry-run parameter and push the changes either to a new branch or directly to master . 1 2 3 4 helm-docs --output-file \"../../README.md\" git add . git commit -m \"add readme.md\" git push","title":"Step 7: Generating a README File with Default Values for the Chart"},{"location":"nmaas-applications/new-application/#conclusion","text":"We have created an automated pipeline using GitHub Actions which would automatically check all new changes to our chart and if accepted will release a new version of it, ready to be installed in an existing Kubernetes cluster. The workflow for releasing a new version of a chart is: creating a new branch and make the necessary changes, incrementing the version field in the Chart.yaml file. creating a new pull request to merge these changes to master . At this point the linting task will be executed. merge the changes to the master branch. At this point the release task will be executed. If you want to see your chart added to the NMaaS catalog please contact nmaas-admin@lists.geant.org with the following information: URL to the upstream source-code repository of the proposed application Brief description of its features URL to the Docker image backing the chart URL to the Helm repository A list of maintainers of the Helm repository","title":"Conclusion"},{"location":"nmaas-applications/tutorials/apache-airflow/","text":"Apache Airflow Apache Airflow is an open-source platform used for orchestrating complex workflows and data pipelines. It enables users to schedule, monitor, and manage tasks, allowing for efficient automation and streamlined data processing. Configuration Wizard The Airflow configuration wizard allows the deployment to be customized according to the user's needs. Fig. 1: First set of configuration options for Apache Airflow Fig. 2: Second set of configuration options for Apache Airflow The customizable fields are: Default user name - username for the default Airflow account which is automatically created. Default user password - password for the default Airflow account which is automatically created. Default user email address - email address for the default Airflow account which is automatically created. Allocated storage space for workers (in GB) - volume size for the persistent volumes attached to the Airflow workers. 10Gi is a good starting point which can be increased in the future, if needed. Allocated storage space for triggerer (in GB) - volume size for the persistent volumes attached to Airflow triggerers. 10Gi should be more than enough in most cases. Enable flower - if ticked, the Flower web interface will be deployed, allowing users to manage the Airflow task queues. Flower user name - username for the default Flower account. Flower uses basic authentication by default. Flower user password - password for the default Flower account. Flower uses basic authentication by default. Enable Git Sync - if ticked, Airflow will automatically fetch the contents from the remote Git repository as specified in the Git repository URL . The Git sync occurs periodically. Git repository URL (SSH format) - the URL of the Git repository hosting the Airflow workflows and which is to be synced periodically. The expected format is shown as a placeholder value in the input field itself. Example: git@github.com:nmaas-platform/airflow-demo.git . Git repsitory branch - the Git repository branch to be periodically synced. The branch must already exist. Git repository sub-directory (relative to repository root) - the folder where the Airflow workflow definitions are placed within the Git repository. Git maintainer SSH private key - the SSH private key which has already been authorized with at least a read-only access to the Git repository specified in the Git repository URL field. Necessary as to ensure that the Git sync component will be able to clone the repository. Git Sync Information The Git sync process utilized by the Apache Airflow Helm chart involves periodically pulling changes from a specified Git repository into the Airflow DAGs (Directed Acyclic Graphs) folder within the Airflow deployment. This enables users to manage and update their workflows directly in a version-controlled Git repository, ensuring consistency and accoutability in the development and deployment of data pipelines. It is possible to use either a public or a private repository. In case a private repository is used, the necessary SSH keys must be configured both on the Airflow side and on the platform hosting the Git repository. It is recommended to use a brand new SSH key pair for each Airflow deployment, to ensure safety. A new SSH key pair can be created using: 1 ssh-keygen After creating the SSH key pair, the public key should be added to the platform hosting the Git repository. For GitHub this can be done by navigating into the repository settings, and adding a new deploy key using the Deploy keys page. The corresponding private key should be pasted in the Git maintainer SSH private key in the default OpenSSH format. Since Git doesn't allow cloning only of a specific subdirectory within a repository, the setting Git repository sub-directory doesn't restrict which folders are cloned. Instead, it simply forces Airflow to only look for DAGs source code in the specified directory. If no value is specified in the deployment wizard, tests/dags is used by default. In order to search the whole repository . can simply be passed as a value to the Git repository sub-directory field. Please note that this is suboptimal with repositories that have a lot of other files, since the inotify watcher used for detecting file changes might easily hit the default system-wide threshold for monitored files. As a result, it is a best practice to keep a dedicated subdirectory for workflow files. Assuming that the Git repository directory tree is as the one below and airflow-demo is the root folder of the repository, then specifying dags as the value of the Git repository sub-directory field will only register the example-dag DAG with Airflow, leaving scratch.py ignored. Please note that since the whole repository is cloned anyhow, config files can be placed at an arbitrary location, even outside the specified dags directory. Airflow searches recursively within the subfolders in the Git repository sub-directory . Git submodules are also supported. 1 2 3 4 airflow-demo/ \u251c\u2500\u2500 dags \u2502 \u2514\u2500\u2500 example-dag.py \u2514\u2500\u2500 scratch.py Airflow clones the repository to /opt/airflow/dags/repo by default, which might be important in certain cases and when referring to absolute paths. The working directory during execution is /opt/airflow . However, it is best to not rely on using environment specific paths, and instead implement a platform agnostic approach, such as getting the full path to the Python file being currently executed and navigating from there: 1 2 import os dirname = os . path . dirname ( __file__ )","title":"Apache Airflow"},{"location":"nmaas-applications/tutorials/apache-airflow/#apache-airflow","text":"Apache Airflow is an open-source platform used for orchestrating complex workflows and data pipelines. It enables users to schedule, monitor, and manage tasks, allowing for efficient automation and streamlined data processing.","title":"Apache Airflow"},{"location":"nmaas-applications/tutorials/apache-airflow/#configuration-wizard","text":"The Airflow configuration wizard allows the deployment to be customized according to the user's needs. Fig. 1: First set of configuration options for Apache Airflow Fig. 2: Second set of configuration options for Apache Airflow The customizable fields are: Default user name - username for the default Airflow account which is automatically created. Default user password - password for the default Airflow account which is automatically created. Default user email address - email address for the default Airflow account which is automatically created. Allocated storage space for workers (in GB) - volume size for the persistent volumes attached to the Airflow workers. 10Gi is a good starting point which can be increased in the future, if needed. Allocated storage space for triggerer (in GB) - volume size for the persistent volumes attached to Airflow triggerers. 10Gi should be more than enough in most cases. Enable flower - if ticked, the Flower web interface will be deployed, allowing users to manage the Airflow task queues. Flower user name - username for the default Flower account. Flower uses basic authentication by default. Flower user password - password for the default Flower account. Flower uses basic authentication by default. Enable Git Sync - if ticked, Airflow will automatically fetch the contents from the remote Git repository as specified in the Git repository URL . The Git sync occurs periodically. Git repository URL (SSH format) - the URL of the Git repository hosting the Airflow workflows and which is to be synced periodically. The expected format is shown as a placeholder value in the input field itself. Example: git@github.com:nmaas-platform/airflow-demo.git . Git repsitory branch - the Git repository branch to be periodically synced. The branch must already exist. Git repository sub-directory (relative to repository root) - the folder where the Airflow workflow definitions are placed within the Git repository. Git maintainer SSH private key - the SSH private key which has already been authorized with at least a read-only access to the Git repository specified in the Git repository URL field. Necessary as to ensure that the Git sync component will be able to clone the repository.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/apache-airflow/#git-sync-information","text":"The Git sync process utilized by the Apache Airflow Helm chart involves periodically pulling changes from a specified Git repository into the Airflow DAGs (Directed Acyclic Graphs) folder within the Airflow deployment. This enables users to manage and update their workflows directly in a version-controlled Git repository, ensuring consistency and accoutability in the development and deployment of data pipelines. It is possible to use either a public or a private repository. In case a private repository is used, the necessary SSH keys must be configured both on the Airflow side and on the platform hosting the Git repository. It is recommended to use a brand new SSH key pair for each Airflow deployment, to ensure safety. A new SSH key pair can be created using: 1 ssh-keygen After creating the SSH key pair, the public key should be added to the platform hosting the Git repository. For GitHub this can be done by navigating into the repository settings, and adding a new deploy key using the Deploy keys page. The corresponding private key should be pasted in the Git maintainer SSH private key in the default OpenSSH format. Since Git doesn't allow cloning only of a specific subdirectory within a repository, the setting Git repository sub-directory doesn't restrict which folders are cloned. Instead, it simply forces Airflow to only look for DAGs source code in the specified directory. If no value is specified in the deployment wizard, tests/dags is used by default. In order to search the whole repository . can simply be passed as a value to the Git repository sub-directory field. Please note that this is suboptimal with repositories that have a lot of other files, since the inotify watcher used for detecting file changes might easily hit the default system-wide threshold for monitored files. As a result, it is a best practice to keep a dedicated subdirectory for workflow files. Assuming that the Git repository directory tree is as the one below and airflow-demo is the root folder of the repository, then specifying dags as the value of the Git repository sub-directory field will only register the example-dag DAG with Airflow, leaving scratch.py ignored. Please note that since the whole repository is cloned anyhow, config files can be placed at an arbitrary location, even outside the specified dags directory. Airflow searches recursively within the subfolders in the Git repository sub-directory . Git submodules are also supported. 1 2 3 4 airflow-demo/ \u251c\u2500\u2500 dags \u2502 \u2514\u2500\u2500 example-dag.py \u2514\u2500\u2500 scratch.py Airflow clones the repository to /opt/airflow/dags/repo by default, which might be important in certain cases and when referring to absolute paths. The working directory during execution is /opt/airflow . However, it is best to not rely on using environment specific paths, and instead implement a platform agnostic approach, such as getting the full path to the Python file being currently executed and navigating from there: 1 2 import os dirname = os . path . dirname ( __file__ )","title":"Git Sync Information"},{"location":"nmaas-applications/tutorials/bastion/","text":"Bastion Ubuntu-based bastion server deployed in a customer domain has VPN access to all the monitored devices. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base tab SSH keys (comma separated) - A list of SSH keys to be added on the Bastion at startup Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Bastion instance (default value is displayed in the placeholder, in this case 5 Gigabyte), e.g. 1 , 2 or 3 .","title":"Bastion"},{"location":"nmaas-applications/tutorials/bastion/#bastion","text":"Ubuntu-based bastion server deployed in a customer domain has VPN access to all the monitored devices.","title":"Bastion"},{"location":"nmaas-applications/tutorials/bastion/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/bastion/#base-tab","text":"SSH keys (comma separated) - A list of SSH keys to be added on the Bastion at startup","title":"Base tab"},{"location":"nmaas-applications/tutorials/bastion/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Bastion instance (default value is displayed in the placeholder, in this case 5 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/booked/","text":"Booked A web-based calendar and resource scheduling system that allows administered management of reservations on any number of resources. Assumptions Note The default password after the initial deployment is password . Default Credentials As stated in the Customizable Parameters section, the admin username is the administrator's email address that is specified during the deployment process directly from the NMaaS web interface. The default password is simply password . Users are strongly encouraged to change the default password of their admin accounts after the initial login. Configuration wizard Configuration parameters to be provided by the user are explained in the subsections below. Base tab Administrator email address - An email address to be used during first login Enable email notifications [Optional] - Checkbox. If selected, email notification generated by Booked are enabled. Enable user registration [Optional] - Checkbox. If selected, new users are allowed to register. Enable use of Booked API [Optional] - Checkbox. If selected, the API is enabled. Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Booked instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Booked"},{"location":"nmaas-applications/tutorials/booked/#booked","text":"A web-based calendar and resource scheduling system that allows administered management of reservations on any number of resources.","title":"Booked"},{"location":"nmaas-applications/tutorials/booked/#assumptions","text":"Note The default password after the initial deployment is password .","title":"Assumptions"},{"location":"nmaas-applications/tutorials/booked/#default-credentials","text":"As stated in the Customizable Parameters section, the admin username is the administrator's email address that is specified during the deployment process directly from the NMaaS web interface. The default password is simply password . Users are strongly encouraged to change the default password of their admin accounts after the initial login.","title":"Default Credentials"},{"location":"nmaas-applications/tutorials/booked/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration wizard"},{"location":"nmaas-applications/tutorials/booked/#base-tab","text":"Administrator email address - An email address to be used during first login Enable email notifications [Optional] - Checkbox. If selected, email notification generated by Booked are enabled. Enable user registration [Optional] - Checkbox. If selected, new users are allowed to register. Enable use of Booked API [Optional] - Checkbox. If selected, the API is enabled.","title":"Base tab"},{"location":"nmaas-applications/tutorials/booked/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Booked instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/changedetectionio/","text":"Introduction ChangeDetection.io is an open-source tool for website change detection. It is capable of monitoring HTML and JSON files and can send various types of notifications when a change is detected. Using XPath or CSS selectors it is also possible to only watch specific page elements. Interactive websites relying heavily on JavaScript can be crawled using a headless Chrome instance which is also deployed on NMaaS together with the base application. Customizable Parameters ChangeDetection.io does not have any parameters that need to be customized during the initial deployment on NMaaS. All configuration is done from the built-in configuration manager accessible once the application is deployed. Examples Fig. 1: ChangeDetection.io Home Screen Fig. 2: Configuring Notification Options Fig. 3: Configuring Fetching Mechanism Fig. 4: Previewing Changes Diff Notifications ChangeDetection.io has support for various notification providers, using the Apprise library . Details about each supported notification provider are given on the Apprise Wiki , as well as on the ChangeDetection.io wiki pages. In terms of the managed NMaaS production instance, users can leverage the built-in mail sender, using the following configuration: 1 mailto://nmaas.eu:587?smtp=nmaas-postfix.nmaas-system&from=changedetection.$domain-name@nmaas.eu&to=$dest-email The parameters $domain-name and $dest-name are up to the user to replace with the specific values, as needed. For example, for the domain name nmaas-test and an admin email of contact@example.com , the configuration would be: 1 mailto://nmaas.eu:587?smtp=nmaas-postfix.nmaas-system&from=changedetection.nmaas-test@nmaas.eu&to=contact@example.com Conclusion For more information and a complete features list, consult the up-to-date ChangeDetection.io Wiki on GitHub.","title":"ChangeDetection.io"},{"location":"nmaas-applications/tutorials/changedetectionio/#introduction","text":"ChangeDetection.io is an open-source tool for website change detection. It is capable of monitoring HTML and JSON files and can send various types of notifications when a change is detected. Using XPath or CSS selectors it is also possible to only watch specific page elements. Interactive websites relying heavily on JavaScript can be crawled using a headless Chrome instance which is also deployed on NMaaS together with the base application.","title":"Introduction"},{"location":"nmaas-applications/tutorials/changedetectionio/#customizable-parameters","text":"ChangeDetection.io does not have any parameters that need to be customized during the initial deployment on NMaaS. All configuration is done from the built-in configuration manager accessible once the application is deployed.","title":"Customizable Parameters"},{"location":"nmaas-applications/tutorials/changedetectionio/#examples","text":"Fig. 1: ChangeDetection.io Home Screen Fig. 2: Configuring Notification Options Fig. 3: Configuring Fetching Mechanism Fig. 4: Previewing Changes Diff","title":"Examples"},{"location":"nmaas-applications/tutorials/changedetectionio/#notifications","text":"ChangeDetection.io has support for various notification providers, using the Apprise library . Details about each supported notification provider are given on the Apprise Wiki , as well as on the ChangeDetection.io wiki pages. In terms of the managed NMaaS production instance, users can leverage the built-in mail sender, using the following configuration: 1 mailto://nmaas.eu:587?smtp=nmaas-postfix.nmaas-system&from=changedetection.$domain-name@nmaas.eu&to=$dest-email The parameters $domain-name and $dest-name are up to the user to replace with the specific values, as needed. For example, for the domain name nmaas-test and an admin email of contact@example.com , the configuration would be: 1 mailto://nmaas.eu:587?smtp=nmaas-postfix.nmaas-system&from=changedetection.nmaas-test@nmaas.eu&to=contact@example.com","title":"Notifications"},{"location":"nmaas-applications/tutorials/changedetectionio/#conclusion","text":"For more information and a complete features list, consult the up-to-date ChangeDetection.io Wiki on GitHub.","title":"Conclusion"},{"location":"nmaas-applications/tutorials/codimd/","text":"CodiMD CodiMD lets you collaborate in real-time with markdown. It is an open-source version of the popular HackMD software, letting you host and control your team's content with speed and ease.","title":"CodiMD"},{"location":"nmaas-applications/tutorials/codimd/#codimd","text":"CodiMD lets you collaborate in real-time with markdown. It is an open-source version of the popular HackMD software, letting you host and control your team's content with speed and ease.","title":"CodiMD"},{"location":"nmaas-applications/tutorials/debian-repository/","text":"Debian Repository Debian repository based on Reprepro is a tool for managing APT repositories. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base Tab `SSH keys (comma separated)`` - A list of SSH keys to be added on the repository at startup Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this repository instance (default value is displayed in the placeholder, in this case 5 Gigabyte), e.g. 1 , 2 or 3 .","title":"Debian Repository"},{"location":"nmaas-applications/tutorials/debian-repository/#debian-repository","text":"Debian repository based on Reprepro is a tool for managing APT repositories.","title":"Debian Repository"},{"location":"nmaas-applications/tutorials/debian-repository/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/debian-repository/#base-tab","text":"`SSH keys (comma separated)`` - A list of SSH keys to be added on the repository at startup","title":"Base Tab"},{"location":"nmaas-applications/tutorials/debian-repository/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this repository instance (default value is displayed in the placeholder, in this case 5 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/elk-stack/","text":"ELK Stack \"ELK\" is the acronym for three open source projects: Elasticsearch, Logstash, and Kibana. Elasticsearch is a search and analytics engine. Logstash is a server\u2011side data processing pipeline that ingests data from multiple sources simultaneously, transforms it, and then sends it to a \"stash\" like Elasticsearch. Kibana lets users visualize data with charts and graphs in Elasticsearch.","title":"ELK Stack"},{"location":"nmaas-applications/tutorials/elk-stack/#elk-stack","text":"\"ELK\" is the acronym for three open source projects: Elasticsearch, Logstash, and Kibana. Elasticsearch is a search and analytics engine. Logstash is a server\u2011side data processing pipeline that ingests data from multiple sources simultaneously, transforms it, and then sends it to a \"stash\" like Elasticsearch. Kibana lets users visualize data with charts and graphs in Elasticsearch.","title":"ELK Stack"},{"location":"nmaas-applications/tutorials/esmond/","text":"Esmond Esmond is a system for collecting, storing, visualizing and analysing large sets of timeseries data.","title":"Esmond"},{"location":"nmaas-applications/tutorials/esmond/#esmond","text":"Esmond is a system for collecting, storing, visualizing and analysing large sets of timeseries data.","title":"Esmond"},{"location":"nmaas-applications/tutorials/gp4l-orchestrator/","text":"GP4L Orchestrator (Camunda and Uptime Kuma) The GP4L Orchestrator is used to orchestrate the network management tools used to manage the GP4L network. These include NetBox acting as a single source of truth, Uptime Kuma used for network monitoring using ping probes, and Oxidized for automated network configuration backup. Note that an Uptime Kuma instance will be created with the instantiation of the GP4L orchestrator. Separate NetBox and Oxidized instances should be first created so that they can be linked to the Camunda orchestrator using the configuration wizard. Configuration Wizard Configuration parameters to be provided by the user are explained in the list below: Username for the Camunda administrator - Username that is used for accessing the Camunda web UI Password for the Camunda administrator - password related to the defined username Default Camunda email recipient - one or more comma separated emails to which the Camunda orchestration processes will send email notifications Send email on create Y/N - Should an email be sent every time a new monitoring probe is being created Send email on modify Y/N - Should an email be sent every time a monitoring probe is being reconfigured Send email on pause Y/N - Should an email be sent every time a monitoring probe is being paused Send email on resume Y/N - Should an email be sent every time a monitoring probe is being resumed NetBox API URL - the API URL for the NetBox instance that is being used as a single source of truth (don't forget the /api at the end of the URL) NetBox API token - the API token used for secure connection, this can be randomly generated Username for the Uptime Kuma web server - the username that is to be used to access the Uptime Kuma web UI, all Camunda created probes will be associated with this username only Password for the Uptime Kuma web server - password related to the defined username Password for the Uptime Kuma API - password used to authenticate to the Uptime Kuma API Oxidized Git repository URL - URL to the Git repository related to the Oxidized instance that is to be used Email addresses to receive the generated repository access SSH public key - once the Camunda orchestrator is setup and initialized it will generate a pair of ssh keys used to access the Oxidized Git repository. The public key of this pair will be sent to this email address and will then need to be copy pasted to the NMaaS user profile. (Note: check the junk folder) The name to use for all Git commits created by Camunda - name under which all Git changes will be made The email to use for all Git commits created by Camunda - email under which all Git changes will be made Finalizing Configuration Once the GP4L orchestrator instance is up and running, before you are able to use the orchestration processes, you need to setup appropriate webhooks in the related NetBox instance. The configuration that needs to be made is provided in the image below. Make sure that you replace the 'camunda_url' part with the actual URL of the instance of Camunda that has been created.","title":"GP4L Orchestrator"},{"location":"nmaas-applications/tutorials/gp4l-orchestrator/#gp4l-orchestrator-camunda-and-uptime-kuma","text":"The GP4L Orchestrator is used to orchestrate the network management tools used to manage the GP4L network. These include NetBox acting as a single source of truth, Uptime Kuma used for network monitoring using ping probes, and Oxidized for automated network configuration backup. Note that an Uptime Kuma instance will be created with the instantiation of the GP4L orchestrator. Separate NetBox and Oxidized instances should be first created so that they can be linked to the Camunda orchestrator using the configuration wizard.","title":"GP4L Orchestrator (Camunda and Uptime Kuma)"},{"location":"nmaas-applications/tutorials/gp4l-orchestrator/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the list below: Username for the Camunda administrator - Username that is used for accessing the Camunda web UI Password for the Camunda administrator - password related to the defined username Default Camunda email recipient - one or more comma separated emails to which the Camunda orchestration processes will send email notifications Send email on create Y/N - Should an email be sent every time a new monitoring probe is being created Send email on modify Y/N - Should an email be sent every time a monitoring probe is being reconfigured Send email on pause Y/N - Should an email be sent every time a monitoring probe is being paused Send email on resume Y/N - Should an email be sent every time a monitoring probe is being resumed NetBox API URL - the API URL for the NetBox instance that is being used as a single source of truth (don't forget the /api at the end of the URL) NetBox API token - the API token used for secure connection, this can be randomly generated Username for the Uptime Kuma web server - the username that is to be used to access the Uptime Kuma web UI, all Camunda created probes will be associated with this username only Password for the Uptime Kuma web server - password related to the defined username Password for the Uptime Kuma API - password used to authenticate to the Uptime Kuma API Oxidized Git repository URL - URL to the Git repository related to the Oxidized instance that is to be used Email addresses to receive the generated repository access SSH public key - once the Camunda orchestrator is setup and initialized it will generate a pair of ssh keys used to access the Oxidized Git repository. The public key of this pair will be sent to this email address and will then need to be copy pasted to the NMaaS user profile. (Note: check the junk folder) The name to use for all Git commits created by Camunda - name under which all Git changes will be made The email to use for all Git commits created by Camunda - email under which all Git changes will be made","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/gp4l-orchestrator/#finalizing-configuration","text":"Once the GP4L orchestrator instance is up and running, before you are able to use the orchestration processes, you need to setup appropriate webhooks in the related NetBox instance. The configuration that needs to be made is provided in the image below. Make sure that you replace the 'camunda_url' part with the actual URL of the instance of Camunda that has been created.","title":"Finalizing Configuration"},{"location":"nmaas-applications/tutorials/grafana/","text":"Grafana Grafana is an open source, feature rich metrics dashboard and graph editor for Graphite, Elasticsearch, OpenTSDB, Prometheus and InfluxDB. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base tab Grafana admin username - Username to be used to access the Grafana user interface Grafana admin password - Password to be used to access the Grafana user interface Connect to existing Prometheus instance [Optional] - If selected, additional fields are displayed allowing to provide information about a Prometheus instance that should be added as a default data source in Grafana NMaaS Prometheus instance / External Prometheus instance - Switch between the type of Prometheus instance that should be used as the data source Data source name - The custom data source name that will be assigned to this Prometheus instance Select Prometheus instance (if NMaaS Prometheus instance is selected) - Pick list allowing to select an instance of Prometheus deployed and already running in the same domain as the Grafana being configured Prometheus instance address (if External Prometheus instance is selected) - URL of the standalone Prometheus instance to be used Additional tab SMTP host [Optional] - The hostname or IP (followed by optional port number) of the SMTP server to be used to send out email notifications. By default it is set to a Postfix instance running locally within the Kubernetes cluster and shared among all the services. SMTP username [Optional] - Username for authorization on the SMTP server (if required) SMTP user password [Optional] - Password for authorization on the SMTP server (if required) Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Grafana instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Grafana"},{"location":"nmaas-applications/tutorials/grafana/#grafana","text":"Grafana is an open source, feature rich metrics dashboard and graph editor for Graphite, Elasticsearch, OpenTSDB, Prometheus and InfluxDB.","title":"Grafana"},{"location":"nmaas-applications/tutorials/grafana/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/grafana/#base-tab","text":"Grafana admin username - Username to be used to access the Grafana user interface Grafana admin password - Password to be used to access the Grafana user interface Connect to existing Prometheus instance [Optional] - If selected, additional fields are displayed allowing to provide information about a Prometheus instance that should be added as a default data source in Grafana NMaaS Prometheus instance / External Prometheus instance - Switch between the type of Prometheus instance that should be used as the data source Data source name - The custom data source name that will be assigned to this Prometheus instance Select Prometheus instance (if NMaaS Prometheus instance is selected) - Pick list allowing to select an instance of Prometheus deployed and already running in the same domain as the Grafana being configured Prometheus instance address (if External Prometheus instance is selected) - URL of the standalone Prometheus instance to be used","title":"Base tab"},{"location":"nmaas-applications/tutorials/grafana/#additional-tab","text":"SMTP host [Optional] - The hostname or IP (followed by optional port number) of the SMTP server to be used to send out email notifications. By default it is set to a Postfix instance running locally within the Kubernetes cluster and shared among all the services. SMTP username [Optional] - Username for authorization on the SMTP server (if required) SMTP user password [Optional] - Password for authorization on the SMTP server (if required)","title":"Additional tab"},{"location":"nmaas-applications/tutorials/grafana/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Grafana instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/icinga2/","text":"Icinga2 Icinga 2 is a monitoring system which checks the availability of your network resources, notifies users of outages, and generates performance data for reporting. Scalable and extensible, Icinga can monitor large, complex environments across multiple locations. Icinga 2 is the monitoring server and requires Icinga Web 2 on top in your Icinga Stack, which is already included as part of the NMaaS deployment. The configuration can be easily managed with either the Icinga Director, config management tools or plain text within the Icinga DSL.","title":"Icinga2"},{"location":"nmaas-applications/tutorials/icinga2/#icinga2","text":"Icinga 2 is a monitoring system which checks the availability of your network resources, notifies users of outages, and generates performance data for reporting. Scalable and extensible, Icinga can monitor large, complex environments across multiple locations. Icinga 2 is the monitoring server and requires Icinga Web 2 on top in your Icinga Stack, which is already included as part of the NMaaS deployment. The configuration can be easily managed with either the Icinga Director, config management tools or plain text within the Icinga DSL.","title":"Icinga2"},{"location":"nmaas-applications/tutorials/influxdb/","text":"InfluxDB InfluxDB is an open-source time series database (TSDB) developed by InfluxData.","title":"InfluxDB"},{"location":"nmaas-applications/tutorials/influxdb/#influxdb","text":"InfluxDB is an open-source time series database (TSDB) developed by InfluxData.","title":"InfluxDB"},{"location":"nmaas-applications/tutorials/jenkins/","text":"Jenkins Jenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.","title":"Jenkins"},{"location":"nmaas-applications/tutorials/jenkins/#jenkins","text":"Jenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.","title":"Jenkins"},{"location":"nmaas-applications/tutorials/librenms/","text":"LibreNMS LibreNMS is an auto-discovering PHP/MySQL/SNMP based network monitoring system which includes support for a wide range of network hardware and operating systems. Configuration Wizard Configuration parameters to be provided by the user are divided into two tabs: Base tab and Advanced tab . NMaaS LibreNMS Application Wizard Base Tab Default username - Username to be used to access the LibreNMS user interface Default user password - Password to be used to access the LibreNMS user interface Default user email [Optional] - Email address of the user configured by default in the application Device (IP address) - IPv4 address of device to be monitored by this LibreNMS instance SNMP community - Community to be used by LibreNMS to pool data from the device to be monitored SNMP version - Version of SNMP available on the device to be monitored Multiple devices can be configured by using the Add device button. Advanced Tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this LibreNMS instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 .","title":"LibreNMS"},{"location":"nmaas-applications/tutorials/librenms/#librenms","text":"LibreNMS is an auto-discovering PHP/MySQL/SNMP based network monitoring system which includes support for a wide range of network hardware and operating systems.","title":"LibreNMS"},{"location":"nmaas-applications/tutorials/librenms/#configuration-wizard","text":"Configuration parameters to be provided by the user are divided into two tabs: Base tab and Advanced tab . NMaaS LibreNMS Application Wizard","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/librenms/#base-tab","text":"Default username - Username to be used to access the LibreNMS user interface Default user password - Password to be used to access the LibreNMS user interface Default user email [Optional] - Email address of the user configured by default in the application Device (IP address) - IPv4 address of device to be monitored by this LibreNMS instance SNMP community - Community to be used by LibreNMS to pool data from the device to be monitored SNMP version - Version of SNMP available on the device to be monitored Multiple devices can be configured by using the Add device button.","title":"Base Tab"},{"location":"nmaas-applications/tutorials/librenms/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this LibreNMS instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 .","title":"Advanced Tab"},{"location":"nmaas-applications/tutorials/maddash/","text":"MaDDash MaDDash is a tool for collecting large amounts of inherently two-dimensional data and presenting it in visually useful ways.","title":"MaDDash"},{"location":"nmaas-applications/tutorials/maddash/#maddash","text":"MaDDash is a tool for collecting large amounts of inherently two-dimensional data and presenting it in visually useful ways.","title":"MaDDash"},{"location":"nmaas-applications/tutorials/maildev/","text":"MailDev Introduction MailDev is a simple application that can be used during the development process to simulate an email server. The core idea is to be able to use MailDev as an SMTP server, without having to register for a commercial SMTP service. MailDev provides a web interface where all \"sent\" emails can be previewed. MailDev itself does not send the emails to their final destination, instead just logs them so that they are visible on the web interface and discards them. This makes it possible to use MailDev for testing purposes, without having to worry about rate limits, deliverability, or spam. Deploying MailDev on NMaaS The MailDev application on NMaaS is primarily aimed at users of the virtual lab use-case. For production applications instantiated on the managed instance of NMaaS, it is possible to use the NMaaS email server, and this is the case by default for most tools already in the catalog. To deploy and configure MailDev on NMaaS, the following steps need to be performed: Subscribe to the application from the Application list. Navigate to the Subscriptions page and initiate the deployment of a new MailDev instnace, by entering the name and desired version. Fig. 1: New MailDev Instance Use the deployment wizard to further customize your new MailDev instance. The current version of the deployment wizard allows the set up of a basic HTTP authentication to the MailDev web interface. This might be useful if multiple users have access to your NMaaS domain. Fig. 2: Configuring the new MailDev Instance Finish the new instance configuration and wait for the deployment process to complete. Fig. 3: Accessing the new MailDev Instance Once deployed, the MailDev web interface becomes available. At this point, any existing application which supports SMTP based notifications can be configured to use the MailDev SMTP implementation with the following settings: SMTP server address: (the correct hostname is shown in the access modes modal on NMaaS) SMTP server port: 1025 SMTP Username: / SMTP Password: / Security: PLAIN An example configuration is available below, as well as a screenshot showing a test message visible on the MailDev web interface. Fig. 4: Configuration of a 3rd Party Application Fig. 5: Previewing Emails on MailDev","title":"MailDev"},{"location":"nmaas-applications/tutorials/maildev/#maildev","text":"","title":"MailDev"},{"location":"nmaas-applications/tutorials/maildev/#introduction","text":"MailDev is a simple application that can be used during the development process to simulate an email server. The core idea is to be able to use MailDev as an SMTP server, without having to register for a commercial SMTP service. MailDev provides a web interface where all \"sent\" emails can be previewed. MailDev itself does not send the emails to their final destination, instead just logs them so that they are visible on the web interface and discards them. This makes it possible to use MailDev for testing purposes, without having to worry about rate limits, deliverability, or spam.","title":"Introduction"},{"location":"nmaas-applications/tutorials/maildev/#deploying-maildev-on-nmaas","text":"The MailDev application on NMaaS is primarily aimed at users of the virtual lab use-case. For production applications instantiated on the managed instance of NMaaS, it is possible to use the NMaaS email server, and this is the case by default for most tools already in the catalog. To deploy and configure MailDev on NMaaS, the following steps need to be performed: Subscribe to the application from the Application list. Navigate to the Subscriptions page and initiate the deployment of a new MailDev instnace, by entering the name and desired version. Fig. 1: New MailDev Instance Use the deployment wizard to further customize your new MailDev instance. The current version of the deployment wizard allows the set up of a basic HTTP authentication to the MailDev web interface. This might be useful if multiple users have access to your NMaaS domain. Fig. 2: Configuring the new MailDev Instance Finish the new instance configuration and wait for the deployment process to complete. Fig. 3: Accessing the new MailDev Instance Once deployed, the MailDev web interface becomes available. At this point, any existing application which supports SMTP based notifications can be configured to use the MailDev SMTP implementation with the following settings: SMTP server address: (the correct hostname is shown in the access modes modal on NMaaS) SMTP server port: 1025 SMTP Username: / SMTP Password: / Security: PLAIN An example configuration is available below, as well as a screenshot showing a test message visible on the MailDev web interface. Fig. 4: Configuration of a 3rd Party Application Fig. 5: Previewing Emails on MailDev","title":"Deploying MailDev on NMaaS"},{"location":"nmaas-applications/tutorials/nav/","text":"NAV Network Administration Visualized (NAV) is an advanced software suite to monitor large computer networks. It automatically discovers network topology, monitors network load and outages, and can send alerts on network events by e-mail and SMS. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base Tab No settings need to be customized in the Base Tab . Additional Tab Admin email [Optional] - Default NAV administrator email address Default sender email [Optional] - Default email address to be used as sender address for email notifications Multiple devices can be configured by using the Add device button. Advanced Tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this NAV instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 .","title":"NAV"},{"location":"nmaas-applications/tutorials/nav/#nav","text":"Network Administration Visualized (NAV) is an advanced software suite to monitor large computer networks. It automatically discovers network topology, monitors network load and outages, and can send alerts on network events by e-mail and SMS.","title":"NAV"},{"location":"nmaas-applications/tutorials/nav/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/nav/#base-tab","text":"No settings need to be customized in the Base Tab .","title":"Base Tab"},{"location":"nmaas-applications/tutorials/nav/#additional-tab","text":"Admin email [Optional] - Default NAV administrator email address Default sender email [Optional] - Default email address to be used as sender address for email notifications Multiple devices can be configured by using the Add device button.","title":"Additional Tab"},{"location":"nmaas-applications/tutorials/nav/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this NAV instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 .","title":"Advanced Tab"},{"location":"nmaas-applications/tutorials/netbox/","text":"Netbox NetBox is an infrastructure resource modeling (IRM) application designed to empower network automation. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It encompasses the following aspects of network management: IP address management (IPAM) - IP networks and addresses, VRFs, and VLANs Equipment racks - Organized by group and site Devices - Types of devices and where they are installed Connections - Network, console, and power connections among devices Virtualization - Virtual machines and clusters Data circuits - Long-haul communications circuits and providers","title":"Netbox"},{"location":"nmaas-applications/tutorials/netbox/#netbox","text":"NetBox is an infrastructure resource modeling (IRM) application designed to empower network automation. Initially conceived by the network engineering team at DigitalOcean, NetBox was developed specifically to address the needs of network and infrastructure engineers. It encompasses the following aspects of network management: IP address management (IPAM) - IP networks and addresses, VRFs, and VLANs Equipment racks - Organized by group and site Devices - Types of devices and where they are installed Connections - Network, console, and power connections among devices Virtualization - Virtual machines and clusters Data circuits - Long-haul communications circuits and providers","title":"Netbox"},{"location":"nmaas-applications/tutorials/oxidized/","text":"Oxidized Oxidized is a simple open-source device configuration backup tool exposing a web-based GUI. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base Tab Oxidized access username - Username to be used to access the Oxidized user interface (HTTP basic auth) Oxidized access password - Password to be used to access the Oxidized user interface (HTTP basic auth) Device access username - Username to be used by Oxidized to connect to the monitored device with SSH (to be configured on the device) Device access password - Password to be used by Oxidized to connect to the monitored device with SSH (to be configured on the device) Device (IP address) - List of IPv4 addresses of devices to be monitored by this Oxidized instance Multiple devices can be configured by using the Add device button. Advanced Tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Oxidized instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 . Configuration Update Oxidized allows for updating tools configuration during runtime. User should follow the steps described on the NMaaS Tool Configuration Process page. Inside the repository two files are being created by default, namely config and router.db , and are placed in the base directory. If a new device model needs to be specified the dedicated model description files should be placed in the model directory.","title":"Oxidized"},{"location":"nmaas-applications/tutorials/oxidized/#oxidized","text":"Oxidized is a simple open-source device configuration backup tool exposing a web-based GUI.","title":"Oxidized"},{"location":"nmaas-applications/tutorials/oxidized/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/oxidized/#base-tab","text":"Oxidized access username - Username to be used to access the Oxidized user interface (HTTP basic auth) Oxidized access password - Password to be used to access the Oxidized user interface (HTTP basic auth) Device access username - Username to be used by Oxidized to connect to the monitored device with SSH (to be configured on the device) Device access password - Password to be used by Oxidized to connect to the monitored device with SSH (to be configured on the device) Device (IP address) - List of IPv4 addresses of devices to be monitored by this Oxidized instance Multiple devices can be configured by using the Add device button.","title":"Base Tab"},{"location":"nmaas-applications/tutorials/oxidized/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Oxidized instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced Tab"},{"location":"nmaas-applications/tutorials/oxidized/#configuration-update","text":"Oxidized allows for updating tools configuration during runtime. User should follow the steps described on the NMaaS Tool Configuration Process page. Inside the repository two files are being created by default, namely config and router.db , and are placed in the base directory. If a new device model needs to be specified the dedicated model description files should be placed in the model directory.","title":"Configuration Update"},{"location":"nmaas-applications/tutorials/perfsonar-central-management/","text":"perfSONAR Central Management A set of perfSONAR central management components comprising psConfig Web Admin , MaDDash and Esmond .","title":"perfSONAR Central Management"},{"location":"nmaas-applications/tutorials/perfsonar-central-management/#perfsonar-central-management","text":"A set of perfSONAR central management components comprising psConfig Web Admin , MaDDash and Esmond .","title":"perfSONAR Central Management"},{"location":"nmaas-applications/tutorials/prometheus/","text":"Prometheus Prometheus is an open-source systems monitoring and alerting toolkit. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base tab Prometheus access username - Username to be used to access the Prometheus user interface (HTTP basic auth) Prometheus access password - Password to be used to access the Prometheus user interface (HTTP basic auth) Global scrape [Optional] - How frequently to scrape targets by default Global evaluation [Optional] - How frequently to evaluate rules Job name - The job name assigned to scraped metrics by default Scrape internal - How frequently to scrape targets from this job Metrics path - The HTTP resource path on which to fetch metrics from targets Targets / IP address and port - The targets specified by the static config (multiple allowed) Labels / Label name & Label value [Optional] - Labels assigned to all metrics scraped from the targets (multiple allowed) Multiple jobs can be configured by using the Add job button. Target is a valid string consisting of a hostname or IP followed by an optional port number. For detailed description of the above parameters please refer to Prometheus online documentation. Additional tab Retention data size [Optional] - The size of storage space up to which the monitoring data should be retained (default value is displayed in the placeholder, in this case 18 Gigabytes), e.g. 18GB , 25GB or 30GB . Retention period [Optional] - The time period for which the monitoring data should be retained (default value is displayed in the placeholder, in this case 15 days), e.g. 15d , 25d or 35d . The value of Retention data size should be kept lower than the value of requested Storage space . Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Prometheus instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 . Prometheus allows for updating the configuration of an already running instance. A configuration update wizard is launched by the Update button available on the application instance details page.","title":"Prometheus"},{"location":"nmaas-applications/tutorials/prometheus/#prometheus","text":"Prometheus is an open-source systems monitoring and alerting toolkit.","title":"Prometheus"},{"location":"nmaas-applications/tutorials/prometheus/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/prometheus/#base-tab","text":"Prometheus access username - Username to be used to access the Prometheus user interface (HTTP basic auth) Prometheus access password - Password to be used to access the Prometheus user interface (HTTP basic auth) Global scrape [Optional] - How frequently to scrape targets by default Global evaluation [Optional] - How frequently to evaluate rules Job name - The job name assigned to scraped metrics by default Scrape internal - How frequently to scrape targets from this job Metrics path - The HTTP resource path on which to fetch metrics from targets Targets / IP address and port - The targets specified by the static config (multiple allowed) Labels / Label name & Label value [Optional] - Labels assigned to all metrics scraped from the targets (multiple allowed) Multiple jobs can be configured by using the Add job button. Target is a valid string consisting of a hostname or IP followed by an optional port number. For detailed description of the above parameters please refer to Prometheus online documentation.","title":"Base tab"},{"location":"nmaas-applications/tutorials/prometheus/#additional-tab","text":"Retention data size [Optional] - The size of storage space up to which the monitoring data should be retained (default value is displayed in the placeholder, in this case 18 Gigabytes), e.g. 18GB , 25GB or 30GB . Retention period [Optional] - The time period for which the monitoring data should be retained (default value is displayed in the placeholder, in this case 15 days), e.g. 15d , 25d or 35d . The value of Retention data size should be kept lower than the value of requested Storage space .","title":"Additional tab"},{"location":"nmaas-applications/tutorials/prometheus/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Prometheus instance (default value is displayed in the placeholder, in this case 20 Gigabytes), e.g. 10 , 20 or 30 . Prometheus allows for updating the configuration of an already running instance. A configuration update wizard is launched by the Update button available on the application instance details page.","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/psconfig-web-admin/","text":"pSConfig Web Admin pSConfig Web Admin is a web-based UI for perfSONAR administrators to define and publish MeshConfig/pSConfig meshes. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base Tab Default username - Username to be used to access the PWA user interface Default password - Password to be used to access the PWA user interface Default email - Email address of the user configured by default in the application Advanced Tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this PWA instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"psConfig Web Admin"},{"location":"nmaas-applications/tutorials/psconfig-web-admin/#psconfig-web-admin","text":"pSConfig Web Admin is a web-based UI for perfSONAR administrators to define and publish MeshConfig/pSConfig meshes.","title":"pSConfig Web Admin"},{"location":"nmaas-applications/tutorials/psconfig-web-admin/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/psconfig-web-admin/#base-tab","text":"Default username - Username to be used to access the PWA user interface Default password - Password to be used to access the PWA user interface Default email - Email address of the user configured by default in the application","title":"Base Tab"},{"location":"nmaas-applications/tutorials/psconfig-web-admin/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this PWA instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced Tab"},{"location":"nmaas-applications/tutorials/routinator/","text":"Routinator Routinator is a full-featured software package that can perform RPKI validation as a one-time operation and produce the result in formats such as CSV, JSON and RPSL, or run as a service that periodically downloads and verifies RPKI data. Routinator offers an RTR server allowing routers supporting Origin Validation (port 3323) to connect to it to fetch verified RPKI data. The built-in HTTP server offers a user interface and endpoints for the various file formats, as well as logging, status and Prometheus monitoring.","title":"Routinator"},{"location":"nmaas-applications/tutorials/routinator/#routinator","text":"Routinator is a full-featured software package that can perform RPKI validation as a one-time operation and produce the result in formats such as CSV, JSON and RPSL, or run as a service that periodically downloads and verifies RPKI data. Routinator offers an RTR server allowing routers supporting Origin Validation (port 3323) to connect to it to fetch verified RPKI data. The built-in HTTP server offers a user interface and endpoints for the various file formats, as well as logging, status and Prometheus monitoring.","title":"Routinator"},{"location":"nmaas-applications/tutorials/spa-inventory/","text":"SPA Inventory Oxidized is a simple open-source device configuration backup tool exposing a web-based GUI. Configuration Wizard Configuration parameters to be provided by the user are explained in the subsections below. Base Tab Inventory access username - Username to be used to access the Inventory user interface and REST API Inventory access password - Password to be used to access the Inventory user interface and REST API Advanced tab Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Inventory instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"SPA Inventory"},{"location":"nmaas-applications/tutorials/spa-inventory/#spa-inventory","text":"Oxidized is a simple open-source device configuration backup tool exposing a web-based GUI.","title":"SPA Inventory"},{"location":"nmaas-applications/tutorials/spa-inventory/#configuration-wizard","text":"Configuration parameters to be provided by the user are explained in the subsections below.","title":"Configuration Wizard"},{"location":"nmaas-applications/tutorials/spa-inventory/#base-tab","text":"Inventory access username - Username to be used to access the Inventory user interface and REST API Inventory access password - Password to be used to access the Inventory user interface and REST API","title":"Base Tab"},{"location":"nmaas-applications/tutorials/spa-inventory/#advanced-tab","text":"Storage space (GB) [Optional] - Amount of storage to be allocated to persist data generated by this Inventory instance (default value is displayed in the placeholder, in this case 1 Gigabyte), e.g. 1 , 2 or 3 .","title":"Advanced tab"},{"location":"nmaas-applications/tutorials/spa/","text":"SPA SPA for the E-Line service The Service Provider Architecture (SPA) is a service management digital platform providing the general processes and components necessary to manage the CSP services via a user-friendly web graphical user interface (Self-Service Portal). The platform in NMaaS has been prepared to manage E-Line service (L2 end-to-end connectivity) implemented by the OpenNSA application with a test default configuration and virtual simplified network topology. Users can familiarize with the SPA without the need of setting up the platform from the scratch. Just log in to the portal and start creating new circuits in a simple network to see how it works. The built-in credentials for particular services are given in the table below. Service Name User Password Inventory inventory inventory OTRS serviceadmin serviceadmin Portal admin admin123 SuiteCRM root root123 More info: https://wiki.geant.org/display/NETDEV/SPA","title":"SPA"},{"location":"nmaas-applications/tutorials/spa/#spa","text":"SPA for the E-Line service The Service Provider Architecture (SPA) is a service management digital platform providing the general processes and components necessary to manage the CSP services via a user-friendly web graphical user interface (Self-Service Portal). The platform in NMaaS has been prepared to manage E-Line service (L2 end-to-end connectivity) implemented by the OpenNSA application with a test default configuration and virtual simplified network topology. Users can familiarize with the SPA without the need of setting up the platform from the scratch. Just log in to the portal and start creating new circuits in a simple network to see how it works. The built-in credentials for particular services are given in the table below. Service Name User Password Inventory inventory inventory OTRS serviceadmin serviceadmin Portal admin admin123 SuiteCRM root root123 More info: https://wiki.geant.org/display/NETDEV/SPA","title":"SPA"},{"location":"nmaas-applications/tutorials/synapse/","text":"Synapse Matrix is an open and secure instant messaging protocol providing rich functionality. Synapse is an open-source server implementing the Matrix protocol. Element (formerly Riot) is an open-source web-client that can connect to any accessible Matrix server.","title":"Synapse"},{"location":"nmaas-applications/tutorials/synapse/#synapse","text":"Matrix is an open and secure instant messaging protocol providing rich functionality. Synapse is an open-source server implementing the Matrix protocol. Element (formerly Riot) is an open-source web-client that can connect to any accessible Matrix server.","title":"Synapse"},{"location":"nmaas-applications/tutorials/uptime-kuma/","text":"Uptime Kuma Introduction Uptime Kuma is a service monitoring application which can: monitor the uptime of web applications monitor DNS changes monitor response times by issuing periodic pings (ICMP requests) monitor SSL certificate expiry monitor availability of a TCP port monitor for presence of a particular keyword on a web page various other application specific monitors for PostgreSQL, MariaDB, MongoDB, etc... design and create status pages Uptime Kuma on NMaaS Uptime Kuma on NMaaS is fully supported in two flavors: standalone flavor, identical with the upstream release, without any modifications. extended flavor which also supports API access using a third-party API extension . Refer to the sections below for more details regarding deployment options for the two flavors. Deploiying the Standalone Version of Uptime Kuma As with any other application available in the NMaaS catalog, the deployment process for the standalone version is: Subscribe your domain to the Uptime Kuma application from the Applications page. Deploy a new instance of Uptime Kuma, providing a unique name for it. Configure the application using the application configuration wizard. In the case of the standalone version, the user deploying the application is only requested to specify the required storage, with 5Gi being the default value. Wait for the deployment to be completed and directly access the newly deployed instance. Upon first access, you will be asked to create the initial Uptime Kuma account. Keep in mind that multi-user support is still in its infancy in Uptime Kuma, so monitors created by one user cannot be accessed by other users. Deploying Uptime Kuma together with an API Server NMaaS also offers an extended flavor of Uptime Kuma, one that comes collocated with the open-source API server implementation by MedAziz11/Uptime-Kuma-Web-API . The deployment process for this flavor, differs somewhat from the standalone version, taking into account the additional features. The deployment steps are: Subscribe your domain to the Uptime Kuma application from the Applications page. Deploy a new instance of Uptime Kuma, providing a unique name for it. Configure the application using the application deployment wizard. Make sure to check the Enable API checkbox. Fig. 1: Uptime Kuma Deployment Wizard Enter the username and password for the default Uptime Kuma user. NMaaS will automatically initialize a new user with the specified credentials, and the first run page will be skipped once the application is deployed. The user will be able to directly login. Enter the password for the API user. The API user is different from the Uptime Kuma user. The default username for the API user is admin . This username cannot be changed at the moment. Finish the deployment process and access the Uptime Kuma web interface and the API's OpenAPI documentation. Fig. 2: Uptime Kuma Access Methods Fig. 3: Uptime Kuma OpenAPI Explorer Warning The accounts for the Uptime Kuma web interface and the API are different. During deployment, the username and password for the Uptime Kuma web interface can be specified, along with the password for the API. The default username for the API is always admin . Danger Changing the user's password from the Uptime Kuma web interface after the application has been deployed will make the API addon nonfunctional. Contact the NMaaS team in case a password change is necessary.","title":"Uptime Kuma"},{"location":"nmaas-applications/tutorials/uptime-kuma/#uptime-kuma","text":"","title":"Uptime Kuma"},{"location":"nmaas-applications/tutorials/uptime-kuma/#introduction","text":"Uptime Kuma is a service monitoring application which can: monitor the uptime of web applications monitor DNS changes monitor response times by issuing periodic pings (ICMP requests) monitor SSL certificate expiry monitor availability of a TCP port monitor for presence of a particular keyword on a web page various other application specific monitors for PostgreSQL, MariaDB, MongoDB, etc... design and create status pages","title":"Introduction"},{"location":"nmaas-applications/tutorials/uptime-kuma/#uptime-kuma-on-nmaas","text":"Uptime Kuma on NMaaS is fully supported in two flavors: standalone flavor, identical with the upstream release, without any modifications. extended flavor which also supports API access using a third-party API extension . Refer to the sections below for more details regarding deployment options for the two flavors.","title":"Uptime Kuma on NMaaS"},{"location":"nmaas-applications/tutorials/uptime-kuma/#deploiying-the-standalone-version-of-uptime-kuma","text":"As with any other application available in the NMaaS catalog, the deployment process for the standalone version is: Subscribe your domain to the Uptime Kuma application from the Applications page. Deploy a new instance of Uptime Kuma, providing a unique name for it. Configure the application using the application configuration wizard. In the case of the standalone version, the user deploying the application is only requested to specify the required storage, with 5Gi being the default value. Wait for the deployment to be completed and directly access the newly deployed instance. Upon first access, you will be asked to create the initial Uptime Kuma account. Keep in mind that multi-user support is still in its infancy in Uptime Kuma, so monitors created by one user cannot be accessed by other users.","title":"Deploiying the Standalone Version of Uptime Kuma"},{"location":"nmaas-applications/tutorials/uptime-kuma/#deploying-uptime-kuma-together-with-an-api-server","text":"NMaaS also offers an extended flavor of Uptime Kuma, one that comes collocated with the open-source API server implementation by MedAziz11/Uptime-Kuma-Web-API . The deployment process for this flavor, differs somewhat from the standalone version, taking into account the additional features. The deployment steps are: Subscribe your domain to the Uptime Kuma application from the Applications page. Deploy a new instance of Uptime Kuma, providing a unique name for it. Configure the application using the application deployment wizard. Make sure to check the Enable API checkbox. Fig. 1: Uptime Kuma Deployment Wizard Enter the username and password for the default Uptime Kuma user. NMaaS will automatically initialize a new user with the specified credentials, and the first run page will be skipped once the application is deployed. The user will be able to directly login. Enter the password for the API user. The API user is different from the Uptime Kuma user. The default username for the API user is admin . This username cannot be changed at the moment. Finish the deployment process and access the Uptime Kuma web interface and the API's OpenAPI documentation. Fig. 2: Uptime Kuma Access Methods Fig. 3: Uptime Kuma OpenAPI Explorer Warning The accounts for the Uptime Kuma web interface and the API are different. During deployment, the username and password for the Uptime Kuma web interface can be specified, along with the password for the API. The default username for the API is always admin . Danger Changing the user's password from the Uptime Kuma web interface after the application has been deployed will make the API addon nonfunctional. Contact the NMaaS team in case a password change is necessary.","title":"Deploying Uptime Kuma together with an API Server"},{"location":"nmaas-applications/tutorials/victoria-metrics/","text":"Victoria Metrics VictoriaMetrics is a highly scalable high-performance database that can be used as an external long-term storage for Prometheus metrics. It can also completely replace Prometheus and perform the polling by itself, using a configuration format that is compatible with existing Prometheus deployments. Apart from Prometheus, it can also substitute InfluxDB, OpenTSDB, and Graphite, as a result of providing compatible interfaces for these protocols. < Stored metrics can be easily visualized by Grafana, by adding the VictoriaMetrics instance as a Prometheus datastore. No matter what protocol is used to store data in VictoriaMetrics, it is queried using the same web endpoint, and only a single datasource is required in Prometheus. Another feature of VictoriaMetrics is to use advanced PromQL expressions, not available in the Prometheus implementation. More details about this can be obtained from the official documentation page .","title":"Victoria Metrics"},{"location":"nmaas-applications/tutorials/victoria-metrics/#victoria-metrics","text":"VictoriaMetrics is a highly scalable high-performance database that can be used as an external long-term storage for Prometheus metrics. It can also completely replace Prometheus and perform the polling by itself, using a configuration format that is compatible with existing Prometheus deployments. Apart from Prometheus, it can also substitute InfluxDB, OpenTSDB, and Graphite, as a result of providing compatible interfaces for these protocols. < Stored metrics can be easily visualized by Grafana, by adding the VictoriaMetrics instance as a Prometheus datastore. No matter what protocol is used to store data in VictoriaMetrics, it is queried using the same web endpoint, and only a single datasource is required in Prometheus. Another feature of VictoriaMetrics is to use advanced PromQL expressions, not available in the Prometheus implementation. More details about this can be obtained from the official documentation page .","title":"Victoria Metrics"},{"location":"nmaas-applications/tutorials/webdav/","text":"WebDAV This application represents a simple WebDAV server which can accept remote files. During the deployment process, the user can also choose whether the uploaded files should be versioned using Git. Three deployments options are possible: Do not use Git for file versioning; Initiate a local Git repository for file versioning which can be browsed using an embedded Git web interface; Integrate with a remote Git repository (e.g. GitHub) and automatically push any uploaded file to the remote git repository. In case the third option is chosen, users are required to set up an SSH key pair which will have push access to the target repository. The target repository URL also must be given in an SSH format during application deployment, e.g. git@host.example.com/username/myrepo .","title":"WebDAV"},{"location":"nmaas-applications/tutorials/webdav/#webdav","text":"This application represents a simple WebDAV server which can accept remote files. During the deployment process, the user can also choose whether the uploaded files should be versioned using Git. Three deployments options are possible: Do not use Git for file versioning; Initiate a local Git repository for file versioning which can be browsed using an embedded Git web interface; Integrate with a remote Git repository (e.g. GitHub) and automatically push any uploaded file to the remote git repository. In case the third option is chosen, users are required to set up an SSH key pair which will have push access to the target repository. The target repository URL also must be given in an SSH format during application deployment, e.g. git@host.example.com/username/myrepo .","title":"WebDAV"},{"location":"nmaas-applications/tutorials/wifimon/","text":"WiFiMon WiFiMon is a WiFi network monitoring and performance verification system. It is capable of detecting performance issues, to visualise the workload of the network, and to provide technical information about the WiFi network (e.g. signal strength, link quality, bit rate, etc.). Additional installation information The final installation step requires loading the appropriate Kibana visualizations and dashboards: Download file `kibana-import-v150.ndjson`` from http://83.97.95.167/deb/kibana-import-v150.ndjson In Kibana UI, select Management -> Stack Management from the menu on the left Select Kibana -> Saved Objects Select import and upload file kibana-import-v150.ndjson","title":"WiFiMon"},{"location":"nmaas-applications/tutorials/wifimon/#wifimon","text":"WiFiMon is a WiFi network monitoring and performance verification system. It is capable of detecting performance issues, to visualise the workload of the network, and to provide technical information about the WiFi network (e.g. signal strength, link quality, bit rate, etc.).","title":"WiFiMon"},{"location":"nmaas-applications/tutorials/wifimon/#additional-installation-information","text":"The final installation step requires loading the appropriate Kibana visualizations and dashboards: Download file `kibana-import-v150.ndjson`` from http://83.97.95.167/deb/kibana-import-v150.ndjson In Kibana UI, select Management -> Stack Management from the menu on the left Select Kibana -> Saved Objects Select import and upload file kibana-import-v150.ndjson","title":"Additional installation information"},{"location":"nmaas-applications/tutorials/zabbix/","text":"Zabbix Zabbix is a mature and effortless enterprise-class open source monitoring solution for network monitoring and application monitoring of millions of metrics. The Zabbix application included in the NMaaS catalog uses TimescaleDB for better performance. After deployment, use the default Admin/zabbix credentials to login.","title":"Zabbix"},{"location":"nmaas-applications/tutorials/zabbix/#zabbix","text":"Zabbix is a mature and effortless enterprise-class open source monitoring solution for network monitoring and application monitoring of millions of metrics. The Zabbix application included in the NMaaS catalog uses TimescaleDB for better performance. After deployment, use the default Admin/zabbix credentials to login.","title":"Zabbix"},{"location":"release-notes/1.5.4/","text":"1.5.4 General nmaas 1.5.4 is a minor update containing one new feature, asynchronous Helm repository updates. Automatic Helm Repository Updates in the Background Until now, the nmaas Platform was executing the helm repo update command via the nmaas-helm component prior to each application instance deployment. This slowed down the deployment process in cases of unresponsive Helm repositories or a large number of repositories that need to be refreshed. The nmaas Platform now exposes two additional configuration properties (configured from Helm chart) controlling this behavior: platform.properties.helm.asyncUpdateEnabled and platform.properties.helm.asyncUpdateCron . The latter accepts a cron-style expression for scheduling when helm repo update should be run in case asyncUpdateEnabled is set to true . A helm repo update is unconditionally run upon each new application version addition and during nmaas-platform startup.","title":"1.5.4"},{"location":"release-notes/1.5.4/#154","text":"","title":"1.5.4"},{"location":"release-notes/1.5.4/#general","text":"nmaas 1.5.4 is a minor update containing one new feature, asynchronous Helm repository updates.","title":"General"},{"location":"release-notes/1.5.4/#automatic-helm-repository-updates-in-the-background","text":"Until now, the nmaas Platform was executing the helm repo update command via the nmaas-helm component prior to each application instance deployment. This slowed down the deployment process in cases of unresponsive Helm repositories or a large number of repositories that need to be refreshed. The nmaas Platform now exposes two additional configuration properties (configured from Helm chart) controlling this behavior: platform.properties.helm.asyncUpdateEnabled and platform.properties.helm.asyncUpdateCron . The latter accepts a cron-style expression for scheduling when helm repo update should be run in case asyncUpdateEnabled is set to true . A helm repo update is unconditionally run upon each new application version addition and during nmaas-platform startup.","title":"Automatic Helm Repository Updates in the Background"},{"location":"release-notes/1.6.0/","text":"1.6.0 General nmaas 1.6.0 is packed with a number of improvements. The long awaited application log viewing has been implemented and is ready to be used for easier troubleshooting by end-users. Users can also now review the application parameters used during the initial deployment, while global administrators can mark an application instance as having been manually upgraded in the background. In this version we also introduced a brand new use-case, nmaas for Virtual Labs, accompanied by a number of related new functionalities. Application Instance Log Viewing Application instance logs can now be viewed directly from the nmaas Portal, enabling easier debugging. Users can simply navigate to the application instance details page and select the View Logs option from the Actions dropdown. Log viewing can be enabled on a per-application basis. If a particular instance does not currently expose its logs, contact your nmaas Platform administrator for more information. Logs can either be viewed using the dedicated web viewer or downloaded for later analysis. In case a given application instance comprises multiple pods, logs are viewable for all of them. Global administrators can enable log viewing for a given application by ticking the Allow log access checkbox when editing a particular version of the application. Note that the log viewing feature can be toggled on a per-version basis. Accessing the log viewer The application instance log viewer Deployment Parameters Viewing It is now possible to look at all the configuration parameters used for instantiating a given application instance once it has been deployed. In this release this is possible only for applications with multiple access methods defined, using the Actions -> Access option . In a subsequent patch release this feature will become globally available for all application instances. Viewing deployment parameters of an application instance Manual Application Instance Update Global administrators can now notify the nmaas Platform that an application instance has been manually upgraded in the background, bypassing the built-in update functionality of nmaas. This is useful if a more complex update operation needs to be done, for example between different incompatible major versions, and the administrator has to make manual changes from the CLI. Once the global administrator has indicated that a manual update has been performed to a new version, the nmaas platform will continue tracking subsequent update paths from that point forward. The manual update functionality is accessible via the Actions -> Manual version update menu of a particular application instance. Manually updating the version of an application instance Virtual Lab Version 1.6.0 also introduces a brand new nmaas use-case, nmaas for Virtual Labs. More information about this use-case is available in the dedicated page, Introduction to nmaas Virtual Lab . Domain Groups It is now possible to specify what set of applications can be deployed by each domain. A domain group can contain one or more domains, precisely specifying what applications are available for deployment by the users in the given domains. Applications that haven't been whitelisted are simply not visible in the application list. A given domain can be part of multiple domain groups, and in that case the set of deployable applications is derived as a union operation of all whitelisted applications across all domain groups where the domain has been added. A detailed walkthrough is provided in the dedicated Domain Groups page. Bulk Domain and User Deployments It is now possible for global administrators and virtual lab managers (more details below) to register multiple users and assign them to domains using a single input file in CSV format uploaded to the Portal. More information is available in the dedicated Bulk Domain Deployment page. Bulk Application Instance Deployments It is now possible for global administrators and virtual lab managers (more details below) to deploy multiple instances of a particular application in one go using a CSV file. Application deployment parameters can also be overridden per deployment. More information is available in the dedicated Bulk Application Deployment page. New Virtual Lab Manager Role A new system role has been added to the Platform component, Virtual Lab Manager that can be assigned to people responsible for organizing virtual labs on nmaas, without giving them a global administrator role. Virtual lab managers are allowed to: create new domain groups perform bulk domain deployments perform bulk application deployments Application managers cannot directly edit domains or users, but it is possible to assign an existing user to an existing domain group using the bulk domain deployment functionality.","title":"1.6.0"},{"location":"release-notes/1.6.0/#160","text":"","title":"1.6.0"},{"location":"release-notes/1.6.0/#general","text":"nmaas 1.6.0 is packed with a number of improvements. The long awaited application log viewing has been implemented and is ready to be used for easier troubleshooting by end-users. Users can also now review the application parameters used during the initial deployment, while global administrators can mark an application instance as having been manually upgraded in the background. In this version we also introduced a brand new use-case, nmaas for Virtual Labs, accompanied by a number of related new functionalities.","title":"General"},{"location":"release-notes/1.6.0/#application-instance-log-viewing","text":"Application instance logs can now be viewed directly from the nmaas Portal, enabling easier debugging. Users can simply navigate to the application instance details page and select the View Logs option from the Actions dropdown. Log viewing can be enabled on a per-application basis. If a particular instance does not currently expose its logs, contact your nmaas Platform administrator for more information. Logs can either be viewed using the dedicated web viewer or downloaded for later analysis. In case a given application instance comprises multiple pods, logs are viewable for all of them. Global administrators can enable log viewing for a given application by ticking the Allow log access checkbox when editing a particular version of the application. Note that the log viewing feature can be toggled on a per-version basis. Accessing the log viewer The application instance log viewer","title":"Application Instance Log Viewing"},{"location":"release-notes/1.6.0/#deployment-parameters-viewing","text":"It is now possible to look at all the configuration parameters used for instantiating a given application instance once it has been deployed. In this release this is possible only for applications with multiple access methods defined, using the Actions -> Access option . In a subsequent patch release this feature will become globally available for all application instances. Viewing deployment parameters of an application instance","title":"Deployment Parameters Viewing"},{"location":"release-notes/1.6.0/#manual-application-instance-update","text":"Global administrators can now notify the nmaas Platform that an application instance has been manually upgraded in the background, bypassing the built-in update functionality of nmaas. This is useful if a more complex update operation needs to be done, for example between different incompatible major versions, and the administrator has to make manual changes from the CLI. Once the global administrator has indicated that a manual update has been performed to a new version, the nmaas platform will continue tracking subsequent update paths from that point forward. The manual update functionality is accessible via the Actions -> Manual version update menu of a particular application instance. Manually updating the version of an application instance","title":"Manual Application Instance Update"},{"location":"release-notes/1.6.0/#virtual-lab","text":"Version 1.6.0 also introduces a brand new nmaas use-case, nmaas for Virtual Labs. More information about this use-case is available in the dedicated page, Introduction to nmaas Virtual Lab .","title":"Virtual Lab"},{"location":"release-notes/1.6.0/#domain-groups","text":"It is now possible to specify what set of applications can be deployed by each domain. A domain group can contain one or more domains, precisely specifying what applications are available for deployment by the users in the given domains. Applications that haven't been whitelisted are simply not visible in the application list. A given domain can be part of multiple domain groups, and in that case the set of deployable applications is derived as a union operation of all whitelisted applications across all domain groups where the domain has been added. A detailed walkthrough is provided in the dedicated Domain Groups page.","title":"Domain Groups"},{"location":"release-notes/1.6.0/#bulk-domain-and-user-deployments","text":"It is now possible for global administrators and virtual lab managers (more details below) to register multiple users and assign them to domains using a single input file in CSV format uploaded to the Portal. More information is available in the dedicated Bulk Domain Deployment page.","title":"Bulk Domain and User Deployments"},{"location":"release-notes/1.6.0/#bulk-application-instance-deployments","text":"It is now possible for global administrators and virtual lab managers (more details below) to deploy multiple instances of a particular application in one go using a CSV file. Application deployment parameters can also be overridden per deployment. More information is available in the dedicated Bulk Application Deployment page.","title":"Bulk Application Instance Deployments"},{"location":"release-notes/1.6.0/#new-virtual-lab-manager-role","text":"A new system role has been added to the Platform component, Virtual Lab Manager that can be assigned to people responsible for organizing virtual labs on nmaas, without giving them a global administrator role. Virtual lab managers are allowed to: create new domain groups perform bulk domain deployments perform bulk application deployments Application managers cannot directly edit domains or users, but it is possible to assign an existing user to an existing domain group using the bulk domain deployment functionality.","title":"New Virtual Lab Manager Role"},{"location":"self-hosted-nmaas/install-guide/","text":"NMaaS Installation Guide Requirements To install NMaaS into an existing Kubernetes cluster, the following requirements must be met: Kubernetes version >=1.16 Helm v3 support in the Kubernetes cluster Existing ingress controller, preferably with a default TLS certificate set (more information available below) An integration with an external load-balancer or MetalLB for bare-metal deployments, so that IPs can be assigned to LoadBalancer services. NMaaS Components NMaaS is comprised of multiple components, and a brief description for each one is provided in the self-hosting introduction page. Installation The NMaaS installation is a two-step process - first an instance of GItLab must be deployed and configured, and then NMaaS itself. The two components cannot be deployed at the same time, since during the deployment process NMaaS requires a GitLab API key to be specified. GitLab Installation GitLab can be deployed using the official Helm chart whose source code is also publicly available . Note that GitLab requires at least 8GB of memory to run. Also note that it requires both a PostgreSQL database and a Redis instance, both of which can either be externalized or deployed in-cluster, by the official chart. GitLab and an External Database GitLab can use an external PostgreSQL instance, but during the deployment process either the root user must be specified, or the following extensions enabled in the target GitLab database: btree_gist pg_trgm This can be done using the following commands: 1 2 create extension btree_gist ; create extension pg_trgm ; GitLab Version 4.8.2 is the latest version of the GitLab chart that has been tested with the latest version of NMaaS. Bellow is a snippet of the mandatory parameters that must be specified during GitLab's deployment, so that it will be compatible with NMaaS. The complete list of supported value parameters is available in the official GitLab Helm chart Git repository . gitlab-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 certmanager : install : false nginx-ingress : enabled : false prometheus : install : false redis : install : true postgresql : postgresqlUsername : gitlab install : true postgresqlDatabase : gitlabhq_production image : tag : 11.9.0 usePasswordFile : false existingSecret : 'gitlab-postgresql' master : extraVolumeMounts : - name : custom-init-scripts mountPath : /docker-entrypoint-preinitdb.d/init_revision.sh subPath : init_revision.sh podAnnotations : postgresql.gitlab/init-revision : \"1\" metrics : enabled : true ## Optionally define additional custom metrics ## ref: https://github.com/wrouesnel/postgres_exporter#adding-new-metrics-via-a-config-file gitlab-runner : install : false global : edition : ce hosts : domain : <TLD> # (e.g. if nmaas.example.com is specified here, gitlab will be accessible under gitlab.nmaas.example.com) https : true ssh : ssh.nmaas.example.com # optional, if the SSH endpoint should differ from GitLab's access domain ingress : enabled : true configureCertmanager : false tls : enabled : true secretName : <MY_TLS_SECRET> path : / annotations : kubernetes.io/ingress.class : \"nginx\" initialRootPassword : secret : gitlab-root-password key : password ## configuration for external postgresql psql : ## the secret must be manually created password : {} # useSecret: true # secret: gitlab-db-password # key: password # host: psql-standalone-postgresql # port: 5432 # username: gitlab # database: gitlab appConfig : defaultProjectFeatures : builds : false time_zone : UTC smtp : enabled : false address : smtp.mailgun.org port : 2525 user_name : \"\" ## doc/installation/secrets.md#smtp-password password : secret : \"\" key : password # domain: authentication : \"plain\" starttls_auto : false openssl_verify_mode : \"peer\" ## doc/installation/deployment.md#outgoing-email ## Email persona used in email sent by GitLab email : from : '' display_name : GitLab reply_to : '' subject_suffix : '' smime : enabled : false secretName : \"\" keyName : \"tls.key\" certName : \"tls.crt\" Note that the secrets whose names are specified in .Values.postgresql.existingSecret and .Values.global.initialRootPassword.secret must be manually created. These secrets contain the postgresql root and user passwords, as well as the initial root password to be used by GitLab, respectively. Below is a snippet that can be reused to create these secrets: 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE gitlab-postgresql --from-literal = postgresql-password = <POSTGRESQL_USER_PASSWORD> --from-literal = postgresql-postgres-password = <POSTGRESQL_ROOT_PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE gitlab-root-password --from-literal = password = <GITLAB_ROOT_PASSWORD> Note that the built-in PostgreSQL chart that can be automatically deployed together with GitLab is based on Bitnami's PostgreSQL chart, so additional customization options can be seen from Bitnami's GitHub page . In case an external PostgreSQL instance will be used then the secret specified in .Values.global.psql.password.secret must be created automatically. Also, keep in mind the warning given above, if a regular PostgreSQL user is specified, the btree and trgm extensions must be enabled beforehand. GitLab Email Sending NMaaS does not rely on email sending via GitLab, so both the email and smtp sections in the value files can be left with their default values - unconfigured. However, users are free to customize these sections according to their own environments. Once all configuration parameters have been specified, GitLab can be installed using the following Helm v3 command: 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" helm repo add gitlab https://charts.gitlab.io helm install -f gitlab.yaml --namespace $NMAAS_NAMESPACE <RELEASE_NAME> --version 4 .8.2 gitlab/gitlab GitLab Deployment Duration Please allow more than 15 minutes for GitLab to be deployed, depending on hardware configuration and current resource utilization. Once GitLab has been deployed, it can be accessed by navigating to gitlab.<TLD> , where TLD is the value specified for the .Values.global.hosts.domain parameter. GitLab Public Exposure Note that after deployment, by default, anyone can register to your newly deployed GitLab instance. This can be configured by logging in as the root GitLab user. Users are advised to determine whether public exposure of the GitLab web interface is needed at all. NMaaS' GitLab integration can work even if only public access to the GitLab SSH interface is provided, since repository cloning always relies on SSH as the transport protocol. To create a GitLab API token that can be used by NMaaS, perform the following steps: Login to GitLab using the root account; Click on the avatar image in the top right corner and select Settings ; From the left-hand navigation menu choose Access Tokens ; Create a new access token with no expiration date by simply leaving the Expires at field empty, and assigning all available scopes; Write down the API token, it will be needed shortly. SSH Access to GitLab Repositories GitLab supports SSH access to any created repositories. If you want to allow your users to clone the repositories where their application configuration is stored, then you will have to alter the GitLab Shell service, and change its type to LoadBalancer, so that a routable IP address will be assigned to it. NMaaS Installation The source code for the NMaaS Helm chart is publicly available on nmaas-platform/nmaas-chart . The README.md file provides details on all the customizable value parameters for a given chart version. The following manual steps must be performed before deploying NMaaS: Creating a private/public SSH keypair so that NMaaS Platform can access NMaaS Helm: 1 2 3 4 5 6 7 8 9 10 #!/bin/bash export NMAAS_NAMESPACE = \"nmaas-system\" tmpdir = $( mktemp -d ) ssh-keygen -f $tmpdir /key -N \"\" # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPrivate }} kubectl create secret generic nmaas-helm-key-private -n $NMAAS_NAMESPACE --from-file = id_rsa = $tmpdir /key # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPublic }} kubectl create secret generic nmaas-helm-key-public -n $NMAAS_NAMESPACE --from-file = helm = $tmpdir /key.pub The secrets for the SP, API, and admin password: 1 2 3 4 5 # Make sure to name the secrets with the same names that have been specified in the values file. The examples below use the defaults, and should be used if no changes have been made. export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-platform-admin --from-literal = password = <PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-api-secret --from-literal = secret = <PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-sp-secret --from-literal = secret = <SSO_SHARED_KEY> Create the NMaaS Janitor secret containing the GitLab API key, generated previously: 1 2 export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-gitlab-janitor-token --from-literal = secret = <GITLAB_API_TOKEN> Once the required secrets have been created, NMaaS can be deployed using the following command (make sure to deploy in the same namespace as GitLab): 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" helm repo add nmaas https://artifactory.software.geant.org/artifactory/nmaas-helm helm install -f values.yaml --namespace $NMAAS_NAMESPACE --version 1 .0.0 nmaas nmaas/nmaas It is recommended to use nmaas-system as the namespace where NMaaS and all associated components (PostgreSQL, GitLab) will be deployed. NMaaS Deployment Time Please allow at least 10 minutes for NMaaS to be fully deployed, depending on hardware configuration and resource utilization. Verifying the Installation You can verify that NMaaS has been successfully deployed by navigating to its ingress URL from your browser, logging in as the admin user and selecting Settings -> Monitoring . From this location, you can execute checks for all the required components of NMaaS. A fully functional installation should return a successful response for all monitors. Administrator Information For more detailed instructions, refer to the Domain Admin Guide Creating New Domains Creating a new customer domain within NMaaS is a two-step process: First, the new domain should be added from the NMaaS web interface. The following steps should be performed. Login to the NMaaS Portal as the administrator user (the default administrator username is admin and the desired password is passed as a installation parameter); Navigate to Settings -> Domains ; Click the Add button and enter the required parameters specific to the newly created domain: Name - full name of given domain (e.g. Test Domain ) Codename - abbreviated name of the domain (e.g. testdom ) Kubernetes namespace (Optional) - a namespace dedicated for this domain to be created in the next step Kubernetes storage class (Optional) - a specific storage class to be used for persistent volumes created in this domain (typically should be left blank) Kubernetes ingress class (Optional) - a ingress class supported by the ingress controller deployed for this domain (should be left blank if a single common controller supports all the domains) External service domain - a base URL for accessing all applications deployed in this domain (typically should contain the Codename and the URL of NMaaS itself, e.g. testdom.nmaas.example.com ) DCN deployment type - by default should be set to Manual DCN status - by default should be set to Configured Customer networks (to be removed) - list of network prefixes to which applications deployed in this domain should have access (thought this parameter is currently mandatory it is not used for any automated actions so any initial values can be provided) Click the Submit button to create the domain Then, the following operations should be performed within the cluster: Create a new Kubernetes namespace with the same name as the domain Create a new MetalLB range with the same name as the new customer domain, and set that addresses should not be automatically assigned. To accomplish this, the existing MetalLB ConfigMap can simply be edited to include the new configuration block. An example MetalLB ConfigMap is available below: config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion : v1 kind : ConfigMap metadata : namespace : metallb-system name : config data : config : | address-pools: - name: default-pool protocol: layer2 addresses: - 192.168.1.100-192.168.1.254 - name: domain1 protocol: layer2 addresses: - 192.168.2.100-192.168.2.254 auto-assign: false With the above configuration, whenever a LoadBalancer Kubernetes Service is created, it will be assigned an address from the default-pool, unless the annotation metallb.universe.tf/address-pool: domain1 is present, in which case an address from the domain1 pool will be allocated. Deploy a new ingress controller in the new domain namespace, with an ingress class that will match the name of the domain. Additional Documentation An online user guide is available at NMaaS User Guide page. Information about the NMaaS applications deployment and configuration process and the NMaaS portfolio is available on the NMaaS Tools page. In case of any questions please contact the NMaaS Team at nmaas@lists.geant.org .","title":"Installation Guide"},{"location":"self-hosted-nmaas/install-guide/#nmaas-installation-guide","text":"","title":"NMaaS Installation Guide"},{"location":"self-hosted-nmaas/install-guide/#requirements","text":"To install NMaaS into an existing Kubernetes cluster, the following requirements must be met: Kubernetes version >=1.16 Helm v3 support in the Kubernetes cluster Existing ingress controller, preferably with a default TLS certificate set (more information available below) An integration with an external load-balancer or MetalLB for bare-metal deployments, so that IPs can be assigned to LoadBalancer services.","title":"Requirements"},{"location":"self-hosted-nmaas/install-guide/#nmaas-components","text":"NMaaS is comprised of multiple components, and a brief description for each one is provided in the self-hosting introduction page.","title":"NMaaS Components"},{"location":"self-hosted-nmaas/install-guide/#installation","text":"The NMaaS installation is a two-step process - first an instance of GItLab must be deployed and configured, and then NMaaS itself. The two components cannot be deployed at the same time, since during the deployment process NMaaS requires a GitLab API key to be specified.","title":"Installation"},{"location":"self-hosted-nmaas/install-guide/#gitlab-installation","text":"GitLab can be deployed using the official Helm chart whose source code is also publicly available . Note that GitLab requires at least 8GB of memory to run. Also note that it requires both a PostgreSQL database and a Redis instance, both of which can either be externalized or deployed in-cluster, by the official chart. GitLab and an External Database GitLab can use an external PostgreSQL instance, but during the deployment process either the root user must be specified, or the following extensions enabled in the target GitLab database: btree_gist pg_trgm This can be done using the following commands: 1 2 create extension btree_gist ; create extension pg_trgm ; GitLab Version 4.8.2 is the latest version of the GitLab chart that has been tested with the latest version of NMaaS. Bellow is a snippet of the mandatory parameters that must be specified during GitLab's deployment, so that it will be compatible with NMaaS. The complete list of supported value parameters is available in the official GitLab Helm chart Git repository . gitlab-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 certmanager : install : false nginx-ingress : enabled : false prometheus : install : false redis : install : true postgresql : postgresqlUsername : gitlab install : true postgresqlDatabase : gitlabhq_production image : tag : 11.9.0 usePasswordFile : false existingSecret : 'gitlab-postgresql' master : extraVolumeMounts : - name : custom-init-scripts mountPath : /docker-entrypoint-preinitdb.d/init_revision.sh subPath : init_revision.sh podAnnotations : postgresql.gitlab/init-revision : \"1\" metrics : enabled : true ## Optionally define additional custom metrics ## ref: https://github.com/wrouesnel/postgres_exporter#adding-new-metrics-via-a-config-file gitlab-runner : install : false global : edition : ce hosts : domain : <TLD> # (e.g. if nmaas.example.com is specified here, gitlab will be accessible under gitlab.nmaas.example.com) https : true ssh : ssh.nmaas.example.com # optional, if the SSH endpoint should differ from GitLab's access domain ingress : enabled : true configureCertmanager : false tls : enabled : true secretName : <MY_TLS_SECRET> path : / annotations : kubernetes.io/ingress.class : \"nginx\" initialRootPassword : secret : gitlab-root-password key : password ## configuration for external postgresql psql : ## the secret must be manually created password : {} # useSecret: true # secret: gitlab-db-password # key: password # host: psql-standalone-postgresql # port: 5432 # username: gitlab # database: gitlab appConfig : defaultProjectFeatures : builds : false time_zone : UTC smtp : enabled : false address : smtp.mailgun.org port : 2525 user_name : \"\" ## doc/installation/secrets.md#smtp-password password : secret : \"\" key : password # domain: authentication : \"plain\" starttls_auto : false openssl_verify_mode : \"peer\" ## doc/installation/deployment.md#outgoing-email ## Email persona used in email sent by GitLab email : from : '' display_name : GitLab reply_to : '' subject_suffix : '' smime : enabled : false secretName : \"\" keyName : \"tls.key\" certName : \"tls.crt\" Note that the secrets whose names are specified in .Values.postgresql.existingSecret and .Values.global.initialRootPassword.secret must be manually created. These secrets contain the postgresql root and user passwords, as well as the initial root password to be used by GitLab, respectively. Below is a snippet that can be reused to create these secrets: 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE gitlab-postgresql --from-literal = postgresql-password = <POSTGRESQL_USER_PASSWORD> --from-literal = postgresql-postgres-password = <POSTGRESQL_ROOT_PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE gitlab-root-password --from-literal = password = <GITLAB_ROOT_PASSWORD> Note that the built-in PostgreSQL chart that can be automatically deployed together with GitLab is based on Bitnami's PostgreSQL chart, so additional customization options can be seen from Bitnami's GitHub page . In case an external PostgreSQL instance will be used then the secret specified in .Values.global.psql.password.secret must be created automatically. Also, keep in mind the warning given above, if a regular PostgreSQL user is specified, the btree and trgm extensions must be enabled beforehand. GitLab Email Sending NMaaS does not rely on email sending via GitLab, so both the email and smtp sections in the value files can be left with their default values - unconfigured. However, users are free to customize these sections according to their own environments. Once all configuration parameters have been specified, GitLab can be installed using the following Helm v3 command: 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" helm repo add gitlab https://charts.gitlab.io helm install -f gitlab.yaml --namespace $NMAAS_NAMESPACE <RELEASE_NAME> --version 4 .8.2 gitlab/gitlab GitLab Deployment Duration Please allow more than 15 minutes for GitLab to be deployed, depending on hardware configuration and current resource utilization. Once GitLab has been deployed, it can be accessed by navigating to gitlab.<TLD> , where TLD is the value specified for the .Values.global.hosts.domain parameter. GitLab Public Exposure Note that after deployment, by default, anyone can register to your newly deployed GitLab instance. This can be configured by logging in as the root GitLab user. Users are advised to determine whether public exposure of the GitLab web interface is needed at all. NMaaS' GitLab integration can work even if only public access to the GitLab SSH interface is provided, since repository cloning always relies on SSH as the transport protocol. To create a GitLab API token that can be used by NMaaS, perform the following steps: Login to GitLab using the root account; Click on the avatar image in the top right corner and select Settings ; From the left-hand navigation menu choose Access Tokens ; Create a new access token with no expiration date by simply leaving the Expires at field empty, and assigning all available scopes; Write down the API token, it will be needed shortly.","title":"GitLab Installation"},{"location":"self-hosted-nmaas/install-guide/#ssh-access-to-gitlab-repositories","text":"GitLab supports SSH access to any created repositories. If you want to allow your users to clone the repositories where their application configuration is stored, then you will have to alter the GitLab Shell service, and change its type to LoadBalancer, so that a routable IP address will be assigned to it.","title":"SSH Access to GitLab Repositories"},{"location":"self-hosted-nmaas/install-guide/#nmaas-installation","text":"The source code for the NMaaS Helm chart is publicly available on nmaas-platform/nmaas-chart . The README.md file provides details on all the customizable value parameters for a given chart version. The following manual steps must be performed before deploying NMaaS: Creating a private/public SSH keypair so that NMaaS Platform can access NMaaS Helm: 1 2 3 4 5 6 7 8 9 10 #!/bin/bash export NMAAS_NAMESPACE = \"nmaas-system\" tmpdir = $( mktemp -d ) ssh-keygen -f $tmpdir /key -N \"\" # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPrivate }} kubectl create secret generic nmaas-helm-key-private -n $NMAAS_NAMESPACE --from-file = id_rsa = $tmpdir /key # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPublic }} kubectl create secret generic nmaas-helm-key-public -n $NMAAS_NAMESPACE --from-file = helm = $tmpdir /key.pub The secrets for the SP, API, and admin password: 1 2 3 4 5 # Make sure to name the secrets with the same names that have been specified in the values file. The examples below use the defaults, and should be used if no changes have been made. export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-platform-admin --from-literal = password = <PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-api-secret --from-literal = secret = <PASSWORD> kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-sp-secret --from-literal = secret = <SSO_SHARED_KEY> Create the NMaaS Janitor secret containing the GitLab API key, generated previously: 1 2 export NMAAS_NAMESPACE = \"nmaas-system\" kubectl create secret generic -n $NMAAS_NAMESPACE nmaas-gitlab-janitor-token --from-literal = secret = <GITLAB_API_TOKEN> Once the required secrets have been created, NMaaS can be deployed using the following command (make sure to deploy in the same namespace as GitLab): 1 2 3 export NMAAS_NAMESPACE = \"nmaas-system\" helm repo add nmaas https://artifactory.software.geant.org/artifactory/nmaas-helm helm install -f values.yaml --namespace $NMAAS_NAMESPACE --version 1 .0.0 nmaas nmaas/nmaas It is recommended to use nmaas-system as the namespace where NMaaS and all associated components (PostgreSQL, GitLab) will be deployed. NMaaS Deployment Time Please allow at least 10 minutes for NMaaS to be fully deployed, depending on hardware configuration and resource utilization.","title":"NMaaS Installation"},{"location":"self-hosted-nmaas/install-guide/#verifying-the-installation","text":"You can verify that NMaaS has been successfully deployed by navigating to its ingress URL from your browser, logging in as the admin user and selecting Settings -> Monitoring . From this location, you can execute checks for all the required components of NMaaS. A fully functional installation should return a successful response for all monitors.","title":"Verifying the Installation"},{"location":"self-hosted-nmaas/install-guide/#administrator-information","text":"For more detailed instructions, refer to the Domain Admin Guide","title":"Administrator Information"},{"location":"self-hosted-nmaas/install-guide/#creating-new-domains","text":"Creating a new customer domain within NMaaS is a two-step process: First, the new domain should be added from the NMaaS web interface. The following steps should be performed. Login to the NMaaS Portal as the administrator user (the default administrator username is admin and the desired password is passed as a installation parameter); Navigate to Settings -> Domains ; Click the Add button and enter the required parameters specific to the newly created domain: Name - full name of given domain (e.g. Test Domain ) Codename - abbreviated name of the domain (e.g. testdom ) Kubernetes namespace (Optional) - a namespace dedicated for this domain to be created in the next step Kubernetes storage class (Optional) - a specific storage class to be used for persistent volumes created in this domain (typically should be left blank) Kubernetes ingress class (Optional) - a ingress class supported by the ingress controller deployed for this domain (should be left blank if a single common controller supports all the domains) External service domain - a base URL for accessing all applications deployed in this domain (typically should contain the Codename and the URL of NMaaS itself, e.g. testdom.nmaas.example.com ) DCN deployment type - by default should be set to Manual DCN status - by default should be set to Configured Customer networks (to be removed) - list of network prefixes to which applications deployed in this domain should have access (thought this parameter is currently mandatory it is not used for any automated actions so any initial values can be provided) Click the Submit button to create the domain Then, the following operations should be performed within the cluster: Create a new Kubernetes namespace with the same name as the domain Create a new MetalLB range with the same name as the new customer domain, and set that addresses should not be automatically assigned. To accomplish this, the existing MetalLB ConfigMap can simply be edited to include the new configuration block. An example MetalLB ConfigMap is available below: config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 apiVersion : v1 kind : ConfigMap metadata : namespace : metallb-system name : config data : config : | address-pools: - name: default-pool protocol: layer2 addresses: - 192.168.1.100-192.168.1.254 - name: domain1 protocol: layer2 addresses: - 192.168.2.100-192.168.2.254 auto-assign: false With the above configuration, whenever a LoadBalancer Kubernetes Service is created, it will be assigned an address from the default-pool, unless the annotation metallb.universe.tf/address-pool: domain1 is present, in which case an address from the domain1 pool will be allocated. Deploy a new ingress controller in the new domain namespace, with an ingress class that will match the name of the domain.","title":"Creating New Domains"},{"location":"self-hosted-nmaas/install-guide/#additional-documentation","text":"An online user guide is available at NMaaS User Guide page. Information about the NMaaS applications deployment and configuration process and the NMaaS portfolio is available on the NMaaS Tools page. In case of any questions please contact the NMaaS Team at nmaas@lists.geant.org .","title":"Additional Documentation"},{"location":"self-hosted-nmaas/introduction/","text":"Introduction Interested users have the option of self-hosting the NMaaS software on their own infrastructure. Depending on the environment, two guides are available: The production installation guide which provides instructions on installing NMaaS on a full-fledged Kubernetes cluster involving multiple cluster nodes. The local installation guide which provides instructions on installing NMaaS for evaluation purposes in smaller environments, consisting even of a single Kubernetes node. Note that apart from the infrastructure aspects, both guides share similarities when it comes to the actual NMaaS deployment, and can be consulted in parallel. NMaaS Components NMaaS' architecture is made up of three primary components and three helper components. The primary components have all been developed within the GEANT project and these are: the NMaaS Portal, the NMaas Platform, and the NMaaS Janitor. The helper components are represented as popular open-source software which has been packaged as Docker containers. These include: NMaaS Helm, NMaaS Postfix, and NMaaS Service Provider (SP). More details about the role that each of these components play are provided in the subsections below. NMaaS Platform NMaaS Platform is the central NMaaS component, exposing a REST API consumed by the NMaaS Portal. It stores the application catalog, the users, as well as information about any deployed applications. Upon a new request for an application deployment, it connects to the NMaaS Helm component and executes the necessary Helm command via an SSH connection. It also communicates with a self-hosted instance of GitLab, in order to provision boilerplate configuration files for the deployed application instances by the users, allowing them to make any additional configuration changes exclusively through Git. External dependencies: PostgreSQL database, self-hosted GitLab instance NMaaS Portal NMaaS Portal represents the front-end application of NMaaS that consumes the REST API offered by NMaaS Platform. NMaaS Portal is a Angular based application that is run in user's browser. NMaaS Janitor The NMaaS Janitor is a helper service that interacts with the self-hosted GitLab API, and deploys the boilerplate configuration templates within the Kubernetes cluster. NMaaS Janitor is also used to retrieve the status of Kubernetes services and load balancer IPs assigned to them. For this reason it also needs privileges to use the Kubernetes API, albeit not as permissive as NMaaS Helm. NMaaS Helm NMaaS Helm interacts with the Kubernetes API of the underlying cluster where NMaaS is deployed, and manages it through the Helm v3 client. As a a result, it requires the cluster-admin Kubernetes role. Whenever a new application is deployed, the NMaaS Platform opens an SSH connection to NMaaS Helm and executes the required Helm command. NMaaS Postfix NMaaS Postfix is an in-cluster mail server that is used by any deployed applications to send emails to external destinations. It does not require any authentication before sending emails, and it can either be configured as a standalone mail server, or it can use a smart host, routing all outgoing emails through some other email server (e.g. Gmail). NMaaS Postfix without a Smart Host If NMaaS Postfix is not configured to use an external mail service for sending the emails, than most likely all outgoing emails will be marked as spam, and users will face delivery problems when sending alerts from their deployed applications. NMaaS Service Provider (SP) The NMaaS SP is an in-cluster SAML Proxy that allows for SSO user login based on SAML. The NMaaS SP component is composed of Apache HTTP server and a Shibboleth Service Provider (Shibboleth SP) software. NMaaS SP is initially configured to authenticate with eduGAIN as the federated Identify Provider but can be customized to work with any compliant IdP. NMaaS SP is still in a Testing Phase The in-cluster NMaaS SP was developed some time back but was never thoroughly tested. However NMaaS development team can provide guidelines on how to setup a NMaaS SAML Proxy on a dedicated VM. Such a setup is currently used for NMaaS production service. Nevertheless basic username and password based log in is available at all times.","title":"Introduction"},{"location":"self-hosted-nmaas/introduction/#introduction","text":"Interested users have the option of self-hosting the NMaaS software on their own infrastructure. Depending on the environment, two guides are available: The production installation guide which provides instructions on installing NMaaS on a full-fledged Kubernetes cluster involving multiple cluster nodes. The local installation guide which provides instructions on installing NMaaS for evaluation purposes in smaller environments, consisting even of a single Kubernetes node. Note that apart from the infrastructure aspects, both guides share similarities when it comes to the actual NMaaS deployment, and can be consulted in parallel.","title":"Introduction"},{"location":"self-hosted-nmaas/introduction/#nmaas-components","text":"NMaaS' architecture is made up of three primary components and three helper components. The primary components have all been developed within the GEANT project and these are: the NMaaS Portal, the NMaas Platform, and the NMaaS Janitor. The helper components are represented as popular open-source software which has been packaged as Docker containers. These include: NMaaS Helm, NMaaS Postfix, and NMaaS Service Provider (SP). More details about the role that each of these components play are provided in the subsections below.","title":"NMaaS Components"},{"location":"self-hosted-nmaas/introduction/#nmaas-platform","text":"NMaaS Platform is the central NMaaS component, exposing a REST API consumed by the NMaaS Portal. It stores the application catalog, the users, as well as information about any deployed applications. Upon a new request for an application deployment, it connects to the NMaaS Helm component and executes the necessary Helm command via an SSH connection. It also communicates with a self-hosted instance of GitLab, in order to provision boilerplate configuration files for the deployed application instances by the users, allowing them to make any additional configuration changes exclusively through Git. External dependencies: PostgreSQL database, self-hosted GitLab instance","title":"NMaaS Platform"},{"location":"self-hosted-nmaas/introduction/#nmaas-portal","text":"NMaaS Portal represents the front-end application of NMaaS that consumes the REST API offered by NMaaS Platform. NMaaS Portal is a Angular based application that is run in user's browser.","title":"NMaaS Portal"},{"location":"self-hosted-nmaas/introduction/#nmaas-janitor","text":"The NMaaS Janitor is a helper service that interacts with the self-hosted GitLab API, and deploys the boilerplate configuration templates within the Kubernetes cluster. NMaaS Janitor is also used to retrieve the status of Kubernetes services and load balancer IPs assigned to them. For this reason it also needs privileges to use the Kubernetes API, albeit not as permissive as NMaaS Helm.","title":"NMaaS Janitor"},{"location":"self-hosted-nmaas/introduction/#nmaas-helm","text":"NMaaS Helm interacts with the Kubernetes API of the underlying cluster where NMaaS is deployed, and manages it through the Helm v3 client. As a a result, it requires the cluster-admin Kubernetes role. Whenever a new application is deployed, the NMaaS Platform opens an SSH connection to NMaaS Helm and executes the required Helm command.","title":"NMaaS Helm"},{"location":"self-hosted-nmaas/introduction/#nmaas-postfix","text":"NMaaS Postfix is an in-cluster mail server that is used by any deployed applications to send emails to external destinations. It does not require any authentication before sending emails, and it can either be configured as a standalone mail server, or it can use a smart host, routing all outgoing emails through some other email server (e.g. Gmail). NMaaS Postfix without a Smart Host If NMaaS Postfix is not configured to use an external mail service for sending the emails, than most likely all outgoing emails will be marked as spam, and users will face delivery problems when sending alerts from their deployed applications.","title":"NMaaS Postfix"},{"location":"self-hosted-nmaas/introduction/#nmaas-service-provider-sp","text":"The NMaaS SP is an in-cluster SAML Proxy that allows for SSO user login based on SAML. The NMaaS SP component is composed of Apache HTTP server and a Shibboleth Service Provider (Shibboleth SP) software. NMaaS SP is initially configured to authenticate with eduGAIN as the federated Identify Provider but can be customized to work with any compliant IdP. NMaaS SP is still in a Testing Phase The in-cluster NMaaS SP was developed some time back but was never thoroughly tested. However NMaaS development team can provide guidelines on how to setup a NMaaS SAML Proxy on a dedicated VM. Such a setup is currently used for NMaaS production service. Nevertheless basic username and password based log in is available at all times.","title":"NMaaS Service Provider (SP)"},{"location":"self-hosted-nmaas/local-dev-environment/appendix/","text":"Appendix: Default Credentials for the NMaaS Development Virtual Machine Note The virtual machine image can be downloaded from https://drive1.demo.renater.fr/index.php/s/rp2awZ6sMnNFQwK . Users are advised to follow part 1 in order to set up the required VirtualBox NAT network before importing. Name Value Virtual Machine IP Address 10.99.99.100/24 IP Address FreeRTR Instance #1 10.99.99.50 Port for Telnet Access FreeRTR Instance #1 1123 IP Address FreeRTR Instance #2 10.99.99.51 Port for Telnet Access FreeRTR Instance #1 1124 Virtual Machine Username nmaas Virtual Machine Password nmaas NMaaS URL https://nmaas.10.99.99.150.nip.io NMaaS Admin Username admin NMaaS Admin Password saamn NMaaS API Secret saamn GitLab URL https://gitlab.nmaas.10.99.99.150.nip.io/users/sign_in GitLab Admin Username root GitLab Admin Password nmaasgitlab GitLab User Access Token Yx5Hsmxzcb-D5XyQJu-n Prometheus Test Instance URL https://promdemo-demo.nmaas.10.99.99.150.nip.io Prometheus Test Instance HTTP Username nmaas_demo Prometheus Test Instance HTTP Password nmaasdemo Grafana Test Instance URL https://grafana-grafana-demo.nmaas.10.99.99.150.nip.io Grafana Test Instance Username nmaas_demo Grafana Test Instance Password nmaasdemo Oxidized Test Instance URL https://oxidized-demo.nmaas.10.99.99.150.nip.io Oxidized Test Instance HTTP Username nmaas_demo Oxidized Test Instance HTTP Password nmaasdemo UptimeKuma Test Instance URL https://uptimekuma-demo.nmaas.10.99.99.150.nip.io UptimeKuma Test Instance Username nmaas_demo UptimeKuma Test Instance Password nmaasdemo!","title":"Appendix - Credentials"},{"location":"self-hosted-nmaas/local-dev-environment/appendix/#appendix-default-credentials-for-the-nmaas-development-virtual-machine","text":"Note The virtual machine image can be downloaded from https://drive1.demo.renater.fr/index.php/s/rp2awZ6sMnNFQwK . Users are advised to follow part 1 in order to set up the required VirtualBox NAT network before importing. Name Value Virtual Machine IP Address 10.99.99.100/24 IP Address FreeRTR Instance #1 10.99.99.50 Port for Telnet Access FreeRTR Instance #1 1123 IP Address FreeRTR Instance #2 10.99.99.51 Port for Telnet Access FreeRTR Instance #1 1124 Virtual Machine Username nmaas Virtual Machine Password nmaas NMaaS URL https://nmaas.10.99.99.150.nip.io NMaaS Admin Username admin NMaaS Admin Password saamn NMaaS API Secret saamn GitLab URL https://gitlab.nmaas.10.99.99.150.nip.io/users/sign_in GitLab Admin Username root GitLab Admin Password nmaasgitlab GitLab User Access Token Yx5Hsmxzcb-D5XyQJu-n Prometheus Test Instance URL https://promdemo-demo.nmaas.10.99.99.150.nip.io Prometheus Test Instance HTTP Username nmaas_demo Prometheus Test Instance HTTP Password nmaasdemo Grafana Test Instance URL https://grafana-grafana-demo.nmaas.10.99.99.150.nip.io Grafana Test Instance Username nmaas_demo Grafana Test Instance Password nmaasdemo Oxidized Test Instance URL https://oxidized-demo.nmaas.10.99.99.150.nip.io Oxidized Test Instance HTTP Username nmaas_demo Oxidized Test Instance HTTP Password nmaasdemo UptimeKuma Test Instance URL https://uptimekuma-demo.nmaas.10.99.99.150.nip.io UptimeKuma Test Instance Username nmaas_demo UptimeKuma Test Instance Password nmaasdemo!","title":"Appendix: Default Credentials for the NMaaS Development Virtual Machine"},{"location":"self-hosted-nmaas/local-dev-environment/introduction/","text":"Introduction to the Local Development Environment Network management is an essential part of any production network, no matter its size. However, organizations often face staff shortages or lack the required resources to properly monitor their network. NMaaS (Network Management as a Service) is a G\u00c9ANT production service that allows effortless deployment of many open-source network monitoring tools on demand, with minimal initial configuration by the end users. Based on the Kubernetes container orchestrator, and deployable on private infrastructure as well, a dedicated NMaaS instance can be used as a central point for monitoring many distributed networks, by utilizing VPN tunnels. New applications can be added to the NMaaS catalogue at any time using Helm charts, an industry standard package manager for Kubernetes. NMaaS hides the operational complexity from end users who access the service through a web application from where they can manage and configure their existing application instances or deploy new ones. Users can also evaluate NMaaS on their own infrastructure by either following this tutorial or by simply downloading the already prepared virtual machine . After downloading the virtual machine image, users are advised to follow part 1 in order to set up the necessary VirtualBox NAT network which is required by the VM so that all of its components can run as expected, and the subnets described in the Appendix remain unchanged. By the end of this 5 part tutorial, users should have an exact replica of the setup done within the virtual machine. This tutorial begins with part 1 where a local Kubernetes cluster is initialized allowing users to choose between two lightweight Kubernetes distributions - MicroK8s or K3s. It then proceeds with part 2 where the NMaaS installation procedure is explained, along with all required dependencies. In part 3 , a simple method is described for setting up virtualized demo networking devices that can later be used as monitoring targets for the applications deployed by NMaaS. The process of deploying such monitoring applications from the list of supported applications in the NMaaS catalog is described in part 4 . The tutorial is concluded with part 5 , allowing advanced users to add their own custom applications to the NMaaS catalog, thus making it available to all potential users of their NMaaS instance. For users who choose to download the already prepared virtual machine and avoid the whole setup process, the Appendix gives an overview of all the credentials that have been used.","title":"Introduction"},{"location":"self-hosted-nmaas/local-dev-environment/introduction/#introduction-to-the-local-development-environment","text":"Network management is an essential part of any production network, no matter its size. However, organizations often face staff shortages or lack the required resources to properly monitor their network. NMaaS (Network Management as a Service) is a G\u00c9ANT production service that allows effortless deployment of many open-source network monitoring tools on demand, with minimal initial configuration by the end users. Based on the Kubernetes container orchestrator, and deployable on private infrastructure as well, a dedicated NMaaS instance can be used as a central point for monitoring many distributed networks, by utilizing VPN tunnels. New applications can be added to the NMaaS catalogue at any time using Helm charts, an industry standard package manager for Kubernetes. NMaaS hides the operational complexity from end users who access the service through a web application from where they can manage and configure their existing application instances or deploy new ones. Users can also evaluate NMaaS on their own infrastructure by either following this tutorial or by simply downloading the already prepared virtual machine . After downloading the virtual machine image, users are advised to follow part 1 in order to set up the necessary VirtualBox NAT network which is required by the VM so that all of its components can run as expected, and the subnets described in the Appendix remain unchanged. By the end of this 5 part tutorial, users should have an exact replica of the setup done within the virtual machine. This tutorial begins with part 1 where a local Kubernetes cluster is initialized allowing users to choose between two lightweight Kubernetes distributions - MicroK8s or K3s. It then proceeds with part 2 where the NMaaS installation procedure is explained, along with all required dependencies. In part 3 , a simple method is described for setting up virtualized demo networking devices that can later be used as monitoring targets for the applications deployed by NMaaS. The process of deploying such monitoring applications from the list of supported applications in the NMaaS catalog is described in part 4 . The tutorial is concluded with part 5 , allowing advanced users to add their own custom applications to the NMaaS catalog, thus making it available to all potential users of their NMaaS instance. For users who choose to download the already prepared virtual machine and avoid the whole setup process, the Appendix gives an overview of all the credentials that have been used.","title":"Introduction to the Local Development Environment"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/","text":"Part 1: Deploying a Local Kubernetes Cluster This tutorial will assume that NMaaS is installed in a virtual machine that is completely isolated from any production environment. However, the discussed steps are applicable to bare-metal hardware as well, once the correct network strategy has been identified by the system administrator. Virtual Machine Prerequisites Ubuntu >= 20.04 Server or any Desktop flavor 12GB+ RAM 2+ VCPUs 60GB+ storage space Virtual Machine Setup Although we will focus on VirtualBox, any virtualization software can be used, depending on the user's preference. Virtualbox 6 is an open-source virtualization software which can be downloaded for free from the official website . After installation, additional network configuration needs to be done before a Kubernetes cluster can be set up. The following network configuration creates a completely isolated network environment from the production network. NMaaS will only be accessible from the host operating system where the virtual machine is deployed. Our virtual machine will need three network interfaces in total: 3 NAT type network adapters (from the same NAT network) which are created manually in Virtualbox (one for Kubernetes, two for freeRTR) Optional: 1 Host-only type network adapter which is also created manually in Virtualbox - for accessing the NAT network from the host system. Using this approach, the NMaaS instance deployed inside the virtual machine will be made accessible by adding a custom route on the host operating system towards the NAT network, traversing the host-only interfaces. DHCP should not be enabled for the second or third NAT interfaces, but DHCP should be enabled for the first NAT interface. If an optional host interface has been added, DHCP should be enabled on it as well. Detailed description of the required configuration steps is given below. Creating a New NAT Network in Virtualbox Navigate to File -> Preferences -> Network and click the Plus button on the right hand side. Once added, click on the cog icon to configure the newly created network. Alter the network name as desired, and enter a preferred CIDR. Make sure that the Supports DHCP option is checked. If the pre-prepared NMaaS VirtualBox image is used, make sure to select the exact same Network CIDR (10.99.99.0/24) since all NMaaS components have already been installed and expect addresses in the 10.99.99.0/24 range. Optional: Creating a New Host-Only Network in Virtualbox If the NMaaS installation needs to be accessible from other networks, one option is to add a Host-Only interface to the virtual machine that will act as a transit between the outside networks and the internal VirtualBox NAT network configured in the previous step. Navigate to File -> Host Network Manager and click on the green Create Button. Select the Configure Adapter Manually radio button and enter the IP address that will be allocated to the host interface connected to the hypervisor along with an appropriate network mask. Make sure that the selected range does not overlap with any existing network or the previously created NAT network. Creating the Virtual Machine in VirtualBox Create a regular virtual machine in VirtualBox, using the latest Ubuntu 20.04 ISO. The following parameters need to be altered: Allocate sufficient memory to the virtual machine. 12GB is the minimum amount which will support a complete NMaaS installation, along with the possibility for deploying additional applications via the catalog. Allocate sufficient number of CPU cores, depending on the performance of your system. In the Network configuration tab, add three adapters: Adapter 1: NAT Network (Select the network created previously ) Adapter 2: NAT Network (Select the network created previously ) Adapter 3: NAT Network (Select the network created previously ) Optional: Adapter 4: Host-only Adapter (Select the network created previously ) If a Desktop version of Ubuntu is being installed, make sure to enable 3D acceleration in the Display tab. Configuring the Guest Operating System Once the guest operating system has been installed, DHCP should be manually disabled on the second and third NAT interfaces. In case of an Ubuntu Server installation, this can be done by editing the Netplan configuration, located in /etc/netplan/00-installer-config.yaml : /etc/netplan/00-installer-config.yaml 1 2 3 4 5 6 7 network : ethernets : ... enp0s8 : dhcp4 : false ... version : 2 Make sure to execute sudo netplan apply so that the new changes will take effect. Desktop editions of Ubuntu usually come with their own GUI network manager, so the interface status should be set to Disabled : Optional: In case a host-only interface has been added to the virtual machine, create a route on your host operating system towards the NAT network via the host-only network interface. Examples are given below both for Microsoft Windows and GNU/Linux host operating systems below. Microsoft Windows 1 2 3 route add < NAT_NETWORK > mask < SUBNET_MASK > < VIRTUALBOX_HOST_NETWORK_IP > # Using the examples above, the command would be: # route add 10.99.99.0 mask 255.255.255.0 192.168.56.1 GNU/Linux 1 2 3 ip route add <NAT_NETWORK>/<CIDR_PREFIX> via <VIRTUALBOX_HOST_NETWORK_IP> # Using the examples above, the command would be: # ip route add 10.99.99.0/24 via 192.168.56.1 Kubernetes Cluster Setup In this section we discuss two quick methods of setting up a local Kubernetes cluster. Option 1: MicroK8s Installation MicroK8s is a snap-based application that can setup a fully functional Kubernetes cluster by executing a single command. It also supports many popular addons which can also be enabled very easily. MicroK8s abstracts away many Kubernetes configuration steps, especially when using the addon system. This can be seen as either an advantage or a disadvantage. Install the MicroK8s snap, using the 1.20 version: 1 sudo snap install microk8s --classic --channel = 1 .20/stable Add the current user to the microk8s group so that access to the microk8s command is unrestricted: 1 2 3 sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Wait until everything is ready: 1 microk8s status --wait-ready Manually check the node status and the list of running pods: 1 2 microk8s kubectl get node microk8s kubectl get pod --all-namespaces Addons Setup CNI Calico comes installed by default, no further manual configuration is required. DNS To enable CoreDNS the following command should be executed: 1 microk8s enable dns By default the Google DNS servers will be used as upstreams (8.8.8.8 and 8.8.4.4). If there is a local DNS server available that should be used instead, it can be specified using semicolons: 1 microk8s enable dns:192.168.1.1 Once the command is executed, all of the necessary Kubernetes resources are immediately created and the associated pods brought up: 1 2 3 4 5 6 microk8s kubectl get pod -n kube-system # NAME READY STATUS RESTARTS AGE # calico-node-gvlsm 1/1 Running 0 8m39s # coredns-86f78bb79c-zhn7p 1/1 Running 0 74s # calico-kube-controllers-847c8c99d-vrlm2 1/1 Running 0 8m42s Testing DNS Resolution Testing the DNS resolution is an optional, but recommended step to ensure that the deployed CoreDNS instance is functioning properly. To do so, an instance of dnsutils can be deployed: 1 microk8s kubectl apply -f https://k8s.io/examples/admin/dns/dnsutils.yaml Once the Pod enters a ready state, we can open a shell session: 1 2 microk8s kubectl exec -it dnsutils -- /bin/sh ping geant.org Storage A local path provisioner can be enabled using: 1 microk8s enable storage Beware when using this in clusters with more than one node. MetalLB MetalLB is a Kubernetes LoadBalancer implementation. 1 microk8s enable metallb:192.168.99.150-192.168.99.200 Pick a free range from the local address space for easiest access during testing. Ingress Nginx Ingress Nginx is a popular Ingress controller for Kubernetes, based on the widely used Nginx web server. 1 microk8s enable ingress To make the newly deployed ingress accessible from outside the CNI network, a LoadBalancer Service can be created with an address assigned by MetalLB: ingress-lb.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion : v1 kind : Service metadata : name : ingress namespace : ingress spec : selector : name : nginx-ingress-microk8s type : LoadBalancer ports : - name : http protocol : TCP port : 80 targetPort : 80 - name : https protocol : TCP port : 443 targetPort : 443 1 2 microk8s kubectl create -f ingress-lb.yaml --save-config microk8s kubectl get service -n ingress Once the assigned IP to the LoadBalancer Service has been acquired by executing the previous command, a browser window can be opened on the local workstation so as to perform a test access to the Ingress Controller. A generic 404 not found message should be displayed. Helm Helm is a package manager for Kubernetes allowing seamless installation of complex application. NMaaS and all of its dependencies have also been packaged as Helm charts, thus easing their deployment process. 1 microk8s enable helm3 Similarly to the way that the kubectl client is accessed, Helm can be invoked using: 1 2 3 microk8s helm3 <HELM_COMMAND> # for example: microk8s helm3 list --all-namespaces Helm Version Unfortunately, the Helm version installed in this manner, as an official MicroK8s addon is too old. A newer version, if needed, can be installed by following the instructions available below. Please note that the GitLab chart, which is a dependency of NMaaS requires a newer Helm version than the one installed as a MicroK8s addon. Installing a Newer Helm Version Download the latest Helm release from https://github.com/helm/helm/releases for your architecture (e.g. https://get.helm.sh/helm-v3.7.0-linux-amd64.tar.gz ). Unpack the downloaded archive file and move it to a location in PATH . 1 2 3 4 wget https://get.helm.sh/helm-v3.7.0-linux-amd64.tar.gz -O helm-latest.tar.gz tar -xvzf helm-latest.tar.gz mv linux-amd64/helm /usr/local/bin chmod +x /usr/local/bin/helm Finally, the kube config to interact with the MicroK8s Kubernetes cluster needs to be copied to the appropriate location: 1 microk8s.config > ~/.kube/config Option 2: K3s Installation K3s is another easy way to configure a full-fledged Kubernetes cluster in a matter of minutes. K3s is more lightweight than other Kubernetes distributions since it does not ship with unnecessary modules, such as the ones for integrating with various cloud providers. K3s offers seamless scalability across multiple nodes and provides the ability to either use an embedded database for storing the cluster state or a relational one, such as PostgreSQL or MySQL. K3s can be installed with the following command: 1 2 3 4 5 6 7 8 9 10 export INSTALL_K3S_VERSION = v1.20.14+k3s2 curl -sfL https://get.k3s.io | sh -s - server \\ --tls-san demo.nmaas.local \\ --tls-san 10 .99.99.100 \\ --disable = traefik \\ --flannel-backend = none \\ --disable-network-policy \\ --disable = servicelb \\ --write-kubeconfig-mode 664 \\ --cluster-cidr = 10 .136.0.0/16 --tls-san \u2013 can be specified multiple times to add additional names for which the automatically generated Kubernetes API certificates will be valid. Make sure to replace the IP address with the IP address of your VM . --disable=traefik \u2013 Traefik needs to be explicitly disabled since it ships by default with new K3s installations. We will use ingress-nginx as our ingress controller and will install it manually in a later step. --flannel-backend=none \u2013 Flannel CNI needs to be explicitly disabled, since we will manually install Calico. --disable-network-policy \u2013 we do not need the default network policy addon that enabled the use of Kubernetes NetworkPolicy objects, since Calico has built-in support for network policies. --disable=servicelb \u2013 the preconfigured implementation for LoadBalancer service objects should be disabled, since we will manually install MetalLB. --write-kubeconfig-mode 664 \u2013 more permissive permissions are needed for the automatically generated kubeconfig file so that regular users, apart from root, can use the kubectl client as well. --clister-cidr=10.136.0.0/16 \u2013 a free subnet range which will be used as the pod network. Should be written down since it will be required in the Calico deployment as well. Another way of providing kubectl access to different users is to make a copy of the original kubeconfig file located in /etc/rancher/k3s/k3s.yaml into a directory and changing its permissions. Then, by exporting the KUBECONFIG environment variable, the kubectl client will be forced to use the newly created configuration: 1 export KUBECONFIG = ~/.kube/config Our cluster is still not in a Ready state, since we do not have a CNI plugin installed yet. 1 kubectl get node -o wide Addons Setup CNI Calico can be manually installed by downloading the manifest file and setting the CALICO_IPV4POOL_CIDR parameter to the value set when deploying K3s. 1 2 3 4 mkdir -p ~/manifests/calico cd ~/manifests/calico wget https://docs.projectcalico.org/manifests/calico.yaml nano calico.yaml calico.yaml 1 2 3 4 5 6 7 8 ... # The default IPv4 pool to create on startup if none exists. Pod IPs will be # chosen from this range. Changing this value after installation will have # no effect. This should fall within `--cluster-cidr`. - name : CALICO_IPV4POOL_CIDR value : \"10.136.0.0/16\" # Disable file logging so `kubectl logs` works. ... 1 kubectl create -f calico.yaml --save-config Once Calico has been installed, the node should transition to a Ready state. 1 kubectl get node -o wide DNS CoreDNS is installed by default with K3s, so no need for any manual installation or configuration. Once Calico CNI has been deployed and the cluster has entered a Ready state, DNS resolution can be tested using the dnsutil pod, as described in the official Kubernetes documentation page. 1 kubectl apply -f https://k8s.io/examples/admin/dns/dnsutils.yaml Once the Pod enters a ready state, we can open a shell session: 1 2 kubectl exec -it dnsutils -- /bin/sh ping geant.org Storage An instance of local path provisioner is automatically installed when deploying K3s, which is sufficient for development single-node clusters such as ours. 1 2 3 # kubectl get storageclass NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE local-path ( default ) rancher.io/local-path Delete WaitForFirstConsumer false 45h MetalLB MetalLB can be installed using the official Kubernetes manifests. To install MetalLB, first the metallb-system namespace must be created: 1 kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml Once the namespace has been created, it can be populated with all of the other necessary components: 1 kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml Finally, a default configuration ConfigMap should be created, describing the address range allocated to MetalLB. Please make sure to select an unused block of space. In our case, we will use addresses 10.99.99.150 to 10.99.99.200 from the GEANT NAT network which we configured in VirtualBox at the start of the guide. metallb-config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion : v1 kind : ConfigMap metadata : namespace : metallb-system name : config data : config : | address-pools: - name: default protocol: layer2 addresses: - 10.99.99.150-10.99.99.200 1 kubectl create -f metallb-config.yaml --save-config Helm To install Helm, we need to first download the latest binary for our architecture and extract it to a location which is in the PATH system variable. Visit https://github.com/helm/helm/releases and copy the download link for the latest release. Download the latest release locally 1 2 3 4 cd $( mktemp -d ) wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz tar -xvzf helm-v3.7.1-linux-amd64.tar.gz sudo mv helm /usr/local/bin/helm Test whether Helm has been successfully installed by executing helm version . Ingress Nginx The last application that needs to be installed before we can move on to installing the NMaaS components is Ingress Nginx. Since we have already configured Helm, the Ingress Nginx installation is simple. Customize the values.yaml file according to the local environment: ingress-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 defaultBackend : enabled : true controller : config : log-format-upstream : '{\"time\": \"$time_iso8601\", \"remote_addr\": \"$proxy_protocol_addr\", \"x-forward-for\": \"$proxy_add_x_forwarded_for\", \"request_id\": \"$req_id\", \"remote_user\": \"$remote_user\", \"bytes_sent\": $bytes_sent, \"request_time\": $request_time, \"status\":$status, \"vhost\": \"$host\", \"request_proto\": \"$server_protocol\", \"path\": \"$uri\", \"request_query\": \"$args\", \"request_length\": $request_length, \"duration\": $request_time,\"method\": \"$request_method\", \"http_referrer\": \"$http_referer\", \"http_user_agent\": \"$http_user_agent\" }' kind : Deployment ingressClass : nginx scope : enabled : false namespace : default service : type : LoadBalancer metrics : enabled : false In our case we have opted to use a Deployment instead of a DaemonSet for the deployment strategy. Additionally, we have selected a service type of LoadBalancer since we have already installed MetalLB and it is ready to allocate an IP address to our LoadBalancer service. Add the ingress-nginx Helm repository and install the application: 1 2 3 4 helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update kubectl create namespace nmaas-system helm install -f ingress-values.yaml --namespace nmaas-system nmaas-ingress ingress-nginx/ingress-nginx We have chosen to install ingress-nginx in the nmaas-system namespace, which will house all the other NMaaS components as well. Note About Helm Errors When running the helm install command, Helm might throw an error about the cluster being unreachable. This is most likely because Helm looks for the kube.config file in the default location, but --write-kubeconfig-mode 664 has been specified during the K3s installation, and the actual location is /etc/rancher/k3s/k3s.yaml . This can be fixed by simply executing: 1 export KUBECONFIG = '/etc/rancher/k3s/k3s.yaml' We can test the installed ingress by directly visiting the allocated LoadBalancer IP address in a browser. We should be presented with a generic 404-not found page. 1 2 kubectl get service -n nmaas-system curl --insecure https://10.99.99.150","title":"Part 1 - Deploying a Local Kubernetes Cluster"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#part-1-deploying-a-local-kubernetes-cluster","text":"This tutorial will assume that NMaaS is installed in a virtual machine that is completely isolated from any production environment. However, the discussed steps are applicable to bare-metal hardware as well, once the correct network strategy has been identified by the system administrator.","title":"Part 1: Deploying a Local Kubernetes Cluster"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#virtual-machine-prerequisites","text":"Ubuntu >= 20.04 Server or any Desktop flavor 12GB+ RAM 2+ VCPUs 60GB+ storage space","title":"Virtual Machine Prerequisites"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#virtual-machine-setup","text":"Although we will focus on VirtualBox, any virtualization software can be used, depending on the user's preference. Virtualbox 6 is an open-source virtualization software which can be downloaded for free from the official website . After installation, additional network configuration needs to be done before a Kubernetes cluster can be set up. The following network configuration creates a completely isolated network environment from the production network. NMaaS will only be accessible from the host operating system where the virtual machine is deployed. Our virtual machine will need three network interfaces in total: 3 NAT type network adapters (from the same NAT network) which are created manually in Virtualbox (one for Kubernetes, two for freeRTR) Optional: 1 Host-only type network adapter which is also created manually in Virtualbox - for accessing the NAT network from the host system. Using this approach, the NMaaS instance deployed inside the virtual machine will be made accessible by adding a custom route on the host operating system towards the NAT network, traversing the host-only interfaces. DHCP should not be enabled for the second or third NAT interfaces, but DHCP should be enabled for the first NAT interface. If an optional host interface has been added, DHCP should be enabled on it as well. Detailed description of the required configuration steps is given below.","title":"Virtual Machine Setup"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#creating-a-new-nat-network-in-virtualbox","text":"Navigate to File -> Preferences -> Network and click the Plus button on the right hand side. Once added, click on the cog icon to configure the newly created network. Alter the network name as desired, and enter a preferred CIDR. Make sure that the Supports DHCP option is checked. If the pre-prepared NMaaS VirtualBox image is used, make sure to select the exact same Network CIDR (10.99.99.0/24) since all NMaaS components have already been installed and expect addresses in the 10.99.99.0/24 range.","title":"Creating a New NAT Network in Virtualbox"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#optional-creating-a-new-host-only-network-in-virtualbox","text":"If the NMaaS installation needs to be accessible from other networks, one option is to add a Host-Only interface to the virtual machine that will act as a transit between the outside networks and the internal VirtualBox NAT network configured in the previous step. Navigate to File -> Host Network Manager and click on the green Create Button. Select the Configure Adapter Manually radio button and enter the IP address that will be allocated to the host interface connected to the hypervisor along with an appropriate network mask. Make sure that the selected range does not overlap with any existing network or the previously created NAT network.","title":"Optional: Creating a New Host-Only Network in Virtualbox"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#creating-the-virtual-machine-in-virtualbox","text":"Create a regular virtual machine in VirtualBox, using the latest Ubuntu 20.04 ISO. The following parameters need to be altered: Allocate sufficient memory to the virtual machine. 12GB is the minimum amount which will support a complete NMaaS installation, along with the possibility for deploying additional applications via the catalog. Allocate sufficient number of CPU cores, depending on the performance of your system. In the Network configuration tab, add three adapters: Adapter 1: NAT Network (Select the network created previously ) Adapter 2: NAT Network (Select the network created previously ) Adapter 3: NAT Network (Select the network created previously ) Optional: Adapter 4: Host-only Adapter (Select the network created previously ) If a Desktop version of Ubuntu is being installed, make sure to enable 3D acceleration in the Display tab.","title":"Creating the Virtual Machine in VirtualBox"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#configuring-the-guest-operating-system","text":"Once the guest operating system has been installed, DHCP should be manually disabled on the second and third NAT interfaces. In case of an Ubuntu Server installation, this can be done by editing the Netplan configuration, located in /etc/netplan/00-installer-config.yaml : /etc/netplan/00-installer-config.yaml 1 2 3 4 5 6 7 network : ethernets : ... enp0s8 : dhcp4 : false ... version : 2 Make sure to execute sudo netplan apply so that the new changes will take effect. Desktop editions of Ubuntu usually come with their own GUI network manager, so the interface status should be set to Disabled : Optional: In case a host-only interface has been added to the virtual machine, create a route on your host operating system towards the NAT network via the host-only network interface. Examples are given below both for Microsoft Windows and GNU/Linux host operating systems below. Microsoft Windows 1 2 3 route add < NAT_NETWORK > mask < SUBNET_MASK > < VIRTUALBOX_HOST_NETWORK_IP > # Using the examples above, the command would be: # route add 10.99.99.0 mask 255.255.255.0 192.168.56.1 GNU/Linux 1 2 3 ip route add <NAT_NETWORK>/<CIDR_PREFIX> via <VIRTUALBOX_HOST_NETWORK_IP> # Using the examples above, the command would be: # ip route add 10.99.99.0/24 via 192.168.56.1","title":"Configuring the Guest Operating System"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#kubernetes-cluster-setup","text":"In this section we discuss two quick methods of setting up a local Kubernetes cluster.","title":"Kubernetes Cluster Setup"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#option-1-microk8s-installation","text":"MicroK8s is a snap-based application that can setup a fully functional Kubernetes cluster by executing a single command. It also supports many popular addons which can also be enabled very easily. MicroK8s abstracts away many Kubernetes configuration steps, especially when using the addon system. This can be seen as either an advantage or a disadvantage. Install the MicroK8s snap, using the 1.20 version: 1 sudo snap install microk8s --classic --channel = 1 .20/stable Add the current user to the microk8s group so that access to the microk8s command is unrestricted: 1 2 3 sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Wait until everything is ready: 1 microk8s status --wait-ready Manually check the node status and the list of running pods: 1 2 microk8s kubectl get node microk8s kubectl get pod --all-namespaces","title":"Option 1: MicroK8s Installation"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#addons-setup","text":"","title":"Addons Setup"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#cni","text":"Calico comes installed by default, no further manual configuration is required.","title":"CNI"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#dns","text":"To enable CoreDNS the following command should be executed: 1 microk8s enable dns By default the Google DNS servers will be used as upstreams (8.8.8.8 and 8.8.4.4). If there is a local DNS server available that should be used instead, it can be specified using semicolons: 1 microk8s enable dns:192.168.1.1 Once the command is executed, all of the necessary Kubernetes resources are immediately created and the associated pods brought up: 1 2 3 4 5 6 microk8s kubectl get pod -n kube-system # NAME READY STATUS RESTARTS AGE # calico-node-gvlsm 1/1 Running 0 8m39s # coredns-86f78bb79c-zhn7p 1/1 Running 0 74s # calico-kube-controllers-847c8c99d-vrlm2 1/1 Running 0 8m42s","title":"DNS"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#testing-dns-resolution","text":"Testing the DNS resolution is an optional, but recommended step to ensure that the deployed CoreDNS instance is functioning properly. To do so, an instance of dnsutils can be deployed: 1 microk8s kubectl apply -f https://k8s.io/examples/admin/dns/dnsutils.yaml Once the Pod enters a ready state, we can open a shell session: 1 2 microk8s kubectl exec -it dnsutils -- /bin/sh ping geant.org","title":"Testing DNS Resolution"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#storage","text":"A local path provisioner can be enabled using: 1 microk8s enable storage Beware when using this in clusters with more than one node.","title":"Storage"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#metallb","text":"MetalLB is a Kubernetes LoadBalancer implementation. 1 microk8s enable metallb:192.168.99.150-192.168.99.200 Pick a free range from the local address space for easiest access during testing.","title":"MetalLB"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#ingress-nginx","text":"Ingress Nginx is a popular Ingress controller for Kubernetes, based on the widely used Nginx web server. 1 microk8s enable ingress To make the newly deployed ingress accessible from outside the CNI network, a LoadBalancer Service can be created with an address assigned by MetalLB: ingress-lb.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion : v1 kind : Service metadata : name : ingress namespace : ingress spec : selector : name : nginx-ingress-microk8s type : LoadBalancer ports : - name : http protocol : TCP port : 80 targetPort : 80 - name : https protocol : TCP port : 443 targetPort : 443 1 2 microk8s kubectl create -f ingress-lb.yaml --save-config microk8s kubectl get service -n ingress Once the assigned IP to the LoadBalancer Service has been acquired by executing the previous command, a browser window can be opened on the local workstation so as to perform a test access to the Ingress Controller. A generic 404 not found message should be displayed.","title":"Ingress Nginx"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#helm","text":"Helm is a package manager for Kubernetes allowing seamless installation of complex application. NMaaS and all of its dependencies have also been packaged as Helm charts, thus easing their deployment process. 1 microk8s enable helm3 Similarly to the way that the kubectl client is accessed, Helm can be invoked using: 1 2 3 microk8s helm3 <HELM_COMMAND> # for example: microk8s helm3 list --all-namespaces Helm Version Unfortunately, the Helm version installed in this manner, as an official MicroK8s addon is too old. A newer version, if needed, can be installed by following the instructions available below. Please note that the GitLab chart, which is a dependency of NMaaS requires a newer Helm version than the one installed as a MicroK8s addon.","title":"Helm"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#installing-a-newer-helm-version","text":"Download the latest Helm release from https://github.com/helm/helm/releases for your architecture (e.g. https://get.helm.sh/helm-v3.7.0-linux-amd64.tar.gz ). Unpack the downloaded archive file and move it to a location in PATH . 1 2 3 4 wget https://get.helm.sh/helm-v3.7.0-linux-amd64.tar.gz -O helm-latest.tar.gz tar -xvzf helm-latest.tar.gz mv linux-amd64/helm /usr/local/bin chmod +x /usr/local/bin/helm Finally, the kube config to interact with the MicroK8s Kubernetes cluster needs to be copied to the appropriate location: 1 microk8s.config > ~/.kube/config","title":"Installing a Newer Helm Version"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#option-2-k3s-installation","text":"K3s is another easy way to configure a full-fledged Kubernetes cluster in a matter of minutes. K3s is more lightweight than other Kubernetes distributions since it does not ship with unnecessary modules, such as the ones for integrating with various cloud providers. K3s offers seamless scalability across multiple nodes and provides the ability to either use an embedded database for storing the cluster state or a relational one, such as PostgreSQL or MySQL. K3s can be installed with the following command: 1 2 3 4 5 6 7 8 9 10 export INSTALL_K3S_VERSION = v1.20.14+k3s2 curl -sfL https://get.k3s.io | sh -s - server \\ --tls-san demo.nmaas.local \\ --tls-san 10 .99.99.100 \\ --disable = traefik \\ --flannel-backend = none \\ --disable-network-policy \\ --disable = servicelb \\ --write-kubeconfig-mode 664 \\ --cluster-cidr = 10 .136.0.0/16 --tls-san \u2013 can be specified multiple times to add additional names for which the automatically generated Kubernetes API certificates will be valid. Make sure to replace the IP address with the IP address of your VM . --disable=traefik \u2013 Traefik needs to be explicitly disabled since it ships by default with new K3s installations. We will use ingress-nginx as our ingress controller and will install it manually in a later step. --flannel-backend=none \u2013 Flannel CNI needs to be explicitly disabled, since we will manually install Calico. --disable-network-policy \u2013 we do not need the default network policy addon that enabled the use of Kubernetes NetworkPolicy objects, since Calico has built-in support for network policies. --disable=servicelb \u2013 the preconfigured implementation for LoadBalancer service objects should be disabled, since we will manually install MetalLB. --write-kubeconfig-mode 664 \u2013 more permissive permissions are needed for the automatically generated kubeconfig file so that regular users, apart from root, can use the kubectl client as well. --clister-cidr=10.136.0.0/16 \u2013 a free subnet range which will be used as the pod network. Should be written down since it will be required in the Calico deployment as well. Another way of providing kubectl access to different users is to make a copy of the original kubeconfig file located in /etc/rancher/k3s/k3s.yaml into a directory and changing its permissions. Then, by exporting the KUBECONFIG environment variable, the kubectl client will be forced to use the newly created configuration: 1 export KUBECONFIG = ~/.kube/config Our cluster is still not in a Ready state, since we do not have a CNI plugin installed yet. 1 kubectl get node -o wide","title":"Option 2: K3s Installation"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#addons-setup_1","text":"","title":"Addons Setup"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#cni_1","text":"Calico can be manually installed by downloading the manifest file and setting the CALICO_IPV4POOL_CIDR parameter to the value set when deploying K3s. 1 2 3 4 mkdir -p ~/manifests/calico cd ~/manifests/calico wget https://docs.projectcalico.org/manifests/calico.yaml nano calico.yaml calico.yaml 1 2 3 4 5 6 7 8 ... # The default IPv4 pool to create on startup if none exists. Pod IPs will be # chosen from this range. Changing this value after installation will have # no effect. This should fall within `--cluster-cidr`. - name : CALICO_IPV4POOL_CIDR value : \"10.136.0.0/16\" # Disable file logging so `kubectl logs` works. ... 1 kubectl create -f calico.yaml --save-config Once Calico has been installed, the node should transition to a Ready state. 1 kubectl get node -o wide","title":"CNI"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#dns_1","text":"CoreDNS is installed by default with K3s, so no need for any manual installation or configuration. Once Calico CNI has been deployed and the cluster has entered a Ready state, DNS resolution can be tested using the dnsutil pod, as described in the official Kubernetes documentation page. 1 kubectl apply -f https://k8s.io/examples/admin/dns/dnsutils.yaml Once the Pod enters a ready state, we can open a shell session: 1 2 kubectl exec -it dnsutils -- /bin/sh ping geant.org","title":"DNS"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#storage_1","text":"An instance of local path provisioner is automatically installed when deploying K3s, which is sufficient for development single-node clusters such as ours. 1 2 3 # kubectl get storageclass NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE local-path ( default ) rancher.io/local-path Delete WaitForFirstConsumer false 45h","title":"Storage"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#metallb_1","text":"MetalLB can be installed using the official Kubernetes manifests. To install MetalLB, first the metallb-system namespace must be created: 1 kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml Once the namespace has been created, it can be populated with all of the other necessary components: 1 kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml Finally, a default configuration ConfigMap should be created, describing the address range allocated to MetalLB. Please make sure to select an unused block of space. In our case, we will use addresses 10.99.99.150 to 10.99.99.200 from the GEANT NAT network which we configured in VirtualBox at the start of the guide. metallb-config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion : v1 kind : ConfigMap metadata : namespace : metallb-system name : config data : config : | address-pools: - name: default protocol: layer2 addresses: - 10.99.99.150-10.99.99.200 1 kubectl create -f metallb-config.yaml --save-config","title":"MetalLB"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#helm_1","text":"To install Helm, we need to first download the latest binary for our architecture and extract it to a location which is in the PATH system variable. Visit https://github.com/helm/helm/releases and copy the download link for the latest release. Download the latest release locally 1 2 3 4 cd $( mktemp -d ) wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz tar -xvzf helm-v3.7.1-linux-amd64.tar.gz sudo mv helm /usr/local/bin/helm Test whether Helm has been successfully installed by executing helm version .","title":"Helm"},{"location":"self-hosted-nmaas/local-dev-environment/p1_local-kubernetes-cluster/#ingress-nginx_1","text":"The last application that needs to be installed before we can move on to installing the NMaaS components is Ingress Nginx. Since we have already configured Helm, the Ingress Nginx installation is simple. Customize the values.yaml file according to the local environment: ingress-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 defaultBackend : enabled : true controller : config : log-format-upstream : '{\"time\": \"$time_iso8601\", \"remote_addr\": \"$proxy_protocol_addr\", \"x-forward-for\": \"$proxy_add_x_forwarded_for\", \"request_id\": \"$req_id\", \"remote_user\": \"$remote_user\", \"bytes_sent\": $bytes_sent, \"request_time\": $request_time, \"status\":$status, \"vhost\": \"$host\", \"request_proto\": \"$server_protocol\", \"path\": \"$uri\", \"request_query\": \"$args\", \"request_length\": $request_length, \"duration\": $request_time,\"method\": \"$request_method\", \"http_referrer\": \"$http_referer\", \"http_user_agent\": \"$http_user_agent\" }' kind : Deployment ingressClass : nginx scope : enabled : false namespace : default service : type : LoadBalancer metrics : enabled : false In our case we have opted to use a Deployment instead of a DaemonSet for the deployment strategy. Additionally, we have selected a service type of LoadBalancer since we have already installed MetalLB and it is ready to allocate an IP address to our LoadBalancer service. Add the ingress-nginx Helm repository and install the application: 1 2 3 4 helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update kubectl create namespace nmaas-system helm install -f ingress-values.yaml --namespace nmaas-system nmaas-ingress ingress-nginx/ingress-nginx We have chosen to install ingress-nginx in the nmaas-system namespace, which will house all the other NMaaS components as well. Note About Helm Errors When running the helm install command, Helm might throw an error about the cluster being unreachable. This is most likely because Helm looks for the kube.config file in the default location, but --write-kubeconfig-mode 664 has been specified during the K3s installation, and the actual location is /etc/rancher/k3s/k3s.yaml . This can be fixed by simply executing: 1 export KUBECONFIG = '/etc/rancher/k3s/k3s.yaml' We can test the installed ingress by directly visiting the allocated LoadBalancer IP address in a browser. We should be presented with a generic 404-not found page. 1 2 kubectl get service -n nmaas-system curl --insecure https://10.99.99.150","title":"Ingress Nginx"},{"location":"self-hosted-nmaas/local-dev-environment/p2_installing-nmaas/","text":"Part 2: Installing NMaaS Once a working Kubernetes cluster has been deployed, we are ready to proceed to the next step - installing NMaaS. All the necessary components will be installed in a single namespace \u2013 nmaas-system . If this namespace has not been created so far, execute: 1 kubectl create namespace nmaas-system GitLab Installation The first NMaaS dependency that we will set up is GitLab, a self-hosted web based Git repository hosting service. Many applications that are deployed by NMaaS users store their configuration data in a Git repository, allowing easier editing, and version management. GitLab has an official Helm chart, and we will use it to create a basic GitLab installation locally. Some parameters must be customized in the values.yaml file before deployment: global.hosts.domain \u2013 should be set to the domain that will be allocated to GitLab. Note that the final hostname where GitLab will be reachable will have a gitlab prepended to it. If nmaas.example.local is set as the global.hosts.domain parameter, then GitLab will be available on gitlab.nmaas.example.local . global.hosts.ssh \u2013 in order for users to be able to interact with their GitLab repositories via SSH, the value of global.hosts.ssh should be set to the MetalLB IP that will be assigned to this new service (usually the next available one) for the gitlab-shell component. If the IP is not known at the time of deployment, then after the initial deployment, once the LoadBalancer service is created and the IP is allocated, a chart upgrade can be performed, where the global.hosts.ssh parameter will be set to the appropriate value. global.ingress.tls.secretName \u2013 an existing Kubernetes TLS secret where the TLS certificate to be used is stored. global.ingress.annotations.kubernetes.io/ingress.class \u2013 should be set to the ingress class used by the deployed ingress-nginx instance. In case of MicroK8s this should be set to public. In case of K3s, it should be set to nginx . optionally, if an email server is available, the global.smtp section can be edited with the appropriate parameters so that outbound email is enabled. gitlab-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 certmanager : install : false nginx-ingress : enabled : false prometheus : install : false redis : install : true postgresql : postgresqlUsername : gitlab install : true postgresqlDatabase : gitlabhq_production usePasswordFile : false existingSecret : 'gitlab-postgresql' master : extraVolumeMounts : - name : custom-init-scripts mountPath : /docker-entrypoint-preinitdb.d/init_revision.sh subPath : init_revision.sh podAnnotations : postgresql.gitlab/init-revision : \"1\" metrics : enabled : false gitlab-runner : install : false gitlab-shell : service : type : LoadBalancer global : edition : ce hosts : domain : nmaas.<INGRESS_IP>.nip.io https : true ssh : <LB_SSH_IP>.nip.io ingress : enabled : true configureCertmanager : false tls : enabled : true # secretName: <EXISTING_OR_DUMMY_TLS_SECRET_NAME> # can be left empty, self-signed certificates will be generated path : / annotations : kubernetes.io/ingress.class : \"public\" initialRootPassword : secret : gitlab-root-password key : password appConfig : defaultProjectFeatures : builds : false time_zone : Europe/Warsaw smtp : enabled : false address : smtp.mailgun.org port : 2525 user_name : \"\" ## doc/installation/secrets.md#smtp-password password : secret : \"my-smtp-secret\" key : password # domain: authentication : \"plain\" starttls_auto : false openssl_verify_mode : \"peer\" ## doc/installation/deployment.md#outgoing-email ## Email persona used in email sent by GitLab email : from : '' display_name : GitLab reply_to : '' subject_suffix : '' smime : enabled : false secretName : \"\" keyName : \"tls.key\" certName : \"tls.crt\" GitLab requires the deployment of a PostgreSQL instance. The necessary secrets containing the PostgreSQL passwords need to be created, as well as the secret containing the initial root GitLab password: 1 2 kubectl create secret generic -n <NAMESPACE> gitlab-postgresql --from-literal = postgresql-password = <POSTGRESQL_USER_PASSWORD> --from-literal = postgresql-postgres-password = <POSTGRESQL_ROOT_PASSWORD> kubectl create secret generic -n <NAMESPACE> gitlab-root-password --from-literal = password = <GITLAB_ROOT_PASSWORD> The root GitLab password will be used for login to the GitLab web interface. We are ready to add the GitLab Helm repository and install the 4.X version of GitLab: 1 2 3 helm repo add gitlab https://charts.gitlab.io helm repo update helm install -f gitlab-values.yaml --namespace nmaas-system nmaas-gitlab --version 4 .12.13 gitlab/gitlab Once GitLab has been deployed, it should be possible to navigate to the login page using a web browser. After logging in, users are advised to configure the following settings: disable new user registrations ( Admin Area -> Settings -> General -> Sign-up restrictions ) Sign-up enabled should be unchecked Require admin approval for new sign-ups should be unchecked enable webhooks to local addresses ( Admin Area -> Settings -> Network -> Outbound requests ) Allow requests to the local network from web hooks and services = checked Allow requests to the local network from system hooks = checked The final step before installing NMaaS itself is to generate a GitLab personal access token which will allow NMaaS to connect to the GitLab API. This can be done from the User Profile page: 1 2 - Click on the user avatar in the right-hand corner of the screen, Edit Profile. Select Access Tokens from the left-hand navigation menu. Give a new name for the authentication token, as well as an optional expiry date. Check all scopes. - Store the token until the next section, where we will create a new secret containing it. NMaaS Installation The final step is to install NMaaS. NMaaS uses SSH communication to connect between components, so we need to create an SSH key pair and store it in a Kubernetes secret. This can be done by executing the following commands: 1 2 3 4 5 6 7 8 9 #!/bin/bash tmpdir = $( mktemp -d ) ssh-keygen -f $tmpdir /key -N \"\" # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPrivate }} kubectl create secret generic nmaas-helm-key-private -n <NMAAS_NAMESPACE> --from-file = id_rsa = $tmpdir /key # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPublic }} kubectl create secret generic nmaas-helm-key-public -n <NMAAS_NAMESPACE> --from-file = helm = $tmpdir /key.pub A few parameters need to be customized in the values.yaml file, to reflect the environment where NMaaS is deployed. global.wildcardCertificateName \u2013 the name of the secret containing the TLS certificate to be used to secure the HTTP communication global.nmaasDomain \u2013 the hostname where NMaaS will be accessible. platform.properties.adminEmail \u2013 the email address which will receive various notifications such as new user sign-up, deployment errors, new application versions... platform.adminPassword.literal \u2013 the password used to login as the admin user in the NMaaS Portal. platform.properties.k8s.ingress.certificate.issuerOrWildcardName \u2013 the name of the wilcard certificate to be used for customer deployed applications, or the name of the cert-manager issuer to use if certificates are issued ad-hoc. platform.properties.k8s.ingress.controller.ingressClass \u2013 the ingress class to be used for deployed applications. Should be set to nginx in the case of K3s and public in the case of MicroK8s. platform.properties.k8s.ingress.controller.publicIngressClass \u2013 the ingress class to be used for applications where the users have explicitly selected to enable public access (e.g. without a VPN). Since this is a local deployment, the value of this parameter should equal the value set in platform.properties.k8s.ingress.controller.ingressClass . publicServiceDomain , externalServiceDomain \u2013 for a local deployment this parameter should be set to the same value as global.nmaasDomain . janitor.properties.gitlabToken.literal \u2013 the value of the personal access token created in GitLab, previously. nmaas-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 global : acmeIssuer : false wildcardCertificateName : <EXISTING_OR_DUMMY_TLS_SECRET_NAME> ingressName : public nmaasDomain : nmaas.<INGRESS_IP>.nip.io demoDeployment : true platform : image : tag : 1.4.4-SNAPSHOT adminPassword : literal : saamn apiSecret : literal : saamn initscripts : image : tag : 1.4.4 properties : gitlab : host : nmaas-gitlab-webservice-default sso : encrpytionSecret : literal : saamn adminEmail : noreply@nmaas.local k8s : ingress : certificate : issuerOrWildcardName : <EXISTING_OR_DUMMY_TLS_SECRET_NAME> controller : ingressClass : public publicIngresClass : public publicServiceDomain : nmaas.<INGRESS_IP>.nip.io externalServiceDomain : nmaas.<INGRESS_IP>.nip.io portal : image : tag : 1.4.4-SNAPSHOT janitor : image : tag : 1.4.4 properties : gitlabToken : literal : <GITLAB_ACCESS_TOKEN> gitlabApiUrl : http://nmaas-gitlab-webservice-default:8181/api/v4 Once the values.yaml file has been customized, NMaaS can be deployed by executing: 1 2 helm repo add nmaas https://artifactory.software.geant.org/artifactory/nmaas-helm helm install -f nmaas-values.yaml --namespace nmaas-system nmaas --version 1 .1.2 nmaas/nmaas NMaaS also requires an the stakater autoreloader component, which can simply be installed using the commands below. This component takes care of restarting the affected pods whenever a configuration change is submitted via GitLab. 1 2 3 helm repo add stakater https://stakater.github.io/stakater-charts helm repo update helm install config-reload --namespace nmaas-system stakater/reloader After the installation, login as the admin user should be possible with the configured password.","title":"Part 2 - Installing NMaaS"},{"location":"self-hosted-nmaas/local-dev-environment/p2_installing-nmaas/#part-2-installing-nmaas","text":"Once a working Kubernetes cluster has been deployed, we are ready to proceed to the next step - installing NMaaS. All the necessary components will be installed in a single namespace \u2013 nmaas-system . If this namespace has not been created so far, execute: 1 kubectl create namespace nmaas-system","title":"Part 2: Installing NMaaS"},{"location":"self-hosted-nmaas/local-dev-environment/p2_installing-nmaas/#gitlab-installation","text":"The first NMaaS dependency that we will set up is GitLab, a self-hosted web based Git repository hosting service. Many applications that are deployed by NMaaS users store their configuration data in a Git repository, allowing easier editing, and version management. GitLab has an official Helm chart, and we will use it to create a basic GitLab installation locally. Some parameters must be customized in the values.yaml file before deployment: global.hosts.domain \u2013 should be set to the domain that will be allocated to GitLab. Note that the final hostname where GitLab will be reachable will have a gitlab prepended to it. If nmaas.example.local is set as the global.hosts.domain parameter, then GitLab will be available on gitlab.nmaas.example.local . global.hosts.ssh \u2013 in order for users to be able to interact with their GitLab repositories via SSH, the value of global.hosts.ssh should be set to the MetalLB IP that will be assigned to this new service (usually the next available one) for the gitlab-shell component. If the IP is not known at the time of deployment, then after the initial deployment, once the LoadBalancer service is created and the IP is allocated, a chart upgrade can be performed, where the global.hosts.ssh parameter will be set to the appropriate value. global.ingress.tls.secretName \u2013 an existing Kubernetes TLS secret where the TLS certificate to be used is stored. global.ingress.annotations.kubernetes.io/ingress.class \u2013 should be set to the ingress class used by the deployed ingress-nginx instance. In case of MicroK8s this should be set to public. In case of K3s, it should be set to nginx . optionally, if an email server is available, the global.smtp section can be edited with the appropriate parameters so that outbound email is enabled. gitlab-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 certmanager : install : false nginx-ingress : enabled : false prometheus : install : false redis : install : true postgresql : postgresqlUsername : gitlab install : true postgresqlDatabase : gitlabhq_production usePasswordFile : false existingSecret : 'gitlab-postgresql' master : extraVolumeMounts : - name : custom-init-scripts mountPath : /docker-entrypoint-preinitdb.d/init_revision.sh subPath : init_revision.sh podAnnotations : postgresql.gitlab/init-revision : \"1\" metrics : enabled : false gitlab-runner : install : false gitlab-shell : service : type : LoadBalancer global : edition : ce hosts : domain : nmaas.<INGRESS_IP>.nip.io https : true ssh : <LB_SSH_IP>.nip.io ingress : enabled : true configureCertmanager : false tls : enabled : true # secretName: <EXISTING_OR_DUMMY_TLS_SECRET_NAME> # can be left empty, self-signed certificates will be generated path : / annotations : kubernetes.io/ingress.class : \"public\" initialRootPassword : secret : gitlab-root-password key : password appConfig : defaultProjectFeatures : builds : false time_zone : Europe/Warsaw smtp : enabled : false address : smtp.mailgun.org port : 2525 user_name : \"\" ## doc/installation/secrets.md#smtp-password password : secret : \"my-smtp-secret\" key : password # domain: authentication : \"plain\" starttls_auto : false openssl_verify_mode : \"peer\" ## doc/installation/deployment.md#outgoing-email ## Email persona used in email sent by GitLab email : from : '' display_name : GitLab reply_to : '' subject_suffix : '' smime : enabled : false secretName : \"\" keyName : \"tls.key\" certName : \"tls.crt\" GitLab requires the deployment of a PostgreSQL instance. The necessary secrets containing the PostgreSQL passwords need to be created, as well as the secret containing the initial root GitLab password: 1 2 kubectl create secret generic -n <NAMESPACE> gitlab-postgresql --from-literal = postgresql-password = <POSTGRESQL_USER_PASSWORD> --from-literal = postgresql-postgres-password = <POSTGRESQL_ROOT_PASSWORD> kubectl create secret generic -n <NAMESPACE> gitlab-root-password --from-literal = password = <GITLAB_ROOT_PASSWORD> The root GitLab password will be used for login to the GitLab web interface. We are ready to add the GitLab Helm repository and install the 4.X version of GitLab: 1 2 3 helm repo add gitlab https://charts.gitlab.io helm repo update helm install -f gitlab-values.yaml --namespace nmaas-system nmaas-gitlab --version 4 .12.13 gitlab/gitlab Once GitLab has been deployed, it should be possible to navigate to the login page using a web browser. After logging in, users are advised to configure the following settings: disable new user registrations ( Admin Area -> Settings -> General -> Sign-up restrictions ) Sign-up enabled should be unchecked Require admin approval for new sign-ups should be unchecked enable webhooks to local addresses ( Admin Area -> Settings -> Network -> Outbound requests ) Allow requests to the local network from web hooks and services = checked Allow requests to the local network from system hooks = checked The final step before installing NMaaS itself is to generate a GitLab personal access token which will allow NMaaS to connect to the GitLab API. This can be done from the User Profile page: 1 2 - Click on the user avatar in the right-hand corner of the screen, Edit Profile. Select Access Tokens from the left-hand navigation menu. Give a new name for the authentication token, as well as an optional expiry date. Check all scopes. - Store the token until the next section, where we will create a new secret containing it.","title":"GitLab Installation"},{"location":"self-hosted-nmaas/local-dev-environment/p2_installing-nmaas/#nmaas-installation","text":"The final step is to install NMaaS. NMaaS uses SSH communication to connect between components, so we need to create an SSH key pair and store it in a Kubernetes secret. This can be done by executing the following commands: 1 2 3 4 5 6 7 8 9 #!/bin/bash tmpdir = $( mktemp -d ) ssh-keygen -f $tmpdir /key -N \"\" # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPrivate }} kubectl create secret generic nmaas-helm-key-private -n <NMAAS_NAMESPACE> --from-file = id_rsa = $tmpdir /key # nmaas-helm-key-private should be replaced with {{ .Values.global.helmAccessKeyPublic }} kubectl create secret generic nmaas-helm-key-public -n <NMAAS_NAMESPACE> --from-file = helm = $tmpdir /key.pub A few parameters need to be customized in the values.yaml file, to reflect the environment where NMaaS is deployed. global.wildcardCertificateName \u2013 the name of the secret containing the TLS certificate to be used to secure the HTTP communication global.nmaasDomain \u2013 the hostname where NMaaS will be accessible. platform.properties.adminEmail \u2013 the email address which will receive various notifications such as new user sign-up, deployment errors, new application versions... platform.adminPassword.literal \u2013 the password used to login as the admin user in the NMaaS Portal. platform.properties.k8s.ingress.certificate.issuerOrWildcardName \u2013 the name of the wilcard certificate to be used for customer deployed applications, or the name of the cert-manager issuer to use if certificates are issued ad-hoc. platform.properties.k8s.ingress.controller.ingressClass \u2013 the ingress class to be used for deployed applications. Should be set to nginx in the case of K3s and public in the case of MicroK8s. platform.properties.k8s.ingress.controller.publicIngressClass \u2013 the ingress class to be used for applications where the users have explicitly selected to enable public access (e.g. without a VPN). Since this is a local deployment, the value of this parameter should equal the value set in platform.properties.k8s.ingress.controller.ingressClass . publicServiceDomain , externalServiceDomain \u2013 for a local deployment this parameter should be set to the same value as global.nmaasDomain . janitor.properties.gitlabToken.literal \u2013 the value of the personal access token created in GitLab, previously. nmaas-values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 global : acmeIssuer : false wildcardCertificateName : <EXISTING_OR_DUMMY_TLS_SECRET_NAME> ingressName : public nmaasDomain : nmaas.<INGRESS_IP>.nip.io demoDeployment : true platform : image : tag : 1.4.4-SNAPSHOT adminPassword : literal : saamn apiSecret : literal : saamn initscripts : image : tag : 1.4.4 properties : gitlab : host : nmaas-gitlab-webservice-default sso : encrpytionSecret : literal : saamn adminEmail : noreply@nmaas.local k8s : ingress : certificate : issuerOrWildcardName : <EXISTING_OR_DUMMY_TLS_SECRET_NAME> controller : ingressClass : public publicIngresClass : public publicServiceDomain : nmaas.<INGRESS_IP>.nip.io externalServiceDomain : nmaas.<INGRESS_IP>.nip.io portal : image : tag : 1.4.4-SNAPSHOT janitor : image : tag : 1.4.4 properties : gitlabToken : literal : <GITLAB_ACCESS_TOKEN> gitlabApiUrl : http://nmaas-gitlab-webservice-default:8181/api/v4 Once the values.yaml file has been customized, NMaaS can be deployed by executing: 1 2 helm repo add nmaas https://artifactory.software.geant.org/artifactory/nmaas-helm helm install -f nmaas-values.yaml --namespace nmaas-system nmaas --version 1 .1.2 nmaas/nmaas NMaaS also requires an the stakater autoreloader component, which can simply be installed using the commands below. This component takes care of restarting the affected pods whenever a configuration change is submitted via GitLab. 1 2 3 helm repo add stakater https://stakater.github.io/stakater-charts helm repo update helm install config-reload --namespace nmaas-system stakater/reloader After the installation, login as the admin user should be possible with the configured password.","title":"NMaaS Installation"},{"location":"self-hosted-nmaas/local-dev-environment/p3_demo-network-environment/","text":"Part 3: Setting Up a Demo Network Environment Acknowledgement These instructions are heavily based on the excellent blog posts and FreeRTR Docs written by Fr\u00e9deric Loui and the RARE team. If there are existing network elements ready to be monitored by NMaaS applications, then this part can be completely skipped. Configuring VirtualBox This tutorial will assume that VirtualBox is used, even though the discussion should be applicable to other virtualization software as well, with minor modifications. The virtual machine where FreeRTR will be installed requires at least two network interfaces, one primary and one additional for each FreeRTR process. The addition of new interfaces can be easily accomplished from the VirtualBox VM settings screen, using the Network section. Each new interface is represented by a new tab, named Adapter 1 , Adapter 2 ... For the new interface, choose Attached to: NAT and make sure to select the NAT network created in Part 1 and that Promiscuous Mode is set to Allow All in the Advanced section. If Promiscuous Mode is not enabled, unfortunately pcapInt will not be able to work properly. Installing FreeRTR To run a local installation of FreeRTR we must first install a Java distribution. Fortunately, this can be accomplished with a single command: 1 2 apt update apt install default-jre-headless ethtool FreeRTR requires at least Java 8 and works with newer versions as well. We are now ready to download FreeRTR: 1 2 3 mkdir /opt/rtr cd /opt/rtr wget http://www.freertr.net/rtr.jar To make our virtual router accessible from the local network we must install the FreeRTR net-tools as well. They come precompiled for convenience. Please refer to RARE/FreeRouter-101 [ #002 ] - \"Let me get out !\" for instructions on building these from source. 1 2 3 wget freerouter.nop.hu/rtr- $( uname -m ) .tar mkdir /opt/rtr/bin tar -xvf rtr- $( uname -m ) .tar -C /opt/rtr/bin As discussed in http://docs.freertr.net/guides/getting-started/001-hello-world/ , to enable basic functionality we need to create two TXT files: a hardware specification file and a software specification file. r1-hw.txt 1 2 int eth1 eth 0000.1111.0001 127.0.0.1 1001 127.0.0.1 2001 tcp2vrf 1123 v1 23 The hardware specification file given above is used to declare the interfaces that we would like our router to have. The syntax is: int <int_name> <int_type> <int_mac_addr> <ip_addr_socket_src> <ip_addr_udp_port_src> <ip_addr_socket_dest> <ip_addr_udp_port_dest> . Note that by using the second line in the hardware specification file we have enabled remote reachability of port 23 (Telnet) by forwarding any TCP connection established towards VM_IP:1123 toward VRF_V1:23 . More information about VRFs will be given in the next steps. This allows easy remote configuration of our router even before we have bound it to a specific network interface of our VM. r1-sw.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 hostname r1 buggy ! vrf def v1 rd 1:1 exit ! prefix-list p4 sequence 10 permit 0.0.0.0/0 ge 0 le 0 exit ! server telnet tel security protocol tel vrf v1 exit ! ipv4 route v1 0.0.0.0 0.0.0.0 192.168.1.1 ! int eth1 desc r1@eth1 -> enp0s8 lldp ena vrf for v1 ipv4 addr 192.168.1.17 255.255.255.0 ipv4 gateway-prefix p4 no shutdown exit ! ! ! sensor ifaces-hw path interfaces-hw/interface/counter prefix freertr-ifaces prepend iface_hw_byte_ command sho inter hwsumm name 0 ifc= key name interfaces-hw/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-hwp path interfaces-hwp/interface/counter prefix freertr-ifaces prepend iface_hw_pack_ command sho inter hwpsumm name 0 ifc= key name interfaces-hwp/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-sw path interfaces-sw/interface/counter prefix freertr-ifaces prepend iface_sw_byte_ command sho inter swsumm name 0 ifc= key name interfaces-sw/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-swp path interfaces-swp/interface/counter prefix freertr-ifaces prepend iface_sw_pack_ command sho inter swpsumm name 0 ifc= key name interfaces-swp/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! server prometheus r1 sensor ifaces-hw sensor ifaces-hwp sensor ifaces-sw sensor ifaces-swp vrf v1 exit Even though the software specification file is large, the most important parts that need to be adapted to the local environment are: Adding a default route: ipv4 route v1 0.0.0.0 0.0.0.0 192.168.1.1 Configuring a static IP: ipv4 addr 192.168.1.17 255.255.255.0 The sensor directives need to be left as they are, since they configure the Prometheus Exporter which will be scrapped using an NMaaS hosted Prometheus instance which we will deploy in the next part. As a last step before starting the FreeRTR process, we need to bring up our second interface and disable hardware offloading: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 INT_NAME = enp0s8 ip link set $INT_NAME up promisc on /sbin/ethtool -K $INT_NAME rx off /sbin/ethtool -K $INT_NAME tx off /sbin/ethtool -K $INT_NAME sg off /sbin/ethtool -K $INT_NAME tso off /sbin/ethtool -K $INT_NAME ufo off /sbin/ethtool -K $INT_NAME gso off /sbin/ethtool -K $INT_NAME gro off /sbin/ethtool -K $INT_NAME lro off /sbin/ethtool -K $INT_NAME rxvlan off /sbin/ethtool -K $INT_NAME txvlan off /sbin/ethtool -K $INT_NAME ntuple off /sbin/ethtool -K $INT_NAME rxhash off As before, please make sure that the correct interface name is used. Once the necessary changes are made to the hardware and software specification files, we are ready to start our first router: 1 java -jar rtr.jar routersc r1-hw.txt r1-sw.txt This will open an interactive session from where we can further alter the running configuration of the router. Of course, access to the local network is still not possible. To enable two-way communication with the \"outside\" world, we need to bind the UDP socket to the network interface that we have configured in the previous section using the pcapInit.bin tool: 1 ./pcapInt.bin enp0s8 2001 127 .0.0.1 1001 127 .0.0.1 Please note that in the above command enp0s8 needs to be replaced with the name of the additional network interface connected to the virtual machine. If reusing the hardware file posted above, the port numbers can remain unchanged. Once started, you can try pinging your default gateway from FreeRTR itself: 1 ping <GATEWAY_IP> /vrf v1 It should work without any issues. The same steps can be repeated for another instance of the virtual router, this time choosing different socket ports in step 4, and adjusting the IP address in the software configuration file. Creating a SystemD Service If automatic startup of the virtual devices is desired, a SystemD service unit can be created. Create a new file called freertr@.service in /etc/systemd/system . freertr@.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = Start a freeRTR instance for %I After = network.target [Service] EnvironmentFile = /etc/default/freertr@%i ExecStartPre = /opt/rtr/interface-config.sh ${INT_NAME} ExecStart = java -jar /opt/rtr/rtr.jar routers ${HW_PATH} ${SW_PATH} User = root # Restart every >2 seconds to avoid StartLimitInterval failure RestartSec = 5 Restart = always [Install] WantedBy = multi-user.target To enable automatic startup of the pcapInt tool as well, the following service unit needs to be created for each router instance, adjusting the After= parameter and the EnvironmentFile accordingly: pcap-freertr-r1.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [Unit] Description = Start a PCAP freeRTR instance for %I After = freertr@r1.service [Service] EnvironmentFile = /etc/default/pcap-freertr-r1 ExecStart = /opt/rtr/bin/pcapInt.bin ${INT_NAME} ${PORT1} 127.0.0.1 ${PORT2} 127.0.0.1 User = root # Restart every >2 seconds to avoid StartLimitInterval failure RestartSec = 5 Restart = always StandardInput = tty TTYPath = /dev/tty2 TTYReset = yes TTYVHangup = yes [Install] WantedBy = multi-user.target Please note that if multiple instances of pcapInit need to be started (e.g. for different virtual routers), then the TTYPath parameter will need to be incremented accordingly. The necessary environment variables that are referenced in these unit files can be created in /etc/default . An example is given below: /etc/default/freertr@r1 1 2 3 4 5 INT_NAME = enp0s8 HW_PATH = /opt/rtr/r1-hw.txt SW_PATH = /opt/rtr/r1-sw.txt PORT1 = 2001 PORT2 = 1001 /etc/default/pcap-freertr-r1 1 2 3 INT_NAME = enp0s8 PORT1 = 2001 PORT2 = 1001 Finally the newly created services can be enabled and started: 1 2 systemctl enable --now freertr@r1 systemctl enable --now pcap-freertr-r1 We are now ready to configure monitoring and configuration backup of our virtual router using tools from the NMaaS catalog.","title":"Part 3 - Demo Network Environment"},{"location":"self-hosted-nmaas/local-dev-environment/p3_demo-network-environment/#part-3-setting-up-a-demo-network-environment","text":"Acknowledgement These instructions are heavily based on the excellent blog posts and FreeRTR Docs written by Fr\u00e9deric Loui and the RARE team. If there are existing network elements ready to be monitored by NMaaS applications, then this part can be completely skipped.","title":"Part 3: Setting Up a Demo Network Environment"},{"location":"self-hosted-nmaas/local-dev-environment/p3_demo-network-environment/#configuring-virtualbox","text":"This tutorial will assume that VirtualBox is used, even though the discussion should be applicable to other virtualization software as well, with minor modifications. The virtual machine where FreeRTR will be installed requires at least two network interfaces, one primary and one additional for each FreeRTR process. The addition of new interfaces can be easily accomplished from the VirtualBox VM settings screen, using the Network section. Each new interface is represented by a new tab, named Adapter 1 , Adapter 2 ... For the new interface, choose Attached to: NAT and make sure to select the NAT network created in Part 1 and that Promiscuous Mode is set to Allow All in the Advanced section. If Promiscuous Mode is not enabled, unfortunately pcapInt will not be able to work properly.","title":"Configuring VirtualBox"},{"location":"self-hosted-nmaas/local-dev-environment/p3_demo-network-environment/#installing-freertr","text":"To run a local installation of FreeRTR we must first install a Java distribution. Fortunately, this can be accomplished with a single command: 1 2 apt update apt install default-jre-headless ethtool FreeRTR requires at least Java 8 and works with newer versions as well. We are now ready to download FreeRTR: 1 2 3 mkdir /opt/rtr cd /opt/rtr wget http://www.freertr.net/rtr.jar To make our virtual router accessible from the local network we must install the FreeRTR net-tools as well. They come precompiled for convenience. Please refer to RARE/FreeRouter-101 [ #002 ] - \"Let me get out !\" for instructions on building these from source. 1 2 3 wget freerouter.nop.hu/rtr- $( uname -m ) .tar mkdir /opt/rtr/bin tar -xvf rtr- $( uname -m ) .tar -C /opt/rtr/bin As discussed in http://docs.freertr.net/guides/getting-started/001-hello-world/ , to enable basic functionality we need to create two TXT files: a hardware specification file and a software specification file. r1-hw.txt 1 2 int eth1 eth 0000.1111.0001 127.0.0.1 1001 127.0.0.1 2001 tcp2vrf 1123 v1 23 The hardware specification file given above is used to declare the interfaces that we would like our router to have. The syntax is: int <int_name> <int_type> <int_mac_addr> <ip_addr_socket_src> <ip_addr_udp_port_src> <ip_addr_socket_dest> <ip_addr_udp_port_dest> . Note that by using the second line in the hardware specification file we have enabled remote reachability of port 23 (Telnet) by forwarding any TCP connection established towards VM_IP:1123 toward VRF_V1:23 . More information about VRFs will be given in the next steps. This allows easy remote configuration of our router even before we have bound it to a specific network interface of our VM. r1-sw.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 hostname r1 buggy ! vrf def v1 rd 1:1 exit ! prefix-list p4 sequence 10 permit 0.0.0.0/0 ge 0 le 0 exit ! server telnet tel security protocol tel vrf v1 exit ! ipv4 route v1 0.0.0.0 0.0.0.0 192.168.1.1 ! int eth1 desc r1@eth1 -> enp0s8 lldp ena vrf for v1 ipv4 addr 192.168.1.17 255.255.255.0 ipv4 gateway-prefix p4 no shutdown exit ! ! ! sensor ifaces-hw path interfaces-hw/interface/counter prefix freertr-ifaces prepend iface_hw_byte_ command sho inter hwsumm name 0 ifc= key name interfaces-hw/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-hwp path interfaces-hwp/interface/counter prefix freertr-ifaces prepend iface_hw_pack_ command sho inter hwpsumm name 0 ifc= key name interfaces-hwp/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-sw path interfaces-sw/interface/counter prefix freertr-ifaces prepend iface_sw_byte_ command sho inter swsumm name 0 ifc= key name interfaces-sw/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! sensor ifaces-swp path interfaces-swp/interface/counter prefix freertr-ifaces prepend iface_sw_pack_ command sho inter swpsumm name 0 ifc= key name interfaces-swp/interface replace \\. _ column 1 name st column 1 replace admin -1 column 1 replace down 0 column 1 replace up 1 column 2 name tx column 3 name rx column 4 name dr exit ! server prometheus r1 sensor ifaces-hw sensor ifaces-hwp sensor ifaces-sw sensor ifaces-swp vrf v1 exit Even though the software specification file is large, the most important parts that need to be adapted to the local environment are: Adding a default route: ipv4 route v1 0.0.0.0 0.0.0.0 192.168.1.1 Configuring a static IP: ipv4 addr 192.168.1.17 255.255.255.0 The sensor directives need to be left as they are, since they configure the Prometheus Exporter which will be scrapped using an NMaaS hosted Prometheus instance which we will deploy in the next part. As a last step before starting the FreeRTR process, we need to bring up our second interface and disable hardware offloading: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 INT_NAME = enp0s8 ip link set $INT_NAME up promisc on /sbin/ethtool -K $INT_NAME rx off /sbin/ethtool -K $INT_NAME tx off /sbin/ethtool -K $INT_NAME sg off /sbin/ethtool -K $INT_NAME tso off /sbin/ethtool -K $INT_NAME ufo off /sbin/ethtool -K $INT_NAME gso off /sbin/ethtool -K $INT_NAME gro off /sbin/ethtool -K $INT_NAME lro off /sbin/ethtool -K $INT_NAME rxvlan off /sbin/ethtool -K $INT_NAME txvlan off /sbin/ethtool -K $INT_NAME ntuple off /sbin/ethtool -K $INT_NAME rxhash off As before, please make sure that the correct interface name is used. Once the necessary changes are made to the hardware and software specification files, we are ready to start our first router: 1 java -jar rtr.jar routersc r1-hw.txt r1-sw.txt This will open an interactive session from where we can further alter the running configuration of the router. Of course, access to the local network is still not possible. To enable two-way communication with the \"outside\" world, we need to bind the UDP socket to the network interface that we have configured in the previous section using the pcapInit.bin tool: 1 ./pcapInt.bin enp0s8 2001 127 .0.0.1 1001 127 .0.0.1 Please note that in the above command enp0s8 needs to be replaced with the name of the additional network interface connected to the virtual machine. If reusing the hardware file posted above, the port numbers can remain unchanged. Once started, you can try pinging your default gateway from FreeRTR itself: 1 ping <GATEWAY_IP> /vrf v1 It should work without any issues. The same steps can be repeated for another instance of the virtual router, this time choosing different socket ports in step 4, and adjusting the IP address in the software configuration file.","title":"Installing FreeRTR"},{"location":"self-hosted-nmaas/local-dev-environment/p3_demo-network-environment/#creating-a-systemd-service","text":"If automatic startup of the virtual devices is desired, a SystemD service unit can be created. Create a new file called freertr@.service in /etc/systemd/system . freertr@.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = Start a freeRTR instance for %I After = network.target [Service] EnvironmentFile = /etc/default/freertr@%i ExecStartPre = /opt/rtr/interface-config.sh ${INT_NAME} ExecStart = java -jar /opt/rtr/rtr.jar routers ${HW_PATH} ${SW_PATH} User = root # Restart every >2 seconds to avoid StartLimitInterval failure RestartSec = 5 Restart = always [Install] WantedBy = multi-user.target To enable automatic startup of the pcapInt tool as well, the following service unit needs to be created for each router instance, adjusting the After= parameter and the EnvironmentFile accordingly: pcap-freertr-r1.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [Unit] Description = Start a PCAP freeRTR instance for %I After = freertr@r1.service [Service] EnvironmentFile = /etc/default/pcap-freertr-r1 ExecStart = /opt/rtr/bin/pcapInt.bin ${INT_NAME} ${PORT1} 127.0.0.1 ${PORT2} 127.0.0.1 User = root # Restart every >2 seconds to avoid StartLimitInterval failure RestartSec = 5 Restart = always StandardInput = tty TTYPath = /dev/tty2 TTYReset = yes TTYVHangup = yes [Install] WantedBy = multi-user.target Please note that if multiple instances of pcapInit need to be started (e.g. for different virtual routers), then the TTYPath parameter will need to be incremented accordingly. The necessary environment variables that are referenced in these unit files can be created in /etc/default . An example is given below: /etc/default/freertr@r1 1 2 3 4 5 INT_NAME = enp0s8 HW_PATH = /opt/rtr/r1-hw.txt SW_PATH = /opt/rtr/r1-sw.txt PORT1 = 2001 PORT2 = 1001 /etc/default/pcap-freertr-r1 1 2 3 INT_NAME = enp0s8 PORT1 = 2001 PORT2 = 1001 Finally the newly created services can be enabled and started: 1 2 systemctl enable --now freertr@r1 systemctl enable --now pcap-freertr-r1 We are now ready to configure monitoring and configuration backup of our virtual router using tools from the NMaaS catalog.","title":"Creating a SystemD Service"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/","text":"Part 4: Monitoring the Demo Network Environment with NMaaS Registering a new Local NMaaS User Registering a new local NMaaS user can be done from the NMaaS homepage. Once all of the required fields (denoted by a red *) are filled, and the privacy policy accepted, the registration form can be submitted. After submission, an administrator approval is required before being able to login. Approving the New User (as Admin) and Creating a New Domain To approve a newly registered user, login as the NMaaS admin, and navigate to Settings -> Users from the right-hand side navigation menu. Hover over the cog next to the new user and select Enable . Once enabled, the user should be made part of an existing domain. Since we currently have not configured any domains, a new one needs to be created. Navigate to Settings -> Domains from the right-hand side navigation menu. Click the blue Add domain button Enter a descriptive name for the domain, as well as a short codename. Please keep the codename as short as possible, since it will be embedded in all customer deployed Kubernetes resources. Choose which Kubernetes namespace will be dedicated to hosting the customer deployed applications. A new namespace can be created by executing: 1 kubectl create namespace <DOMAIN_CODENAME> For a local deployment, leave the Kubernetes storage class field empty, and set Kubernetes Ingress class to the ingress class available in the cluster (public for MicroK8s, nginx for K3s) As External service domain set the domain codename, suffixed by the NMaaS URL. For example, if the domain codename is demo, then External service domain should be set to demo.nmaas.<INGRESS_LB_IP>.nip.io . Set the DCN deployment type to Manual and tick DCN Configured . Set a dummy customer network, for example 127.0.0.1/24 . Once created, any existing user can be made part of the domain. Return to Settings -> Users and choose the Details option after hovering over the cog for the new user. In the Privileges section, assign the role Domain admin to the newly created user. Adding a Personal SSH Public Key After the user has been approved, if email sending has been successfully configured, the user should receive a confirmation message. During the first login, the user will be asked to enter an SSH public key which will be used for access to the GitLab repositories hosting the deployed applications' configuration files. An SSH key can also be specified at any later point in time from the Profile -> SSH keys section. Please add an SSH public key before proceeding to the next section, Application Deployment. Application Deployment The application deployment process is consisted of two parts: Subscribing to the desired application from the list of all applications. Deploying an instance of the application from the Subscriptions page. Deploying Prometheus Prometheus is a monitoring application which uses the pull methodology to fetch metrics from a given device. To deploy Prometheus, first subscribe to it from the Applications section. Then choose the Deploy option. On the first pop-up, an option is presented to enter a unique instance name, as well as select the desired application version. The deployment process consists of 6 different steps, but only step 4, Application deployed, requires user interaction. Once step 4 has been reached, a blue Configure button will appear. Clicking on this blue Configure button will present a configuration wizard, where additional parameters can be set. The configuration wizard is specific to the application being deployed. In the case of Prometheus, there is an option to configure the HTTP Basic authentication username and password, as well as the scrape interval. The IP addresses of the devices that need to be monitored can be specified in the Jobs array. Note that the demo networking devices deployed in the previous step can also be monitored. They have a Prometheus exporter running on port 9001, reachable without any authentication. Additional devices can be added after the application has been deployed by using the Git repository which will host the configuration. After the application is successfully deployed, it will transition to an Active state, and a blue Actions button will become available. By selecting the Access option in this dropdown menu, the user will be immediately redirected to the Prometheus home page. Deploying Grafana By now we have configured Prometheus to monitor the devices in our environment, but we still do not have a way to visualize the gathered metrics. Grafana is an open-source application that can generate graphs from different data sources, including Prometheus. To deploy Grafana in an NMaaS environment, the same general steps can be used as before: subscribing to the Grafana application from the Applications page creating a new instance from the Subscriptions page The configuration wizard that becomes available once the deployment enters the Deployed phase is different in the case of Grafana. Apart from specifying the Grafana username and password that can be used for accessing the web interface, users have the option of directly choosing an existing Prometheus instance that has been deployed within their NMaaS domain, and adding it as a data source to Grafana. This can be accomplished by ticking the Connect to existing Prometheus instance checkbox, and selecting the NMaaS Prometheus Instance radio button. Of course, a Grafana instance hosted on NMaaS can be used for connecting to external data sources as well. In this case, the checkbox Connect to existing Prometheus instance can simply be left unchecked. Once the application is deployed, it can be accessed by selecting the Actions -> Access button. After login, users can verify that the previously deployed Prometheus instance has been added as a Data Source by selecting the cog icon on the left hand side and choosing Data Sources . At this point, new dashboards can either be created from scratch, or imported from the Grafana dashboard gallery. For example, if the freeRTR virtual instances are deployed, the following two dashboards can be imported to visualize the packet and input/output rates of the devices: https://grafana.com/grafana/dashboards/13152 https://grafana.com/grafana/dashboards/13153 An existing dashboard can be imported into Grafana by simply choosing the Plus button on the left-hand side and selecting Import. Either a JSON document describing the parameters of the dashboard can be pasted or just the dashboard ID, as shown on the official Grafana page. In our case, the IDs for the two previously mentioned dashboards are 13152 and 13153 , respectively. This information is also directly visible in their URL. After importing the dashboard, a redirect is immediately issued, and the defined graphs are shown. Deploying Oxidized Oxidized is an open-source application that is capable of fetching the configuration of remote devices and if enabled, version it using an internal or external Git repository. In our demo scenario, we will use Oxidized to periodically fetch the configuration from the available network elements. To do so, we must first deploy Oxidized in our NMaaS domain. The deployment steps for Oxidized are very similar to the other applications that have been deployed so far: Subscribe to the Oxidized application from the Applications page. Deploy an Oxidized instance from the Subscriptions page. Once the Deploy button is clicked, a pop-up similar as before appears, where an instance name should be provided, and the desired Oxidized version selected. Since Oxidized can connect to devices using a remote access protocol such as Telnet or SSH, the configuration wizard asks for IP information. Additionally, HTTP Basic authentication can also be configured to better secure the Oxidized web interface, using the Oxidized access username and Oxidized access password fields. Once deployed, the web interface becomes immediately accessible, simply by choosing the blue Actions button and selecting Access . Additional Oxidized configuration, such as altering the list of monitored devices or even adding custom Oxidized models can be done using Git. During the deployment process, a new GitLab repository has been automatically created which hosts the Oxidized configuration data. To access it, select Actions -> Configure and copy the git clone command. After cloning this repository, two folders should appear: base and model . The base folder houses basic configuration about the monitored devices: router.db \u2013 hostnames, IP addresses, and groups for the devices config \u2013 storage backend, backup storage location, credentials... The model folder houses specific device models, which describe how Oxidized should connect to the monitored devices and what commands to execute in order to acquire the running configuration. The RARE team has created a custom Oxidized model which allows configuration fetching from FreeRTR devices. If you have configured freeRTR as part of this tutorial, then this model is required for successful connections towards the freeRTR instances. Monitoring freeRTR Devices with Oxidized After cloning the repository, navigate to the model folder and create the file rare.rb wth the following content: rare.rb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class RARE < Oxidized :: Model prompt /([\\w.@()-]+#\\s?)$/ comment '! ' cmd :all do | cfg | cfg . gsub! /^% Invalid input detected at '\\^' marker\\.$|^\\s+\\^$/ , '' cfg . cut_both end cmd :secret do | cfg | cfg end cmd 'show clock' do | cfg | comment \"---------- show clock\" comment cfg end cmd 'show platform' do | cfg | comment \"---------- show platform\" comments = [] comments << cfg . lines . first lines = cfg . lines lines . each_with_index do | line , i | if line !~ /^mem:|^uptime:/ comments << line . strip! end end comments << \" \\n \" comment comments . join \" \\n \" end cmd 'show interfaces description' do | cfg | comment \"---------- show interface description\" comment cfg end cmd 'show startup-config' do | cfg | comment \"---------- show startup-config\" cfg = cfg . each_line . to_a [ 0 ..- 1 ] cfg = cfg . reject { | line | line . match /^ntp clock-period / } . join cfg . gsub! /^Current configuration : [^\\n]*\\n/ , '' cfg . gsub! /^ tunnel mpls traffic-eng bandwidth[^\\n]*\\n*( (?: [^\\n]*\\n*)* tunnel mpls traffic-eng auto-bw)/mx , ' \\1 ' cfg end cfg :telnet do username /^Username:/i password /^Password:/i end cfg :telnet , :ssh do # preferred way to handle additional passwords post_login do if vars ( :enable ) == true cmd \"enable\" elsif vars ( :enable ) cmd \"enable\" , /^[pP]assword:/ cmd vars ( :enable ) end end post_login 'terminal length 0' post_login 'terminal width 0' pre_logout 'exit' end end After adding the model, it must also be referenced in the base/config file, where the format of the router.db file can be altered as well. config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 --- username : root password : root model : rare interval : 43200 use_syslog : false debug : false threads : 30 timeout : 20 retries : 3 prompt : !ruby/regexp /^([\\w.@-]+[#>]\\s?)$/ rest : 0.0.0.0:8888 vars : {} groups : {} pid : \"/storage/pid\" input : default : ssh, telnet debug : false ssh : secure : false output : default : git file : directory : \"/storage/configs\" git : user : oxidized email : oxidized@man.poznan.pl repo : \"/storage/oxidized.git\" source : default : csv csv : file : \"/root/.config/oxidized/router.db\" delimiter : !ruby/regexp /:/ map : name : 0 ip : 1 model : 2 model_map : rare : rare cisco : ios juniper : junos Note that we have altered the keys: model, source.csv.map and model_map. By altering the source.csv.map object we can set the format of the CSV file that contains the device information. In this case, we will format our CSV file using three columns: name ; ip ; model . Finally, alter the base/router.db file to reflect the changes made to the CSV format: router.db 1 2 r1:10.99.99.50:rare r2:10.99.99.51:rare The second column, the IP addresses, should be replaced with the IP addresses of your virtual freeRTR devices. The final step is to simply commit the changes that have been made. If this is the first time that Git is used, then the global Git user.name and email should be set: 1 2 git config --global user.name \"NMaaS Demo\" git config --global user.email \"nmaas_demo@example.com\" Any value can be used for these parameters, they are not related to NMaaS. The changes can be committed and pushed to the remote repository using: 1 2 3 git add . git commit -m \"freeRTR config change\" git push After the push is made, the Oxidized container will be rebooted to apply the changes. To verify the configuration changes that were made, the Oxidized web interface can be visited. It should show green boxes under Last Status for all devices. This means that the last attempt to fetch the configuration data has been successful. A complete version history can be obtained by using the versions option from the Actions column. On the Versions page there is an option to download a given configuration archive or create a diff.","title":"Part 4 - Monitoring the Demo Network Environment"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#part-4-monitoring-the-demo-network-environment-with-nmaas","text":"","title":"Part 4: Monitoring the Demo Network Environment with NMaaS"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#registering-a-new-local-nmaas-user","text":"Registering a new local NMaaS user can be done from the NMaaS homepage. Once all of the required fields (denoted by a red *) are filled, and the privacy policy accepted, the registration form can be submitted. After submission, an administrator approval is required before being able to login.","title":"Registering a new Local NMaaS User"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#approving-the-new-user-as-admin-and-creating-a-new-domain","text":"To approve a newly registered user, login as the NMaaS admin, and navigate to Settings -> Users from the right-hand side navigation menu. Hover over the cog next to the new user and select Enable . Once enabled, the user should be made part of an existing domain. Since we currently have not configured any domains, a new one needs to be created. Navigate to Settings -> Domains from the right-hand side navigation menu. Click the blue Add domain button Enter a descriptive name for the domain, as well as a short codename. Please keep the codename as short as possible, since it will be embedded in all customer deployed Kubernetes resources. Choose which Kubernetes namespace will be dedicated to hosting the customer deployed applications. A new namespace can be created by executing: 1 kubectl create namespace <DOMAIN_CODENAME> For a local deployment, leave the Kubernetes storage class field empty, and set Kubernetes Ingress class to the ingress class available in the cluster (public for MicroK8s, nginx for K3s) As External service domain set the domain codename, suffixed by the NMaaS URL. For example, if the domain codename is demo, then External service domain should be set to demo.nmaas.<INGRESS_LB_IP>.nip.io . Set the DCN deployment type to Manual and tick DCN Configured . Set a dummy customer network, for example 127.0.0.1/24 . Once created, any existing user can be made part of the domain. Return to Settings -> Users and choose the Details option after hovering over the cog for the new user. In the Privileges section, assign the role Domain admin to the newly created user.","title":"Approving the New User (as Admin) and Creating a New Domain"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#adding-a-personal-ssh-public-key","text":"After the user has been approved, if email sending has been successfully configured, the user should receive a confirmation message. During the first login, the user will be asked to enter an SSH public key which will be used for access to the GitLab repositories hosting the deployed applications' configuration files. An SSH key can also be specified at any later point in time from the Profile -> SSH keys section. Please add an SSH public key before proceeding to the next section, Application Deployment.","title":"Adding a Personal SSH Public Key"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#application-deployment","text":"The application deployment process is consisted of two parts: Subscribing to the desired application from the list of all applications. Deploying an instance of the application from the Subscriptions page.","title":"Application Deployment"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#deploying-prometheus","text":"Prometheus is a monitoring application which uses the pull methodology to fetch metrics from a given device. To deploy Prometheus, first subscribe to it from the Applications section. Then choose the Deploy option. On the first pop-up, an option is presented to enter a unique instance name, as well as select the desired application version. The deployment process consists of 6 different steps, but only step 4, Application deployed, requires user interaction. Once step 4 has been reached, a blue Configure button will appear. Clicking on this blue Configure button will present a configuration wizard, where additional parameters can be set. The configuration wizard is specific to the application being deployed. In the case of Prometheus, there is an option to configure the HTTP Basic authentication username and password, as well as the scrape interval. The IP addresses of the devices that need to be monitored can be specified in the Jobs array. Note that the demo networking devices deployed in the previous step can also be monitored. They have a Prometheus exporter running on port 9001, reachable without any authentication. Additional devices can be added after the application has been deployed by using the Git repository which will host the configuration. After the application is successfully deployed, it will transition to an Active state, and a blue Actions button will become available. By selecting the Access option in this dropdown menu, the user will be immediately redirected to the Prometheus home page.","title":"Deploying Prometheus"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#deploying-grafana","text":"By now we have configured Prometheus to monitor the devices in our environment, but we still do not have a way to visualize the gathered metrics. Grafana is an open-source application that can generate graphs from different data sources, including Prometheus. To deploy Grafana in an NMaaS environment, the same general steps can be used as before: subscribing to the Grafana application from the Applications page creating a new instance from the Subscriptions page The configuration wizard that becomes available once the deployment enters the Deployed phase is different in the case of Grafana. Apart from specifying the Grafana username and password that can be used for accessing the web interface, users have the option of directly choosing an existing Prometheus instance that has been deployed within their NMaaS domain, and adding it as a data source to Grafana. This can be accomplished by ticking the Connect to existing Prometheus instance checkbox, and selecting the NMaaS Prometheus Instance radio button. Of course, a Grafana instance hosted on NMaaS can be used for connecting to external data sources as well. In this case, the checkbox Connect to existing Prometheus instance can simply be left unchecked. Once the application is deployed, it can be accessed by selecting the Actions -> Access button. After login, users can verify that the previously deployed Prometheus instance has been added as a Data Source by selecting the cog icon on the left hand side and choosing Data Sources . At this point, new dashboards can either be created from scratch, or imported from the Grafana dashboard gallery. For example, if the freeRTR virtual instances are deployed, the following two dashboards can be imported to visualize the packet and input/output rates of the devices: https://grafana.com/grafana/dashboards/13152 https://grafana.com/grafana/dashboards/13153 An existing dashboard can be imported into Grafana by simply choosing the Plus button on the left-hand side and selecting Import. Either a JSON document describing the parameters of the dashboard can be pasted or just the dashboard ID, as shown on the official Grafana page. In our case, the IDs for the two previously mentioned dashboards are 13152 and 13153 , respectively. This information is also directly visible in their URL. After importing the dashboard, a redirect is immediately issued, and the defined graphs are shown.","title":"Deploying Grafana"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#deploying-oxidized","text":"Oxidized is an open-source application that is capable of fetching the configuration of remote devices and if enabled, version it using an internal or external Git repository. In our demo scenario, we will use Oxidized to periodically fetch the configuration from the available network elements. To do so, we must first deploy Oxidized in our NMaaS domain. The deployment steps for Oxidized are very similar to the other applications that have been deployed so far: Subscribe to the Oxidized application from the Applications page. Deploy an Oxidized instance from the Subscriptions page. Once the Deploy button is clicked, a pop-up similar as before appears, where an instance name should be provided, and the desired Oxidized version selected. Since Oxidized can connect to devices using a remote access protocol such as Telnet or SSH, the configuration wizard asks for IP information. Additionally, HTTP Basic authentication can also be configured to better secure the Oxidized web interface, using the Oxidized access username and Oxidized access password fields. Once deployed, the web interface becomes immediately accessible, simply by choosing the blue Actions button and selecting Access . Additional Oxidized configuration, such as altering the list of monitored devices or even adding custom Oxidized models can be done using Git. During the deployment process, a new GitLab repository has been automatically created which hosts the Oxidized configuration data. To access it, select Actions -> Configure and copy the git clone command. After cloning this repository, two folders should appear: base and model . The base folder houses basic configuration about the monitored devices: router.db \u2013 hostnames, IP addresses, and groups for the devices config \u2013 storage backend, backup storage location, credentials... The model folder houses specific device models, which describe how Oxidized should connect to the monitored devices and what commands to execute in order to acquire the running configuration. The RARE team has created a custom Oxidized model which allows configuration fetching from FreeRTR devices. If you have configured freeRTR as part of this tutorial, then this model is required for successful connections towards the freeRTR instances.","title":"Deploying Oxidized"},{"location":"self-hosted-nmaas/local-dev-environment/p4_monitoring-demo-network-environment/#monitoring-freertr-devices-with-oxidized","text":"After cloning the repository, navigate to the model folder and create the file rare.rb wth the following content: rare.rb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class RARE < Oxidized :: Model prompt /([\\w.@()-]+#\\s?)$/ comment '! ' cmd :all do | cfg | cfg . gsub! /^% Invalid input detected at '\\^' marker\\.$|^\\s+\\^$/ , '' cfg . cut_both end cmd :secret do | cfg | cfg end cmd 'show clock' do | cfg | comment \"---------- show clock\" comment cfg end cmd 'show platform' do | cfg | comment \"---------- show platform\" comments = [] comments << cfg . lines . first lines = cfg . lines lines . each_with_index do | line , i | if line !~ /^mem:|^uptime:/ comments << line . strip! end end comments << \" \\n \" comment comments . join \" \\n \" end cmd 'show interfaces description' do | cfg | comment \"---------- show interface description\" comment cfg end cmd 'show startup-config' do | cfg | comment \"---------- show startup-config\" cfg = cfg . each_line . to_a [ 0 ..- 1 ] cfg = cfg . reject { | line | line . match /^ntp clock-period / } . join cfg . gsub! /^Current configuration : [^\\n]*\\n/ , '' cfg . gsub! /^ tunnel mpls traffic-eng bandwidth[^\\n]*\\n*( (?: [^\\n]*\\n*)* tunnel mpls traffic-eng auto-bw)/mx , ' \\1 ' cfg end cfg :telnet do username /^Username:/i password /^Password:/i end cfg :telnet , :ssh do # preferred way to handle additional passwords post_login do if vars ( :enable ) == true cmd \"enable\" elsif vars ( :enable ) cmd \"enable\" , /^[pP]assword:/ cmd vars ( :enable ) end end post_login 'terminal length 0' post_login 'terminal width 0' pre_logout 'exit' end end After adding the model, it must also be referenced in the base/config file, where the format of the router.db file can be altered as well. config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 --- username : root password : root model : rare interval : 43200 use_syslog : false debug : false threads : 30 timeout : 20 retries : 3 prompt : !ruby/regexp /^([\\w.@-]+[#>]\\s?)$/ rest : 0.0.0.0:8888 vars : {} groups : {} pid : \"/storage/pid\" input : default : ssh, telnet debug : false ssh : secure : false output : default : git file : directory : \"/storage/configs\" git : user : oxidized email : oxidized@man.poznan.pl repo : \"/storage/oxidized.git\" source : default : csv csv : file : \"/root/.config/oxidized/router.db\" delimiter : !ruby/regexp /:/ map : name : 0 ip : 1 model : 2 model_map : rare : rare cisco : ios juniper : junos Note that we have altered the keys: model, source.csv.map and model_map. By altering the source.csv.map object we can set the format of the CSV file that contains the device information. In this case, we will format our CSV file using three columns: name ; ip ; model . Finally, alter the base/router.db file to reflect the changes made to the CSV format: router.db 1 2 r1:10.99.99.50:rare r2:10.99.99.51:rare The second column, the IP addresses, should be replaced with the IP addresses of your virtual freeRTR devices. The final step is to simply commit the changes that have been made. If this is the first time that Git is used, then the global Git user.name and email should be set: 1 2 git config --global user.name \"NMaaS Demo\" git config --global user.email \"nmaas_demo@example.com\" Any value can be used for these parameters, they are not related to NMaaS. The changes can be committed and pushed to the remote repository using: 1 2 3 git add . git commit -m \"freeRTR config change\" git push After the push is made, the Oxidized container will be rebooted to apply the changes. To verify the configuration changes that were made, the Oxidized web interface can be visited. It should show green boxes under Last Status for all devices. This means that the last attempt to fetch the configuration data has been successful. A complete version history can be obtained by using the versions option from the Actions column. On the Versions page there is an option to download a given configuration archive or create a diff.","title":"Monitoring freeRTR Devices with Oxidized"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/","text":"Part 5: Adding a Custom Application to the NMaaS Catalog Any application that has an existing Helm chart can be added to the NMaaS catalog. In this example we will use the popular uptime monitoring application - UptimeKuma . The agenda is to first create a regular Helm chart, without introducing any NMaaS dependencies, thus keeping it reusable across platforms. Then, we will add this Helm chart as a new application to the NMaaS catalog. Creating a Helm Chart NMaaS does not mandate any requirements when creating Helm charts. If Helm best practices are followed, then there should not be any problem in integrating the application to the NMaaS catalog. The boilerplate code for a new Helm chart can be generated using the helm create command: 1 helm create nmaas-uptimekuma Without going into specifics of how Helm charts are created, the source files for the nmaas-uptimekuma chart are provided below. We discuss some important aspects at the end of this section. templates/_helpers.tpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {{ /* vim : set filetype=mustache : * / }} {{ /* Expand the name of the chart. */ }} {{ - define \"name\" - }} {{ - default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" - }} {{ - end - }} {{ /* Create a default fully qualified app name. We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec). */ }} {{ - define \"fullname\" - }} {{ - .Release.Name | trunc 63 | trimSuffix \"-\" - }} {{ - end - }} templates/ingress.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 {{ - if .Values.ingress.enabled - }} {{ - $serviceName : = include \"fullname\" . - }} {{ - $servicePort : = .Values.service.port - }} {{ - $kubeVersion : = .Capabilities.KubeVersion.GitVersion - }} {{ - if semverCompare \">=1.19-0\" $kubeVersion - }} apiVersion : networking.k8s.io/v1 {{ - else - }} apiVersion : networking.k8s.io/v1beta1 {{ - end }} kind : Ingress metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} annotations : {{ - if .Values.ingress.tls.acme }} kubernetes.io/tls-acme : \"{{ .Values.ingress.tls.acme }}\" certmanager.k8s.io/cluster-issuer : \"{{ .Values.ingress.tls.certOrIssuer }}\" {{ - end }} kubernetes.io/ingress.class : \"{{ .Values.ingress.class }}\" nginx.ingress.kubernetes.io/proxy-read-timeout : \"3600\" nginx.ingress.kubernetes.io/proxy-send-timeout : \"3600\" nginx.ingress.kubernetes.io/server-snippets : | location / { proxy_set_header Upgrade $http_upgrade; proxy_http_version 1.1; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $host; proxy_set_header Connection \"upgrade\"; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_cache_bypass $http_upgrade; } spec : rules : {{ - range $host : = .Values.ingress.hosts }} - host : {{ $host }} http : paths : - path : / {{ - if semverCompare \">=1.19-0\" $kubeVersion }} pathType : Prefix backend : service : name : {{ $serviceName }} port : number : {{ $servicePort }} {{ - else }} backend : serviceName : {{ $serviceName }} servicePort : {{ $servicePort }} {{ - end }} {{ - end - }} {{ - if .Values.ingress.tls.enabled }} tls : - hosts : {{ - range $host : = .Values.ingress.hosts }} - {{ $host }} {{ - end - }} {{ - if .Values.ingress.tls.acme }} secretName : {{ .Release.Name }} -tls {{ - else }} secretName : {{ .Values.ingress.tls.certOrIssuer }} {{ - end }} {{ - end - }} {{ - end - }} templates/service.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion : v1 kind : Service metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} access : external spec : type : {{ .Values.service.type }} {{ - if eq .Values.service.type \"ClusterIP\" }} clusterIP : None {{ - end }} ports : - port : {{ .Values.service.port }} targetPort : {{ .Values.service.targetPort }} protocol : TCP name : {{ .Values.service.name }} selector : app : {{ template \"name\" . }} release : {{ .Release.Name }} templates/statefulset.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 apiVersion : apps/v1 kind : StatefulSet metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} spec : serviceName : \"\" replicas : {{ .Values.replicaCount }} selector : matchLabels : app : {{ template \"name\" . }} release : {{ .Release.Name }} template : metadata : labels : app : {{ template \"name\" . }} release : {{ .Release.Name }} spec : containers : - name : {{ .Chart.Name }} image : \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\" imagePullPolicy : {{ .Values.image.pullPolicy }} ports : - name : http containerPort : 3001 protocol : TCP resources : {{ - toYaml .Values.resources | nindent 12 }} volumeMounts : - mountPath : /app/data name : {{ .Values.persistence.existingClaim | default (include \"fullname\" .) | quote }} livenessProbe : exec : command : - node - extra/healthcheck.js initialDelaySeconds : 180 periodSeconds : 60 timeoutSeconds : 30 readinessProbe : httpGet : path : / port : 3001 scheme : HTTP {{ - if .Values.persistence.enabled }} volumes : {{ - if .Values.persistence.existingClaim }} - name : {{ .Values.persistence.existingClaim | quote }} persistentVolumeClaim : claimName : {{ .Values.persistence.existingClaim | quote }} {{ - else }} volumeClaimTemplates : - metadata : name : {{ include \"fullname\" . | quote }} spec : accessModes : - {{ .Values.persistence.accessMode | quote }} resources : requests : storage : {{ .Values.persistence.size | quote }} {{ - if and (.Values.persistence.storageClass) (ne \"-\" .Values.persistence.storageClass) }} storageClassName : \"{{ .Values.persistence.storageClass }}\" {{ - end }} {{ - end }} {{ - else }} volumes : - name : {{ include \"fullname\" . | quote }} emptyDir : {} {{ - end }} values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 replicaCount : 1 image : repository : louislam/uptime-kuma tag : \"1.10.2\" pullPolicy : IfNotPresent imagePullSecrets : [] nameOverride : \"\" fullnameOverride : \"\" service : name : http type : ClusterIP port : 3001 targetPort : http ingress : enabled : true class : nginx hosts : - uptime.nmaas.example.com tls : enabled : true resources : limits : cpu : 500m memory : 512Mi requests : cpu : 200m memory : 256Mi persistence : enabled : True storageClass : \"-\" size : 5Gi accessMode : ReadWriteOnce existingClaim : \"\" Note that no NMaaS specific information has been used in the chart. The same chart can be used to create an instance of the uptime-kuma application on any Kubernetes cluster. Once the chart has been created, it should be uploaded to a Helm repository. There are many providers which allow hosting of Helm charts free of charge. Submitting an Application to the NMaaS catalog For more information, please have a look at our dedicated guide where a step-by-step explanation is provided on using GitHub for hosting and publishing Helm charts - Adding a New Application . Adding a new Application to the NMaaS Catalog After the chart has been updated to a public Helm repository, the new application wizard can be used to add it to the NMaaS catalog. Login as the administrator user within the NMaaS portal and choose Settings -> Applications . Click on the blue Add button in the top-left corner. The new application wizard consists of 7 steps. These steps are: General information Basic application information Logo and screenshots Application descriptions Deployment specification Configuration templates Content review In the sections that follow we elaborate further on each step. Step 1: General Information The general information step provides a brief description of the process for adding a new application to the NMaaS catalog. Users are required only to tick the I read the general instructions above checkbox before proceeding to the next step, Basic application information . Step 2: Basic Application Information The Basic application information step requires the administrator to enter information that will describe the application and provide external links for the license, source code, official website, and tags. All of this information is shown on the application details page. The tags are used to better classify the application in terms of the functionality that it offers. Step 3: Logo and Screenshots The third step asks the administrator to upload the application logo which will be shown in the catalog, as well as screenshots, showing the most common use-cases. Before uploading any images, please ensure that you have the appropriate copyright permission to do so. Step 4: Application Descriptions NMaaS supports localization in multiple languages. By default the Application descriptions steps shows input fields for Brief description and Full description of the application in English. These fields should be used to provide a brief introduction for new users to the applications, explaining its features, as well as any default username or passwords that have been used and users are expected to change. Translation of the content can be provided for additional languages by choosing the Select optional languages dropdown in the bottom left corner. Step 5: Deployment Specification The deployment specification page contains common parameters that should be parametrized during the instance deployment procedure by end-users. These parameters are relevant for all applications, such as whether the application exposes a web interface, has a built-in SSH server, volume information... Additionally, in the Static global deploy parameters section, application maintainers can specify any additional parameters that should be passed as is to all new instances of the application. The deploy parameter key field should reference the values.yaml parameter that needs to be customized, while the Deploy parameter value its value. Basic Application Information The basic application information is consisted of the following fields: Chart name \u2013 the name of the Helm chart that has been uploaded to a public repository. All instances created by end-users will actually be Releases of this chart. Chart version \u2013 the chart version to be used for creating new application instances. Note that NMaaS fully supports application versioning, and more than one application version can be active and available in the NMaaS catalog at a given point in time. Additional versions can be added once the application has been integrated into the catalog. Helm Chart repository URL address \u2013 the full URL to the Helm repository where the chart is hosted. Expose web user interface \u2013 whether the application being added to the catalog exposes a web interface that should be reachable by users. In the case of UptimeKuma, this should be ticked. Allow SSH access \u2013 whether the application being added to the catalog comes with a built-in SSH server through which the users can directly connect to the container where the application is running, e.g., for additional configuration. Global Deploy Parameters The global deploy parameters allow the administrator to pass some globally defined NMaaS variables to the Helm Release during its deployment. For example, many applications allow users to specify outbound SMTP servers which can be used for external email sending. Since NMaaS already has an SMTP component, any deployed application can simply use the configured and tested NMaaS email server. In this case, the system variables SMTP_HOSTNAME , SMTP_PORT , SMTP_USERNAME , SMTP_PASSWORD can be passed to arbitrary Helm value keys. For example, the following configuration would pass the global SMTP_HOSTNAME deploy parameter as the config.smtp.host chart parameter whenever a new Release is created: The following global deploy parameters are currently available: SMTP_HOSTNAME SMTP_PORT SMTP_USERNAME SMTP_PASSWORD DOMAIN_CODENAME \u2013 the name of the domain where the Release is being created BASE_URL \u2013 the URL at which the application will be accessible RELEASE_NAME \u2013 the name of the Helm Release In the case of UptimeKuma, we do not need to configure any global deploy parameters. Static Global Deploy Parameters Static global deploy parameters allow the application administrator to specify custom parameters that should be passed to the chart whenever a new Release is being created. Please note that this is different than Global Deploy Parameters which were used to pass an internal NMaaS parameter to each new Release. In the case of static global deploy parameters, there is no limitation on what can be passed as a value. Let's assume that our chart has a values.yaml parameter that enables or disables new user registration, and this parameter is set to enable by default. If we want to disable new user registrations for each new Release and do not want the NMaaS user to have an option to enable registrations, then we can simple disable this behavior using a static global deploy parameter. An example is given below. In the case of UptimeKuma, we do not need to configure any global deploy parameters, since the chart itself is relatively simple. Storage Volumes The storage volumes section allows the configuration of persistent volumes for each new release. This is similar to the global deploy parameters but this configuration has been externalized to a dedicated section in order to make it more straight forward. The following global variables should be passed to the respective chart parameters that deal with storage: PERSISTENCE_ENABLED (e.g., this option is commonly specified as persistence.enabled in charts) PERSISTENCE_STORAGE_SPACE (e.g., this option is commonly specified as persistence.size in charts) PERSISTENCE_STORAGE_CLASS (e.g., this option is commonly specified as persistence.storageClass in charts) PERSISTENCE_NAME (e.g., this option is commonly specified as persistence.name in charts) The Default storage space input field allows the administrator to set a default value for new PersistentVolumeClaims created during instance deployment. The size is expressed in gigabytes. Users are usually given an option to customize this value by themselves. In the case of UptimeKuma, the following configuration is required: Access Methods The Access Methods section allows the application administrator to customize the parameters related to external access. As previously, NMaaS parameters are mapped to the appropriate parameters exposed by the Chart's values.yaml file. Most of the parameters are self-explanatory, but some warrant additional attention. For example: the INGRESS_CLASS parameter will contain the ingress class that should be used for the newly deployed ingress object once the Helm Release is created. This is an essential information, since NMaaS supports per-domain ingress controllers. Without this information, the wrong ingress controller will most like be used for serving, or the application would not be accessible at all. In the case of UptimeKuma, the following configuration is required: Step 6: Configuration Templates In the Configuration Templates step the administrator can specify which chart parameters can be specified by the end-users themselves. This step of the wizard offers a full-fledged form builder tool, which can be used for configuring the deployment parameters by the users. Let's presume that the chart exposes a global.notifications.certificateExpiry parameter which customizes whether the application will send certificate expiry notifications for added monitors or not. We can allow the NMaaS users to customize this parameter in the following way. This parameter would best be modeled by a checkbox, so we drag-and-drop the checkbox component from the left hand side toolbar to the main canvas. In the Display tab enter basic information about the new form field, such as its label, description, and optional tooltip that will be shown on hover. In the API tab using the Property Name input field enter the values.yaml chart parameter to which this information should be passed. In our mock example this is global#notifications#certificateExpiry . Please note that instead of . (dot), the # (hash) sign should be used. This is a limitation of the web interface. Save the field configuration by clicking on the green Save button. Step 7: Content Review The last step of the wizard is to simply review the entered information in the previous step and check the preview. If no additional changes need to be made, the application can be submitted by clicking on the green Submit button. Approving the Application Before the application will be shown to all users of the NMaaS instance, it must be activated. This can be done from the Applications page by simply expanding the list of application versions, hovering on the cog button, selecting the Change state option and setting the state to Active .","title":"Part 5 - Adding a Custom Application"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#part-5-adding-a-custom-application-to-the-nmaas-catalog","text":"Any application that has an existing Helm chart can be added to the NMaaS catalog. In this example we will use the popular uptime monitoring application - UptimeKuma . The agenda is to first create a regular Helm chart, without introducing any NMaaS dependencies, thus keeping it reusable across platforms. Then, we will add this Helm chart as a new application to the NMaaS catalog.","title":"Part 5: Adding a Custom Application to the NMaaS Catalog"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#creating-a-helm-chart","text":"NMaaS does not mandate any requirements when creating Helm charts. If Helm best practices are followed, then there should not be any problem in integrating the application to the NMaaS catalog. The boilerplate code for a new Helm chart can be generated using the helm create command: 1 helm create nmaas-uptimekuma Without going into specifics of how Helm charts are created, the source files for the nmaas-uptimekuma chart are provided below. We discuss some important aspects at the end of this section. templates/_helpers.tpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {{ /* vim : set filetype=mustache : * / }} {{ /* Expand the name of the chart. */ }} {{ - define \"name\" - }} {{ - default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" - }} {{ - end - }} {{ /* Create a default fully qualified app name. We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec). */ }} {{ - define \"fullname\" - }} {{ - .Release.Name | trunc 63 | trimSuffix \"-\" - }} {{ - end - }} templates/ingress.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 {{ - if .Values.ingress.enabled - }} {{ - $serviceName : = include \"fullname\" . - }} {{ - $servicePort : = .Values.service.port - }} {{ - $kubeVersion : = .Capabilities.KubeVersion.GitVersion - }} {{ - if semverCompare \">=1.19-0\" $kubeVersion - }} apiVersion : networking.k8s.io/v1 {{ - else - }} apiVersion : networking.k8s.io/v1beta1 {{ - end }} kind : Ingress metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} annotations : {{ - if .Values.ingress.tls.acme }} kubernetes.io/tls-acme : \"{{ .Values.ingress.tls.acme }}\" certmanager.k8s.io/cluster-issuer : \"{{ .Values.ingress.tls.certOrIssuer }}\" {{ - end }} kubernetes.io/ingress.class : \"{{ .Values.ingress.class }}\" nginx.ingress.kubernetes.io/proxy-read-timeout : \"3600\" nginx.ingress.kubernetes.io/proxy-send-timeout : \"3600\" nginx.ingress.kubernetes.io/server-snippets : | location / { proxy_set_header Upgrade $http_upgrade; proxy_http_version 1.1; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $host; proxy_set_header Connection \"upgrade\"; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_cache_bypass $http_upgrade; } spec : rules : {{ - range $host : = .Values.ingress.hosts }} - host : {{ $host }} http : paths : - path : / {{ - if semverCompare \">=1.19-0\" $kubeVersion }} pathType : Prefix backend : service : name : {{ $serviceName }} port : number : {{ $servicePort }} {{ - else }} backend : serviceName : {{ $serviceName }} servicePort : {{ $servicePort }} {{ - end }} {{ - end - }} {{ - if .Values.ingress.tls.enabled }} tls : - hosts : {{ - range $host : = .Values.ingress.hosts }} - {{ $host }} {{ - end - }} {{ - if .Values.ingress.tls.acme }} secretName : {{ .Release.Name }} -tls {{ - else }} secretName : {{ .Values.ingress.tls.certOrIssuer }} {{ - end }} {{ - end - }} {{ - end - }} templates/service.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 apiVersion : v1 kind : Service metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} access : external spec : type : {{ .Values.service.type }} {{ - if eq .Values.service.type \"ClusterIP\" }} clusterIP : None {{ - end }} ports : - port : {{ .Values.service.port }} targetPort : {{ .Values.service.targetPort }} protocol : TCP name : {{ .Values.service.name }} selector : app : {{ template \"name\" . }} release : {{ .Release.Name }} templates/statefulset.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 apiVersion : apps/v1 kind : StatefulSet metadata : name : {{ template \"fullname\" . }} labels : app : {{ template \"name\" . }} chart : {{ .Chart.Name }} -{{ .Chart.Version | replace \"+\" \"_\" }} release : {{ .Release.Name }} heritage : {{ .Release.Service }} spec : serviceName : \"\" replicas : {{ .Values.replicaCount }} selector : matchLabels : app : {{ template \"name\" . }} release : {{ .Release.Name }} template : metadata : labels : app : {{ template \"name\" . }} release : {{ .Release.Name }} spec : containers : - name : {{ .Chart.Name }} image : \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\" imagePullPolicy : {{ .Values.image.pullPolicy }} ports : - name : http containerPort : 3001 protocol : TCP resources : {{ - toYaml .Values.resources | nindent 12 }} volumeMounts : - mountPath : /app/data name : {{ .Values.persistence.existingClaim | default (include \"fullname\" .) | quote }} livenessProbe : exec : command : - node - extra/healthcheck.js initialDelaySeconds : 180 periodSeconds : 60 timeoutSeconds : 30 readinessProbe : httpGet : path : / port : 3001 scheme : HTTP {{ - if .Values.persistence.enabled }} volumes : {{ - if .Values.persistence.existingClaim }} - name : {{ .Values.persistence.existingClaim | quote }} persistentVolumeClaim : claimName : {{ .Values.persistence.existingClaim | quote }} {{ - else }} volumeClaimTemplates : - metadata : name : {{ include \"fullname\" . | quote }} spec : accessModes : - {{ .Values.persistence.accessMode | quote }} resources : requests : storage : {{ .Values.persistence.size | quote }} {{ - if and (.Values.persistence.storageClass) (ne \"-\" .Values.persistence.storageClass) }} storageClassName : \"{{ .Values.persistence.storageClass }}\" {{ - end }} {{ - end }} {{ - else }} volumes : - name : {{ include \"fullname\" . | quote }} emptyDir : {} {{ - end }} values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 replicaCount : 1 image : repository : louislam/uptime-kuma tag : \"1.10.2\" pullPolicy : IfNotPresent imagePullSecrets : [] nameOverride : \"\" fullnameOverride : \"\" service : name : http type : ClusterIP port : 3001 targetPort : http ingress : enabled : true class : nginx hosts : - uptime.nmaas.example.com tls : enabled : true resources : limits : cpu : 500m memory : 512Mi requests : cpu : 200m memory : 256Mi persistence : enabled : True storageClass : \"-\" size : 5Gi accessMode : ReadWriteOnce existingClaim : \"\" Note that no NMaaS specific information has been used in the chart. The same chart can be used to create an instance of the uptime-kuma application on any Kubernetes cluster. Once the chart has been created, it should be uploaded to a Helm repository. There are many providers which allow hosting of Helm charts free of charge. Submitting an Application to the NMaaS catalog For more information, please have a look at our dedicated guide where a step-by-step explanation is provided on using GitHub for hosting and publishing Helm charts - Adding a New Application .","title":"Creating a Helm Chart"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#adding-a-new-application-to-the-nmaas-catalog","text":"After the chart has been updated to a public Helm repository, the new application wizard can be used to add it to the NMaaS catalog. Login as the administrator user within the NMaaS portal and choose Settings -> Applications . Click on the blue Add button in the top-left corner. The new application wizard consists of 7 steps. These steps are: General information Basic application information Logo and screenshots Application descriptions Deployment specification Configuration templates Content review In the sections that follow we elaborate further on each step.","title":"Adding a new Application to the NMaaS Catalog"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-1-general-information","text":"The general information step provides a brief description of the process for adding a new application to the NMaaS catalog. Users are required only to tick the I read the general instructions above checkbox before proceeding to the next step, Basic application information .","title":"Step 1: General Information"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-2-basic-application-information","text":"The Basic application information step requires the administrator to enter information that will describe the application and provide external links for the license, source code, official website, and tags. All of this information is shown on the application details page. The tags are used to better classify the application in terms of the functionality that it offers.","title":"Step 2: Basic Application Information"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-3-logo-and-screenshots","text":"The third step asks the administrator to upload the application logo which will be shown in the catalog, as well as screenshots, showing the most common use-cases. Before uploading any images, please ensure that you have the appropriate copyright permission to do so.","title":"Step 3: Logo and Screenshots"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-4-application-descriptions","text":"NMaaS supports localization in multiple languages. By default the Application descriptions steps shows input fields for Brief description and Full description of the application in English. These fields should be used to provide a brief introduction for new users to the applications, explaining its features, as well as any default username or passwords that have been used and users are expected to change. Translation of the content can be provided for additional languages by choosing the Select optional languages dropdown in the bottom left corner.","title":"Step 4: Application Descriptions"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-5-deployment-specification","text":"The deployment specification page contains common parameters that should be parametrized during the instance deployment procedure by end-users. These parameters are relevant for all applications, such as whether the application exposes a web interface, has a built-in SSH server, volume information... Additionally, in the Static global deploy parameters section, application maintainers can specify any additional parameters that should be passed as is to all new instances of the application. The deploy parameter key field should reference the values.yaml parameter that needs to be customized, while the Deploy parameter value its value.","title":"Step 5: Deployment Specification"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#basic-application-information","text":"The basic application information is consisted of the following fields: Chart name \u2013 the name of the Helm chart that has been uploaded to a public repository. All instances created by end-users will actually be Releases of this chart. Chart version \u2013 the chart version to be used for creating new application instances. Note that NMaaS fully supports application versioning, and more than one application version can be active and available in the NMaaS catalog at a given point in time. Additional versions can be added once the application has been integrated into the catalog. Helm Chart repository URL address \u2013 the full URL to the Helm repository where the chart is hosted. Expose web user interface \u2013 whether the application being added to the catalog exposes a web interface that should be reachable by users. In the case of UptimeKuma, this should be ticked. Allow SSH access \u2013 whether the application being added to the catalog comes with a built-in SSH server through which the users can directly connect to the container where the application is running, e.g., for additional configuration.","title":"Basic Application Information"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#global-deploy-parameters","text":"The global deploy parameters allow the administrator to pass some globally defined NMaaS variables to the Helm Release during its deployment. For example, many applications allow users to specify outbound SMTP servers which can be used for external email sending. Since NMaaS already has an SMTP component, any deployed application can simply use the configured and tested NMaaS email server. In this case, the system variables SMTP_HOSTNAME , SMTP_PORT , SMTP_USERNAME , SMTP_PASSWORD can be passed to arbitrary Helm value keys. For example, the following configuration would pass the global SMTP_HOSTNAME deploy parameter as the config.smtp.host chart parameter whenever a new Release is created: The following global deploy parameters are currently available: SMTP_HOSTNAME SMTP_PORT SMTP_USERNAME SMTP_PASSWORD DOMAIN_CODENAME \u2013 the name of the domain where the Release is being created BASE_URL \u2013 the URL at which the application will be accessible RELEASE_NAME \u2013 the name of the Helm Release In the case of UptimeKuma, we do not need to configure any global deploy parameters.","title":"Global Deploy Parameters"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#static-global-deploy-parameters","text":"Static global deploy parameters allow the application administrator to specify custom parameters that should be passed to the chart whenever a new Release is being created. Please note that this is different than Global Deploy Parameters which were used to pass an internal NMaaS parameter to each new Release. In the case of static global deploy parameters, there is no limitation on what can be passed as a value. Let's assume that our chart has a values.yaml parameter that enables or disables new user registration, and this parameter is set to enable by default. If we want to disable new user registrations for each new Release and do not want the NMaaS user to have an option to enable registrations, then we can simple disable this behavior using a static global deploy parameter. An example is given below. In the case of UptimeKuma, we do not need to configure any global deploy parameters, since the chart itself is relatively simple.","title":"Static Global Deploy Parameters"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#storage-volumes","text":"The storage volumes section allows the configuration of persistent volumes for each new release. This is similar to the global deploy parameters but this configuration has been externalized to a dedicated section in order to make it more straight forward. The following global variables should be passed to the respective chart parameters that deal with storage: PERSISTENCE_ENABLED (e.g., this option is commonly specified as persistence.enabled in charts) PERSISTENCE_STORAGE_SPACE (e.g., this option is commonly specified as persistence.size in charts) PERSISTENCE_STORAGE_CLASS (e.g., this option is commonly specified as persistence.storageClass in charts) PERSISTENCE_NAME (e.g., this option is commonly specified as persistence.name in charts) The Default storage space input field allows the administrator to set a default value for new PersistentVolumeClaims created during instance deployment. The size is expressed in gigabytes. Users are usually given an option to customize this value by themselves. In the case of UptimeKuma, the following configuration is required:","title":"Storage Volumes"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#access-methods","text":"The Access Methods section allows the application administrator to customize the parameters related to external access. As previously, NMaaS parameters are mapped to the appropriate parameters exposed by the Chart's values.yaml file. Most of the parameters are self-explanatory, but some warrant additional attention. For example: the INGRESS_CLASS parameter will contain the ingress class that should be used for the newly deployed ingress object once the Helm Release is created. This is an essential information, since NMaaS supports per-domain ingress controllers. Without this information, the wrong ingress controller will most like be used for serving, or the application would not be accessible at all. In the case of UptimeKuma, the following configuration is required:","title":"Access Methods"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-6-configuration-templates","text":"In the Configuration Templates step the administrator can specify which chart parameters can be specified by the end-users themselves. This step of the wizard offers a full-fledged form builder tool, which can be used for configuring the deployment parameters by the users. Let's presume that the chart exposes a global.notifications.certificateExpiry parameter which customizes whether the application will send certificate expiry notifications for added monitors or not. We can allow the NMaaS users to customize this parameter in the following way. This parameter would best be modeled by a checkbox, so we drag-and-drop the checkbox component from the left hand side toolbar to the main canvas. In the Display tab enter basic information about the new form field, such as its label, description, and optional tooltip that will be shown on hover. In the API tab using the Property Name input field enter the values.yaml chart parameter to which this information should be passed. In our mock example this is global#notifications#certificateExpiry . Please note that instead of . (dot), the # (hash) sign should be used. This is a limitation of the web interface. Save the field configuration by clicking on the green Save button.","title":"Step 6: Configuration Templates"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#step-7-content-review","text":"The last step of the wizard is to simply review the entered information in the previous step and check the preview. If no additional changes need to be made, the application can be submitted by clicking on the green Submit button.","title":"Step 7: Content Review"},{"location":"self-hosted-nmaas/local-dev-environment/p5_adding_custom_app/#approving-the-application","text":"Before the application will be shown to all users of the NMaaS instance, it must be activated. This can be done from the Applications page by simply expanding the list of application versions, hovering on the cog button, selecting the Change state option and setting the state to Active .","title":"Approving the Application"},{"location":"use-cases/virtual-lab/bulk-application-deployment/","text":"Bulk Application Deployment The \"bulk application deployment\" feature allows NMaaS administrators to deploy many application instances at once. This is useful for scenarios where NMaaS is used simply as an orchestration platform, and the end-users of the deployed applications should not be required to have an NMaaS account. Bulk Application Deployment in the Context of Virtual Lab When using NMaaS for the virtual lab use-case, teachers might want to deploy individual application instances for each student taking part in a course, without going over the account provisioning process first. There can be many reasons for taking this approach, such as: the NMaaS web UI is deployed in an isolated network without public access the students are not experienced enough with the use of PaaS-like platforms the process defined by the home institution regarding on-boarding of new users to NMaaS is too time consuming After bulk deploying the applications, teachers can simply share the connection information with the students, completely abstracting away the use of NMaaS, and hiding any implementational details. Using Bulk Application Deployment The bulk application deployment feature can be accessed by navigating to Advanced -> Bulk application deployments . Note that currently this feature is only available to global NMaaS administrators. The overview page shows a history of past bulk application deployments, with options either to see more details about a given deployment, or create a new one. A new bulk application deployment can be initiated by clicking on the New deployment button. The first step when launching the bulk application deployment wizard is to select which application is going to be deployed. The second step is dedicated to customizing the deployments. A CSV file can be uploaded, specifying the domains in which the applications should be deployed, the application versions, and any auxiliary parameters which need to be overridden. These parameters are related to Helm parameters which are exposed in the underlying chart's values.yaml file. A basic example of a CSV file which can be used for bulk application deployment is given below. 1 2 3 domain,instance,version,param.juiceshop.properties.ctfKey demo-user02,demojsh02,14.5.1,SECRET1 demo-user03,demojsh03,14.5.1,SECRET1 In the example above the Helm parameter juiceshop.properties.ctfKey is customized for both of the deployments. Additional Parameter Specification Any Helm parameter can be overridden, assuming that it is prefixed with the static prefix param. . For example, if ingress support should be disabled for given bulk deployments, and assuming that the chart exposes an ingress.enabled flag, the CSV file will need to contain a dedicated param.ingress.enabled column. The bulk deployment wizard supports either uploading an existing CSV file from the local device or editing the provided example directly in the browser. Once the CSV file is uploaded, the applications will be instantiated in a background task. Administrators can follow the progress from the details page. Once deployment is completed, connection details can be obtained on a per-application basis. The video below demonstrates the bulk application deployment process.","title":"Bulk Application Deployment"},{"location":"use-cases/virtual-lab/bulk-application-deployment/#bulk-application-deployment","text":"The \"bulk application deployment\" feature allows NMaaS administrators to deploy many application instances at once. This is useful for scenarios where NMaaS is used simply as an orchestration platform, and the end-users of the deployed applications should not be required to have an NMaaS account.","title":"Bulk Application Deployment"},{"location":"use-cases/virtual-lab/bulk-application-deployment/#bulk-application-deployment-in-the-context-of-virtual-lab","text":"When using NMaaS for the virtual lab use-case, teachers might want to deploy individual application instances for each student taking part in a course, without going over the account provisioning process first. There can be many reasons for taking this approach, such as: the NMaaS web UI is deployed in an isolated network without public access the students are not experienced enough with the use of PaaS-like platforms the process defined by the home institution regarding on-boarding of new users to NMaaS is too time consuming After bulk deploying the applications, teachers can simply share the connection information with the students, completely abstracting away the use of NMaaS, and hiding any implementational details.","title":"Bulk Application Deployment in the Context of Virtual Lab"},{"location":"use-cases/virtual-lab/bulk-application-deployment/#using-bulk-application-deployment","text":"The bulk application deployment feature can be accessed by navigating to Advanced -> Bulk application deployments . Note that currently this feature is only available to global NMaaS administrators. The overview page shows a history of past bulk application deployments, with options either to see more details about a given deployment, or create a new one. A new bulk application deployment can be initiated by clicking on the New deployment button. The first step when launching the bulk application deployment wizard is to select which application is going to be deployed. The second step is dedicated to customizing the deployments. A CSV file can be uploaded, specifying the domains in which the applications should be deployed, the application versions, and any auxiliary parameters which need to be overridden. These parameters are related to Helm parameters which are exposed in the underlying chart's values.yaml file. A basic example of a CSV file which can be used for bulk application deployment is given below. 1 2 3 domain,instance,version,param.juiceshop.properties.ctfKey demo-user02,demojsh02,14.5.1,SECRET1 demo-user03,demojsh03,14.5.1,SECRET1 In the example above the Helm parameter juiceshop.properties.ctfKey is customized for both of the deployments. Additional Parameter Specification Any Helm parameter can be overridden, assuming that it is prefixed with the static prefix param. . For example, if ingress support should be disabled for given bulk deployments, and assuming that the chart exposes an ingress.enabled flag, the CSV file will need to contain a dedicated param.ingress.enabled column. The bulk deployment wizard supports either uploading an existing CSV file from the local device or editing the provided example directly in the browser. Once the CSV file is uploaded, the applications will be instantiated in a background task. Administrators can follow the progress from the details page. Once deployment is completed, connection details can be obtained on a per-application basis. The video below demonstrates the bulk application deployment process.","title":"Using Bulk Application Deployment"},{"location":"use-cases/virtual-lab/bulk-domain-deployment/","text":"Bulk Domain Deployment The \"bulk domain deployment\" feature in NMaaS allows administrators to provision new domains and users in bulk. This is useful in cases where large groups of people should be registered at once, such as in the case with the virtual lab scenario. Bulk Domain Deployment in the Context of Virtual Lab When NMaaS is used for virtual lab deployments, teachers might need to create new accounts for all enrolled students in a given course, create corresponding domains, and join them to appropriate domain groups . All of these tasks can be accomplished using the bulk domain deployment functionality. Using Bulk Domain Deployment Administrators can access the bulk domain deployment feature by navigating to Advanced -> Bulk domain deployment . From there, a history of existing bulk domain deployments can be seen, with an option to initiate a new one as well. Clicking on the New deployment button opens the bulk domain deployment wizard. New domains can be specified either by using the built-in CSV editor or uploading an existing CSV file from the local device. The CSV file should have the following columns: 1 domain,username,networks,domainGroups,email Registering New Users Non-existent users can also be referenced in the CSV file for bulk domain deployment. In such cases, the user is automatically provisioned. Access to the NMaaS platform is provided to users after using the Forgot password functionality, and activating their account using the provided email address during the bulk domain provisioning. Domain Groups During bulk domain deployment, if any non-existent domain groups referenced in the CSV file are automatically created. After the domain import is completed, administrators should make sure to whitelist the desired applications for deployment, since by default all applications are blacklisted for new domain groups. The video below demonstrates the whole bulk domain deployment process.","title":"Bulk Domain Deployment"},{"location":"use-cases/virtual-lab/bulk-domain-deployment/#bulk-domain-deployment","text":"The \"bulk domain deployment\" feature in NMaaS allows administrators to provision new domains and users in bulk. This is useful in cases where large groups of people should be registered at once, such as in the case with the virtual lab scenario.","title":"Bulk Domain Deployment"},{"location":"use-cases/virtual-lab/bulk-domain-deployment/#bulk-domain-deployment-in-the-context-of-virtual-lab","text":"When NMaaS is used for virtual lab deployments, teachers might need to create new accounts for all enrolled students in a given course, create corresponding domains, and join them to appropriate domain groups . All of these tasks can be accomplished using the bulk domain deployment functionality.","title":"Bulk Domain Deployment in the Context of Virtual Lab"},{"location":"use-cases/virtual-lab/bulk-domain-deployment/#using-bulk-domain-deployment","text":"Administrators can access the bulk domain deployment feature by navigating to Advanced -> Bulk domain deployment . From there, a history of existing bulk domain deployments can be seen, with an option to initiate a new one as well. Clicking on the New deployment button opens the bulk domain deployment wizard. New domains can be specified either by using the built-in CSV editor or uploading an existing CSV file from the local device. The CSV file should have the following columns: 1 domain,username,networks,domainGroups,email Registering New Users Non-existent users can also be referenced in the CSV file for bulk domain deployment. In such cases, the user is automatically provisioned. Access to the NMaaS platform is provided to users after using the Forgot password functionality, and activating their account using the provided email address during the bulk domain provisioning. Domain Groups During bulk domain deployment, if any non-existent domain groups referenced in the CSV file are automatically created. After the domain import is completed, administrators should make sure to whitelist the desired applications for deployment, since by default all applications are blacklisted for new domain groups. The video below demonstrates the whole bulk domain deployment process.","title":"Using Bulk Domain Deployment"},{"location":"use-cases/virtual-lab/domain-groups/","text":"Domain Groups in NMaaS \"Domain groups\" is an NMaaS feature that allows NMaaS administrators to restrict which applications are available for deployment to given domains. This feature is useful for scenarios where a group of domains should have access to a restricted set of applications, instead of the whole catalog. Domain Groups in the Context of Virtual Lab An example scenario for domain groups and one for which they were originally developed is virtual lab. When organizing virtual labs on NMaaS, it is expected that many different users might need access to a different set of applications, but not to the whole catalog at once. This is the case when a university uses NMaaS for conducting virtual labs for multiple courses. Students enrolled in course A might need access to applications 1, 2, and 3, while students in course B might need access to applications 4, 5, and 6. Assuming that the complete NMaaS catalog also includes applications aimed at the teaching staff which might require additional compute resources or present security risks when deployed by students, such applications should not be deployable in the students' domains. Using Domain Groups Domain groups can be created during the bulk domain creation process, as well as manually. One domain group can contain multiple domains, and one domain can be part of multiple domain groups. Taking into account that one domain might partake in multiple domain groups, the formal list of applications deployable in a given domain is a union of all deployable applications allowed by all of the domain groups in which the given domain is a member. For example, if the domain test-domain is part of domain groups group1 , group2 , and group3 , and assuming that they define the following lists of available applications: Domain group group1 : Zabbix , PostgreSQL Domain group group2 : MariaDB , JuiceShop Domain group group3 : InfluxDB In the scenario described above, test-domain would have access to all 5 applications: Zabbix , PostgreSQL , MariaDB , JuiceShop , and InfluxDB . The goal for this behavior is to allow a user to reuse a single domain across multiple courses, where each course might be represented by a separate domain group, allowing only the deployment of applications which are necessary for completing the course. Initial Domain Group Settings When creating a domain group for the first time, all of the applications are blacklisted. This means that a domain part of a single domain group where application policies have not been defined yet will not be able to deploy any application on NMaaS. Domain groups can be managed by selecting the Domain groups option from the settings dropdown in the navigational menu (represented by a cog icon). Administrators are given the option to manually create a new domain group, manage domain group memberships, and alter the list of whitelisted/blacklisted applications for a given domain group. The video below demonstrates the domain groups configuration process.","title":"Domain Groups"},{"location":"use-cases/virtual-lab/domain-groups/#domain-groups-in-nmaas","text":"\"Domain groups\" is an NMaaS feature that allows NMaaS administrators to restrict which applications are available for deployment to given domains. This feature is useful for scenarios where a group of domains should have access to a restricted set of applications, instead of the whole catalog.","title":"Domain Groups in NMaaS"},{"location":"use-cases/virtual-lab/domain-groups/#domain-groups-in-the-context-of-virtual-lab","text":"An example scenario for domain groups and one for which they were originally developed is virtual lab. When organizing virtual labs on NMaaS, it is expected that many different users might need access to a different set of applications, but not to the whole catalog at once. This is the case when a university uses NMaaS for conducting virtual labs for multiple courses. Students enrolled in course A might need access to applications 1, 2, and 3, while students in course B might need access to applications 4, 5, and 6. Assuming that the complete NMaaS catalog also includes applications aimed at the teaching staff which might require additional compute resources or present security risks when deployed by students, such applications should not be deployable in the students' domains.","title":"Domain Groups in the Context of Virtual Lab"},{"location":"use-cases/virtual-lab/domain-groups/#using-domain-groups","text":"Domain groups can be created during the bulk domain creation process, as well as manually. One domain group can contain multiple domains, and one domain can be part of multiple domain groups. Taking into account that one domain might partake in multiple domain groups, the formal list of applications deployable in a given domain is a union of all deployable applications allowed by all of the domain groups in which the given domain is a member. For example, if the domain test-domain is part of domain groups group1 , group2 , and group3 , and assuming that they define the following lists of available applications: Domain group group1 : Zabbix , PostgreSQL Domain group group2 : MariaDB , JuiceShop Domain group group3 : InfluxDB In the scenario described above, test-domain would have access to all 5 applications: Zabbix , PostgreSQL , MariaDB , JuiceShop , and InfluxDB . The goal for this behavior is to allow a user to reuse a single domain across multiple courses, where each course might be represented by a separate domain group, allowing only the deployment of applications which are necessary for completing the course. Initial Domain Group Settings When creating a domain group for the first time, all of the applications are blacklisted. This means that a domain part of a single domain group where application policies have not been defined yet will not be able to deploy any application on NMaaS. Domain groups can be managed by selecting the Domain groups option from the settings dropdown in the navigational menu (represented by a cog icon). Administrators are given the option to manually create a new domain group, manage domain group memberships, and alter the list of whitelisted/blacklisted applications for a given domain group. The video below demonstrates the domain groups configuration process.","title":"Using Domain Groups"},{"location":"use-cases/virtual-lab/vlab-introduction/","text":"Introduction to NMaaS Virtual Lab NMaaS Virtual Lab is a new NMaaS use-case aimed at educational communities. The core idea is to leverage the existing NMaaS functionality of on-demand application deployment and repurpose it in a learning context. This approach would allow NMaaS to be further used in the process of both formal, supervised, education (e.g., university courses), as well as for informal, and self-paced education (MOOCs, short demos, tutorials). During the initial planning, a number of scenarios have been envisioned, including: deployment of randomized, black-box containers for studying common software vulnerabilities; offloading of resource-intensive workloads on a centralized and powerful Kubernetes cluster, including JupyterLab servers, data processing pipelines, and simulations; creation of personalized, portable development environments with all necessary services included, such as a web-based integrated development environments (IDEs), relational databases, message queues, application servers, etc... making use of limited compute resources to serve as many users as possible through the deployment of ephemeral containers that are active only while used and paused when idle. Reactivation can be attempted at any point in time, preserving all previous data. The overall use-case along with its distinct scenarios has the potential to bring a number of benefits to both learners and educators. In the subsections below we elaborate on the underlying NMaaS features which make these benefits possible in more details. NMaaS Virtual Lab from the Perspective of Educators Organizing hands-on exercises where all students can participate is often a challenging and time-consuming task for educators. It entails hardware provisioning, configuration, application deployment, user management, per tenant isolation, and integration with existing platforms, such as learning management systems (LMS) and grading systems. Depending on the subject area and technical proficiency of the educators and supporting staff, this manual approach does not scale for moderate and large groups of students. To overcome these issues, NMaaS will implement the following features, with the end-goal of making the organization of hands-on exercises by educators as effortless as possible: centralized provisioning and management of user profiles together with support for bulk user imports from LMS exports; individual, isolated, workspace (domain) for each and every user where they can deploy available applications on-demand, without interference from other participants; shared domains between multiple users for scenarios where team work is expected; personalized catalog of applications for each user through the introduction of domain groups. Each domain group can contain one or more domains, precisely specifying what applications are available for deployment by the users. This allows the same - NMaaS instance to be reused for multiple courses at the same, where each user can be enrolled into multiple courses, and would have access only to previously whitelisted applications; bulk deployment of application instances across multiple domains for scenarios where the application deployment should not be done by the users themselves. NMaaS Virtual Lab from the Perspective of Learners Due to the challenging nature of organizing hands-on exercises, learners are usually required to deploy the necessary applications on their own workstations, either directly or in an isolated environment through the use of containers or virtual machines. This approach requires that each participant not only have the necessary hardware resources, but also to posses the required technical know-how for setting up and debugging the environment, which is usually not the main focus of the exercise itself. To make hands-on exercises more accessible to all learners, no matter their background or area of study, NMaaS will offer the following features: an accessible web portal where users can login and gain access to a curated catalog of applications they can explore; a simple deployment of application instances through the use of a deployment wizard which visually guides the user through the necessary steps; minimizing hardware requirements for the personal workstations of learners, since all software runs on a central infrastructure and is remotely accessible from anywhere; an isolated environment for experimenting, where depending on the application catalog, users can explore additional software on their own time, apart from what is required in the context of specific learning modules. The Road Ahead The vision for the NMaaS virtual lab use-case is to make it as easy as possible to deploy and use, both from the educators and learners perspective. By leveraging the possibility to add custom applications to the catalog, it is expected that each deployment will have a unique set of deployable applications. Through the introduction of catalog federation, it should be possible for different institutions to share their application templates, fostering collaboration, and knowledge exchange, bringing added value to the whole NMaaS ecosystem. It should be recognized that NMaaS does not necessarily have to be limited to organizing hands-on exercises for learners. As a result of its multi-tenancy, a single NMaaS instance can also be used by the educators themselves, making use of the compute capacity for running resource intensive processing pipelines or Jupyter notebooks. It can also be used by the supporting staff for easy deployment and management of network services which, of course, is the original use-case of NMaaS. Demos The first video below demonstrates the deployment process of an application from a trainee's perspective. The second video below showcases how NMaaS can be used as a remote development environment for various programming languages (Python in this particular case).","title":"Introduction"},{"location":"use-cases/virtual-lab/vlab-introduction/#introduction-to-nmaas-virtual-lab","text":"NMaaS Virtual Lab is a new NMaaS use-case aimed at educational communities. The core idea is to leverage the existing NMaaS functionality of on-demand application deployment and repurpose it in a learning context. This approach would allow NMaaS to be further used in the process of both formal, supervised, education (e.g., university courses), as well as for informal, and self-paced education (MOOCs, short demos, tutorials). During the initial planning, a number of scenarios have been envisioned, including: deployment of randomized, black-box containers for studying common software vulnerabilities; offloading of resource-intensive workloads on a centralized and powerful Kubernetes cluster, including JupyterLab servers, data processing pipelines, and simulations; creation of personalized, portable development environments with all necessary services included, such as a web-based integrated development environments (IDEs), relational databases, message queues, application servers, etc... making use of limited compute resources to serve as many users as possible through the deployment of ephemeral containers that are active only while used and paused when idle. Reactivation can be attempted at any point in time, preserving all previous data. The overall use-case along with its distinct scenarios has the potential to bring a number of benefits to both learners and educators. In the subsections below we elaborate on the underlying NMaaS features which make these benefits possible in more details.","title":"Introduction to NMaaS Virtual Lab"},{"location":"use-cases/virtual-lab/vlab-introduction/#nmaas-virtual-lab-from-the-perspective-of-educators","text":"Organizing hands-on exercises where all students can participate is often a challenging and time-consuming task for educators. It entails hardware provisioning, configuration, application deployment, user management, per tenant isolation, and integration with existing platforms, such as learning management systems (LMS) and grading systems. Depending on the subject area and technical proficiency of the educators and supporting staff, this manual approach does not scale for moderate and large groups of students. To overcome these issues, NMaaS will implement the following features, with the end-goal of making the organization of hands-on exercises by educators as effortless as possible: centralized provisioning and management of user profiles together with support for bulk user imports from LMS exports; individual, isolated, workspace (domain) for each and every user where they can deploy available applications on-demand, without interference from other participants; shared domains between multiple users for scenarios where team work is expected; personalized catalog of applications for each user through the introduction of domain groups. Each domain group can contain one or more domains, precisely specifying what applications are available for deployment by the users. This allows the same - NMaaS instance to be reused for multiple courses at the same, where each user can be enrolled into multiple courses, and would have access only to previously whitelisted applications; bulk deployment of application instances across multiple domains for scenarios where the application deployment should not be done by the users themselves.","title":"NMaaS Virtual Lab from the Perspective of Educators"},{"location":"use-cases/virtual-lab/vlab-introduction/#nmaas-virtual-lab-from-the-perspective-of-learners","text":"Due to the challenging nature of organizing hands-on exercises, learners are usually required to deploy the necessary applications on their own workstations, either directly or in an isolated environment through the use of containers or virtual machines. This approach requires that each participant not only have the necessary hardware resources, but also to posses the required technical know-how for setting up and debugging the environment, which is usually not the main focus of the exercise itself. To make hands-on exercises more accessible to all learners, no matter their background or area of study, NMaaS will offer the following features: an accessible web portal where users can login and gain access to a curated catalog of applications they can explore; a simple deployment of application instances through the use of a deployment wizard which visually guides the user through the necessary steps; minimizing hardware requirements for the personal workstations of learners, since all software runs on a central infrastructure and is remotely accessible from anywhere; an isolated environment for experimenting, where depending on the application catalog, users can explore additional software on their own time, apart from what is required in the context of specific learning modules.","title":"NMaaS Virtual Lab from the Perspective of Learners"},{"location":"use-cases/virtual-lab/vlab-introduction/#the-road-ahead","text":"The vision for the NMaaS virtual lab use-case is to make it as easy as possible to deploy and use, both from the educators and learners perspective. By leveraging the possibility to add custom applications to the catalog, it is expected that each deployment will have a unique set of deployable applications. Through the introduction of catalog federation, it should be possible for different institutions to share their application templates, fostering collaboration, and knowledge exchange, bringing added value to the whole NMaaS ecosystem. It should be recognized that NMaaS does not necessarily have to be limited to organizing hands-on exercises for learners. As a result of its multi-tenancy, a single NMaaS instance can also be used by the educators themselves, making use of the compute capacity for running resource intensive processing pipelines or Jupyter notebooks. It can also be used by the supporting staff for easy deployment and management of network services which, of course, is the original use-case of NMaaS.","title":"The Road Ahead"},{"location":"use-cases/virtual-lab/vlab-introduction/#demos","text":"The first video below demonstrates the deployment process of an application from a trainee's perspective. The second video below showcases how NMaaS can be used as a remote development environment for various programming languages (Python in this particular case).","title":"Demos"}]}